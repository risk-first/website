"use strict";(globalThis.webpackChunkrf_website=globalThis.webpackChunkrf_website||[]).push([[5051],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var a=t(96540);const i={},s=a.createContext(i);function r(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),a.createElement(s.Provider,{value:n},e.children)}},94587:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"ai/Practices/AI-As-Judge","title":"AI As Judge","description":"Using the outputs of one (trained) AI to measure the performance of another","source":"@site/docs/ai/Practices/AI-As-Judge.md","sourceDirName":"ai/Practices","slug":"/ai/Practices/AI-As-Judge","permalink":"/ai/Practices/AI-As-Judge","draft":false,"unlisted":false,"editUrl":"https://github.com/risk-first/website/blob/master/docs/ai/Practices/AI-As-Judge.md","tags":[{"inline":true,"label":"AI As Judge","permalink":"/tags/ai-as-judge"},{"inline":true,"label":"AI Practices","permalink":"/tags/ai-practices"}],"version":"current","frontMatter":{"title":"AI As Judge","description":"Using the outputs of one (trained) AI to measure the performance of another","featured":{"class":"c","element":"<action>AI-As-Judge</action>"},"tags":["AI As Judge","AI Practices"],"practice":{"mitigates":[{"tag":"Emergent Behaviour","reason":"Could catch early signs of unexpected AI behaviour by flagging responses that deviate from expected norms.","efficacy":"High"},{"tag":"Unintended Cascading Failures","reason":"Can act as a real-time filter to catch dangerous AI outputs before they propagate (e.g., financial trading AI making reckless decisions)."},{"tag":"Social Manipulation","reason":"Can prevent harmful misinformation, disinformation, and deepfakes from spreading by having a second user-owned AI fact-check or block misleading content."},{"tag":"Loss Of Human Control","reason":"Can enforce alignment principles by rejecting responses that optimise for harmful proxy goals."},{"tag":"Unintended Cascading failures","reason":"Introduces a level of redundancy around AI systems, allowing them to sound the alarm when operational parameters are breached."}]}},"sidebar":"tutorialSidebar","previous":{"title":"Synthetic Intelligence Rivalry","permalink":"/ai/Risks/Synthetic-Intelligence-Rivalry"},"next":{"title":"Ecosystem Diversity","permalink":"/ai/Practices/Ecosystem-Diversity"}}');var i=t(74848),s=t(28453);const r={title:"AI As Judge",description:"Using the outputs of one (trained) AI to measure the performance of another",featured:{class:"c",element:"<action>AI-As-Judge</action>"},tags:["AI As Judge","AI Practices"],practice:{mitigates:[{tag:"Emergent Behaviour",reason:"Could catch early signs of unexpected AI behaviour by flagging responses that deviate from expected norms.",efficacy:"High"},{tag:"Unintended Cascading Failures",reason:"Can act as a real-time filter to catch dangerous AI outputs before they propagate (e.g., financial trading AI making reckless decisions)."},{tag:"Social Manipulation",reason:"Can prevent harmful misinformation, disinformation, and deepfakes from spreading by having a second user-owned AI fact-check or block misleading content."},{tag:"Loss Of Human Control",reason:"Can enforce alignment principles by rejecting responses that optimise for harmful proxy goals."},{tag:"Unintended Cascading failures",reason:"Introduces a level of redundancy around AI systems, allowing them to sound the alarm when operational parameters are breached."}]}},o=void 0,c={},l=[{value:"Sources",id:"sources",level:2}];function d(e){const n={a:"a",h2:"h2",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components},{PracticeIntro:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("PracticeIntro",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t,{details:r}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"AI-As-Judge is a mitigation technique where one AI model generates responses while a second AI evaluates and filters them based on predefined rules, helping to enforce content moderation, alignment with ethical guidelines, and safety constraints."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Compare with ",(0,i.jsx)(n.a,{href:"/tags/Human-In-The-Loop",children:"Human In The Loop"}),", although once trained, the AI is always vigilant."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Requires extensive training and evaluation on its own, but potentially could be a service provided to enhance controls in"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"sources",children:"Sources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://huggingface.co/learn/cookbook/llm_judge",children:"Using LLM-As-A-Judge for an automated and versatile evaluation"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);