"use strict";(self.webpackChunkrf_website=self.webpackChunkrf_website||[]).push([[6543],{28453:(e,t,i)=>{i.d(t,{R:()=>s,x:()=>o});var r=i(96540);const n={},a=r.createContext(n);function s(e){const t=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:s(e.components),r.createElement(a.Provider,{value:t},e.children)}},28470:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"ai/Practices/Interpretability","title":"Interpretability","description":"Developing tools to analyse AI decision-making processes and detect emergent behaviors before they become risks.","source":"@site/docs/ai/Practices/Interpretability.md","sourceDirName":"ai/Practices","slug":"/ai/Practices/Interpretability","permalink":"/ai/Practices/Interpretability","draft":false,"unlisted":false,"editUrl":"https://github.com/risk-first/website/blob/master/docs/ai/Practices/Interpretability.md","tags":[{"inline":false,"label":"Interpretability","permalink":"/tags/Interpretability"},{"inline":false,"label":"AI Practice","permalink":"/tags/AI-Practice"}],"version":"current","frontMatter":{"title":"Interpretability","description":"Developing tools to analyse AI decision-making processes and detect emergent behaviors before they become risks.","featured":{"class":"c","element":"<action>Interpretability</action>"},"tags":["Interpretability","AI Practice"],"practice":{"mitigates":[{"tag":"Emergent Behaviour","reason":"An explicit interruption capability can avert catastrophic errors or runaway behaviours"}]}},"sidebar":"tutorialSidebar","previous":{"title":"Human In The Loop","permalink":"/ai/Practices/Human-In-The-Loop"},"next":{"title":"Kill Switch","permalink":"/ai/Practices/Kill-Switch"}}');var n=i(74848),a=i(28453);const s={title:"Interpretability",description:"Developing tools to analyse AI decision-making processes and detect emergent behaviors before they become risks.",featured:{class:"c",element:"<action>Interpretability</action>"},tags:["Interpretability","AI Practice"],practice:{mitigates:[{tag:"Emergent Behaviour",reason:"An explicit interruption capability can avert catastrophic errors or runaway behaviours"}]}},o=void 0,c={},l=[];function p(e){const t={li:"li",p:"p",ul:"ul",...(0,a.R)(),...e.components},{PracticeIntro:i}=t;return i||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("PracticeIntro",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i,{details:s}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Helps understand AI behavior but does not prevent emergent capabilities from appearing."}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Research in explainable AI is advancing, but understanding deep learning models remains complex."}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(p,{...e})}):p(e)}}}]);