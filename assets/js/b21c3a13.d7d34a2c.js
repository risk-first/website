"use strict";(self.webpackChunkrf_website=self.webpackChunkrf_website||[]).push([[5083],{46719:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>c,frontMatter:()=>o,metadata:()=>r,toc:()=>h});var n=s(74848),i=s(28453);const o={title:"Regression Testing",description:"Testing to ensure new changes do not adversely affect existing functionality.",tags:["Practice","Regression Testing"],featured:{class:"c",element:"<action>Regression Test</action>"},practice:{aka:["Retesting","Non-Regression Testing","Software Regression Testing"],mitigates:[{tag:"Implementation Risk",reason:"Detects and prevents regressions in the software."},{tag:"Reliability Risk",reason:"Regression testing helps prevent reliability breaks caused by software change."}],attendant:[{tag:"Schedule Risk",reason:"Can be time-consuming and introduce delays."},{tag:"Reliability Risk",reason:"Requires a stable testing environment, creating dependencies."},{tag:"Complexity Risk",reason:"Managing extensive regression tests can add complexity."}],related:["../Development-and-Coding/Refactoring","../Testing-and-Quality-Assurance/Integration-Testing","../Deployment-and-Operations/Release-Delivery"]}},a=void 0,r={id:"practices/Testing-and-Quality-Assurance/Regression-Testing",title:"Regression Testing",description:"Testing to ensure new changes do not adversely affect existing functionality.",source:"@site/docs/practices/Testing-and-Quality-Assurance/Regression-Testing.md",sourceDirName:"practices/Testing-and-Quality-Assurance",slug:"/practices/Testing-and-Quality-Assurance/Regression-Testing",permalink:"/practices/Testing-and-Quality-Assurance/Regression-Testing",draft:!1,unlisted:!1,editUrl:"https://github.com/risk-first/website/blob/master/docs/practices/Testing-and-Quality-Assurance/Regression-Testing.md",tags:[{inline:!1,label:"Practice",permalink:"/tags/Practice"},{inline:!1,label:"Regression Testing",permalink:"/tags/Regression-Testing"}],version:"current",frontMatter:{title:"Regression Testing",description:"Testing to ensure new changes do not adversely affect existing functionality.",tags:["Practice","Regression Testing"],featured:{class:"c",element:"<action>Regression Test</action>"},practice:{aka:["Retesting","Non-Regression Testing","Software Regression Testing"],mitigates:[{tag:"Implementation Risk",reason:"Detects and prevents regressions in the software."},{tag:"Reliability Risk",reason:"Regression testing helps prevent reliability breaks caused by software change."}],attendant:[{tag:"Schedule Risk",reason:"Can be time-consuming and introduce delays."},{tag:"Reliability Risk",reason:"Requires a stable testing environment, creating dependencies."},{tag:"Complexity Risk",reason:"Managing extensive regression tests can add complexity."}],related:["../Development-and-Coding/Refactoring","../Testing-and-Quality-Assurance/Integration-Testing","../Deployment-and-Operations/Release-Delivery"]}},sidebar:"tutorialSidebar",previous:{title:"Performance Testing",permalink:"/practices/Testing-and-Quality-Assurance/Performance-Testing"},next:{title:"Security Testing",permalink:"/practices/Testing-and-Quality-Assurance/Security-Testing"}},l={},h=[{value:"Description",id:"description",level:2},{value:"Discussion",id:"discussion",level:2},{value:"What Is It?",id:"what-is-it",level:2},{value:"Number Formats",id:"number-formats",level:2},{value:"Out-Of-Order Processing",id:"out-of-order-processing",level:2},{value:"Field Changes",id:"field-changes",level:2},{value:"File Formats",id:"file-formats",level:2},{value:"Methodology Changes",id:"methodology-changes",level:2},{value:"Aggregation Changes",id:"aggregation-changes",level:2},{value:"Non-Determinism",id:"non-determinism",level:2},{value:"Human Factors",id:"human-factors",level:2},{value:"Too Much Trouble",id:"too-much-trouble",level:2},{value:"See Also",id:"see-also",level:2}];function d(e){const t={a:"a",blockquote:"blockquote",em:"em",h2:"h2",li:"li",p:"p",ul:"ul",...(0,i.R)(),...e.components},{PracticeIntro:s,TagList:a}=t;return s||u("PracticeIntro",!0),a||u("TagList",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s,{details:o}),"\n",(0,n.jsx)(t.h2,{id:"description",children:"Description"}),"\n",(0,n.jsxs)(t.blockquote,{children:["\n",(0,n.jsxs)(t.p,{children:['"Regression testing is a type of software testing that seeks to uncover software regressions: as a previously developed and tested software is changed, whether the previously working software stops working or behaves differently." - ',(0,n.jsxs)(t.a,{href:"https://en.wikipedia.org/wiki/Regression_testing",children:["Regression testing, ",(0,n.jsx)(t.em,{children:"Wikipedia"})]})]}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"Regression Testing involves testing the software after changes have been made to ensure that existing functionality is not adversely affected. This practice helps in maintaining the stability and reliability of the software by catching and addressing regressions early in the development process."}),"\n",(0,n.jsx)(t.h2,{id:"discussion",children:"Discussion"}),"\n",(0,n.jsx)(t.h2,{id:"what-is-it",children:"What Is It?"}),"\n",(0,n.jsx)(t.p,{children:"Let\u2019s say you have two versions of some software.  A and A*. A* will replace version A at some period in the future.   Because we\u2019ve not bothered to build any automated acceptance tests for either A or A*, we want to make sure we haven\u2019t introduced any faults into A* that A didn\u2019t have."}),"\n",(0,n.jsxs)(t.p,{children:["For simplicity's sake, lets say both A and A* consume some ",(0,n.jsx)(t.em,{children:"inputs"})," and produce a report as the ",(0,n.jsx)(t.em,{children:"output"}),"."]}),"\n",(0,n.jsx)(t.p,{children:"Obviously, A might have lots of faults (that is, errors in it's output).  But, with regression testing we are able to prove that at least, A* won\u2019t have any new ones.  Or are we?"}),"\n",(0,n.jsx)(t.p,{children:"Regression testing proceeds by running the two systems side-by-side using the same input data, and hopefully producing the same outputs.  Someone will usually write some kind of diff (short for difference) routine to compare the results of the two systems, to see if they are the same."}),"\n",(0,n.jsx)(t.p,{children:"Often, this turns into an industry in itself, for reasons we will now go into.  Because, regression testing never works the way you hoped it would."}),"\n",(0,n.jsx)(t.h2,{id:"number-formats",children:"Number Formats"}),"\n",(0,n.jsx)(t.p,{children:"The first and most trivial problem you run into is that the numbers are different.  For example, one million can, more or less be represented in any one of these ways:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"1.0E6,"}),"\n",(0,n.jsx)(t.li,{children:"1,000,000"}),"\n",(0,n.jsx)(t.li,{children:"1000000,"}),"\n",(0,n.jsx)(t.li,{children:"1000000.000000000"}),"\n",(0,n.jsx)(t.li,{children:"1,000,001"}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"So, whoever wrote the diff tool, to compare the two systems, now has to consider that the formats are different."}),"\n",(0,n.jsx)(t.p,{children:"In the worst case (the last one),  the numbers are actually different. But, not different enough to matter.  Is anyone going to look into why the numbers have changed?  Probably not.  But a dollar here or there is nothing, right?  Right?  What about two dollars? And so on."}),"\n",(0,n.jsx)(t.h2,{id:"out-of-order-processing",children:"Out-Of-Order Processing"}),"\n",(0,n.jsx)(t.p,{children:"The second issue that you run into (and the second-most trivial) is that the results are in a different order coming out of each system.  If A and A* are producing vast quantities of data, this in itself now becomes a software engineering problem, because somehow, you have to sort the two sets of data to be the same, before you can compare them."}),"\n",(0,n.jsx)(t.p,{children:"Again, this is not the end of the world, but the diff tool gets a bit more complex.  Maybe complex enough to require it\u2019s own database."}),"\n",(0,n.jsx)(t.h2,{id:"field-changes",children:"Field Changes"}),"\n",(0,n.jsx)(t.p,{children:"Third up, and also quite trivial:  the report formats coming out of A and A* may have changed.  In the best case, A* has added some new columns to the report, and so to compare the results of the two systems, you\u2019re now going to need to understand the column orders and remove the extra ones from the comparison."}),"\n",(0,n.jsx)(t.p,{children:"In the worst case, A* changes the columns.  If the key changes, it might make it impossible to work out what the row from A was that needs to be compared with A*.  Usually, the mapping is recoverable but, yes of course the diff tool takes on more complexity."}),"\n",(0,n.jsx)(t.h2,{id:"file-formats",children:"File Formats"}),"\n",(0,n.jsx)(t.p,{children:"Maybe the original, CSV format of A is proving cumbersome, and A* is now using XML or JSON or protobufs or something crazy.  Of course, poor diff now has to convert either the new format back to the old, or the old format to the new, in order to compare them."}),"\n",(0,n.jsx)(t.p,{children:"Sometimes, for backwards compatibility, A* will continue to also producing CSV format.  So that\u2019s helpful for the diff tool, right?  Well, some.  But are you sure that the data in the XML format is consistent with that in the CSV?   How do you know?"}),"\n",(0,n.jsx)(t.h2,{id:"methodology-changes",children:"Methodology Changes"}),"\n",(0,n.jsx)(t.p,{children:"Things are starting to get serious now.  But at this stage, we\u2019ve spent considerable efforts building diff and also it\u2019s brother, diff-xml, so we\u2019re kind of committed.   The next change you start to see is that, obviously, we have made improvements in A to get A*, so actually, there are some differences because A* is deliberately different from A."}),"\n",(0,n.jsx)(t.p,{children:"This is great - these are the changes we wanted to see.  This means the software is right, yes? Well, possibly.  Some of the values are different.  But are they different correct or different broken?  If you\u2019re lucky, (and you have a good programmer) you might be able to get around this problem with some clever enhancements to the diff which either exclude any differences due to the change, or compare in some way that takes into account the methodology change. But, probably not."}),"\n",(0,n.jsx)(t.h2,{id:"aggregation-changes",children:"Aggregation Changes"}),"\n",(0,n.jsx)(t.p,{children:"This is where it gets really tricky: let\u2019s say the output of A and A* is to aggregate some input. But, the way in which aggregation is performed has changed.  You might end up with different row counts in A and A*, and no way to reconcile them at all.   This is pretty much curtains for the diff tool, unless it only affects a few of the rows and you can exclude again."}),"\n",(0,n.jsx)(t.h2,{id:"non-determinism",children:"Non-Determinism"}),"\n",(0,n.jsx)(t.p,{children:"This problem is that perhaps A and A* may not produce the same results each time they are run.   This means you can\u2019t even regression test A with itself, let alone something new.  \u2018A' may also use a back-end service in the production of its results, so even if the code in A itself is deterministic, it may be reliant on something that isn\u2019t.  How will you work around that?"}),"\n",(0,n.jsx)(t.h2,{id:"human-factors",children:"Human Factors"}),"\n",(0,n.jsx)(t.p,{children:"The likelihood is, whenever you run the diff, someone has to eyeball the exceptions it produces.  They\u2019ll probably be ok with this the first time, so long as there aren\u2019t too many to look through.  After a while though, they\u2019ll probably cheerfully tell you things are fine, even when they\u2019re not.  They were fine the other day, so whatevs."}),"\n",(0,n.jsx)(t.p,{children:"If none of the other issues warn you against regression testing, this should be the big one:  people are not designed to repetitively do anything. Without oversight, they will cut corners.  Don\u2019t put them in this position: it\u2019s not fair."}),"\n",(0,n.jsx)(t.h2,{id:"too-much-trouble",children:"Too Much Trouble"}),"\n",(0,n.jsx)(t.p,{children:"One of the biggest problems is that, eventually, it\u2019s probably too much trouble.  You have to get both systems up and running at the same time, with the same input data, and deterministic services, and you might have to access the production systems for this, and then get the data out of them, and then run the diff tool and eyeball the numbers.  You\u2019ll probably have to clone databases so that A* has the same data as A.  You\u2019ll probably have to do that every time you run it as A is a live system..."}),"\n",(0,n.jsxs)(t.p,{children:["Regression testing ",(0,n.jsx)(t.em,{children:"seems like"})," it's going to be a big win.  Sometimes, if you're lucky, it might be.  But at least now you can see some of the ",(0,n.jsx)(t.a,{href:"/tags/Hidden-Risk",children:"Hidden Risks"})," associated with it."]}),"\n",(0,n.jsxs)(t.p,{children:["Although ",(0,n.jsx)(t.a,{href:"Automated-Testing",children:"Automated Acceptance Tests"})," seem like a harder option, they are much easier to debug, and are probably what you really need:   what they tend to do though is surface problems in the original system that you didn't want to fix.  But, is that a bad thing?"]}),"\n",(0,n.jsx)(t.p,{children:"Likelihood is, the payback of regression testing is probably slight.  But, if you can confidently say that none of these risks is going to present a serious problem to you, then by all means, skip writing acceptance tests and go ahead."}),"\n",(0,n.jsx)(t.h2,{id:"see-also",children:"See Also"}),"\n",(0,n.jsx)(a,{tag:"Regression Testing"})]})}function c(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}function u(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},28453:(e,t,s)=>{s.d(t,{R:()=>a,x:()=>r});var n=s(96540);const i={},o=n.createContext(i);function a(e){const t=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),n.createElement(o.Provider,{value:t},e.children)}}}]);