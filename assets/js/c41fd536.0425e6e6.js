"use strict";(globalThis.webpackChunkrf_website=globalThis.webpackChunkrf_website||[]).push([[8389],{15411:(e,i,s)=>{s.r(i),s.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"ai/Start","title":"Artificial Intelligence Risk Framework","description":"Risk-First Track of articles on Artificial Intelligence Risk","source":"@site/docs/ai/Start.md","sourceDirName":"ai","slug":"/ai/Start","permalink":"/ai/Start","draft":false,"unlisted":false,"editUrl":"https://github.com/risk-first/website/blob/master/docs/ai/Start.md","tags":[{"inline":false,"label":"Front","permalink":"/tags/Front"}],"version":"current","sidebarPosition":7,"frontMatter":{"title":"Artificial Intelligence Risk Framework","description":"Risk-First Track of articles on Artificial Intelligence Risk","featured":{"class":"c","element":"<image-artifact imgsrc=\\"/public/templates/risk-first/posts/ai.svg\\">AI Risks</image-artifact>"},"layout":"categories","tags":["Front"],"tweet":"yes","sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Glossary of Practices","permalink":"/practices/Glossary-Of-Practices"},"next":{"title":"Community","permalink":"/community/Start"}}');var r=s(74848),t=s(28453);const a={title:"Artificial Intelligence Risk Framework",description:"Risk-First Track of articles on Artificial Intelligence Risk",featured:{class:"c",element:'<image-artifact imgsrc="/public/templates/risk-first/posts/ai.svg">AI Risks</image-artifact>'},layout:"categories",tags:["Front"],tweet:"yes",sidebar_position:7},o=void 0,l={},c=[{value:"Agentic Software Development Risk Framework",id:"agentic-software-development-risk-framework",level:2},{value:"Societal AI Risk Framework",id:"societal-ai-risk-framework",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(e){const i={a:"a",em:"em",h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.p,{children:"Risk-First has developed two complementary risk frameworks for understanding and managing AI-related risks."}),"\n",(0,r.jsx)(i.h2,{id:"agentic-software-development-risk-framework",children:"Agentic Software Development Risk Framework"}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"https://agentic-software-development.riskfirst.org",children:"agentic-software-development.riskfirst.org"})})}),"\n",(0,r.jsxs)(i.p,{children:["A framework addressing the unique threats that emerge when ",(0,r.jsx)(i.strong,{children:"AI systems autonomously write, modify, and deploy code"}),". Existing AI governance frameworks (NIST AI RMF, ISO/IEC 42001) focus on AI as a decision-making component \u2014 but AI is becoming the ",(0,r.jsx)(i.em,{children:"primary producer and modifier"})," of software itself."]}),"\n",(0,r.jsx)(i.p,{children:'This shifts risk from "bad AI decision" to "unsafe evolving codebase" \u2014 a completely different class of risk.'}),"\n",(0,r.jsx)(i.p,{children:"Covers capabilities such as:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Code Generation"})," \u2014 AI producing source code and configurations"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Tool Calling"})," \u2014 Invoking external APIs and system commands"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Autonomous Planning"})," \u2014 Decomposing goals without human intervention"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Multi-Agent Orchestration"})," \u2014 Coordinating multiple AI agents"]}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"And threats including Code Security Risks, Supply Chain Risks, Prompt Injection, and Autonomy & Control Risks."}),"\n",(0,r.jsx)(i.h2,{id:"societal-ai-risk-framework",children:"Societal AI Risk Framework"}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"https://societal-ai-risk.riskfirst.org",children:"societal-ai-risk.riskfirst.org"})})}),"\n",(0,r.jsxs)(i.p,{children:["A framework addressing ",(0,r.jsx)(i.strong,{children:"civilisation-scale risks"})," from advanced AI systems. This examines what happens to society as AI grows in capability and autonomy \u2014 risks that affect economies, political systems, human agency, and the balance of power between humans and machines."]}),"\n",(0,r.jsx)(i.p,{children:"Covers risks such as:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Emergent Behaviour"})," \u2014 Unforeseen capabilities arising from scaling"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Loss of Human Control"})," \u2014 AI evolving beyond human oversight"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Social Manipulation"})," \u2014 AI-driven disinformation at scale"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Superintelligence With Malicious Intent"})," \u2014 Advanced AI acting against human interests"]}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"And practices including Human-In-The-Loop, Global AI Governance, Kill Switch mechanisms, and more."}),"\n",(0,r.jsx)(i.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,r.jsxs)(i.p,{children:["For a comprehensive view of AI risk frameworks across all domains, see the ",(0,r.jsx)(i.a,{href:"https://airisk.mit.edu",children:"MIT AI Risks Database"})," which covers hundreds of different frameworks."]})]})}function m(e={}){const{wrapper:i}={...(0,t.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,i,s)=>{s.d(i,{R:()=>a,x:()=>o});var n=s(96540);const r={},t=n.createContext(r);function a(e){const i=n.useContext(t);return n.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(t.Provider,{value:i},e.children)}}}]);