% Page setup
\documentclass[11pt]{memoir}
\setstocksize{9.69in}{7.44in}
\settrimmedsize{\stockheight}{\stockwidth}{*}
\setlrmarginsandblock{3.5cm}{2.5cm}{*}
\setulmarginsandblock{2cm}{3cm}{*}
\checkandfixthelayout 
\setheadfoot{\onelineskip}{2\onelineskip}

% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{parskip}    	
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}	

\usepackage{graphicx}					
\usepackage{amssymb}

%SetFonts
\usepackage[T1]{fontenc}
\usepackage{newpxtext,newpxmath}

%Images
\usepackage{graphicx}
% We will generate all images so they have a width 1\maxwidth. This means
% that they will get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother
\let\Oldincludegraphics\includegraphics
\renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=1\maxwidth]{#1}}
\usepackage{rotating}
\usepackage[margin=10pt,font=small,labelfont=bf]{caption}
\captionsetup[figure]{labelfont={bf,it},textfont={bf,it}}
 \setfloatlocations{figure}{thpb}


% Links
\usepackage[hyphens]{url}
\usepackage[unicode=true]{hyperref}
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={},
            colorlinks=false,
            urlcolor=black,
            linkcolor=black,
            pdfborder={0 0 0}}

% Footers / Page Numbers            (FIX ME)
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
  \renewcommand{\headrulewidth}{0pt}
  \fancyfoot[LE, RO]{\thepage}
  \fancyfoot[C]{\textsl}

% Tables            
\usepackage{longtable,booktabs}
\usepackage[width=.8\textwidth]{caption}
% These lines are needed to make table captions work with longtable:
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{rotating}
 \setfloatlocations{table}{thpb}


% Code Sections
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\lstnewenvironment{code}{\lstset{basicstyle=\small\ttfamily}}{}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}


%Links as Notes
\DeclareRobustCommand{\href}[2]{#2\footnote{\url{#1}}}
 \renewcommand{\footnotesize}{\fontsize{6.5pt}{8.5pt}\selectfont}


%Sections
\chapterstyle{veelo}
\setlength{\beforechapskip}{20pt}
\setsechook{\hangsecnum}
\setcounter{secnumdepth}{5}

\begin{document}

\frontmatter

\title{Risk-First Software Development: The Menagerie}
\author{Rob Moffat}

\begin{titlingpage}

\hspace{0.05\textwidth}

\centering

{\Huge\bfseries\textsc{Risk-First}}\\[1\baselineskip]

{\Huge\bfseries\textsc{Software Development}}\\[2\baselineskip]

{\Huge\textit{Volume 1: The Menagerie}}\\[4\baselineskip]

{\Oldincludegraphics[width=0.5\textwidth]{images/R1_logo_grue.png}}\\[4\baselineskip]

{\Huge\textsc{Rob Moffat}}


\end{titlingpage}

\hypertarget{risk-first-the-menagerie}{%
\section{Risk-First: The Menagerie}\label{risk-first-the-menagerie}}

By Rob Moffat

Copyright \copyright 2018 Kite9 Ltd.

All rights reserved. No part of this publication may be reproduced,
distributed, or transmitted in any form or by any means, including
photocopying, recording, or other electronic or mechanical methods,
without the prior written permission of the publisher, except in the
case of brief quotations embodied in critical reviews and certain other
noncommercial uses permitted by copyright law. For permission requests,
write to the publisher, addressed ``Attention: Permissions
Coordinator,'' at the address below.

ISBN: 9781717491855

\hypertarget{credits}{%
\subsection{Credits}\label{credits}}

tbd

Cover Images: Biodiversity Heritage Library. Biologia
Centrali-Americana. Insecta. Rhynchota. Hemiptera-Homoptera. Volume 1
(1881-1905)

Cover Design By P. Moffat (\texttt{peter@petermoffat.com})

Thanks to:

\hypertarget{books-in-the-series}{%
\subsection{Books In The Series}\label{books-in-the-series}}

\begin{itemize}
\tightlist
\item
  \textbf{Risk-First: The Menagerie:} Book one of the Risk-First series
  argues the case for viewing \emph{all} of the activities on a software
  project through the lens of \emph{managing risk}. It introduces the
  menagerie of different risks you're likely to meet on a software
  project, naming and classifying them so that we can try to understand
  them better.
\item
  \textbf{Risk-First: Tools and Practices:} Book two of the Risk-First
  series explores the relationship between software project risks and
  the tools and practices we use to mitigate them. Due for publication
  in 2020.
\end{itemize}

\hypertarget{online}{%
\subsection{Online}\label{online}}

Material for the books is freely available to read, drawn from
\texttt{risk-first.org}.

\hypertarget{published-by}{%
\subsection{Published By}\label{published-by}}

\begin{verbatim}
Kite9 Ltd.
14 Manor Close
Colchester
CO6 4AR
\end{verbatim}

\newpage
\setcounter{tocdepth}{0}
\tableofcontents

\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

Welcome to Risk-First!

Let's cover some of the big questions up-front: The why, what, who, how
and where of \emph{The Menagerie}.

\hypertarget{why}{%
\section{Why}\label{why}}

\begin{quotation}

``Scrum, Waterfall, Lean, Prince2: what do they all have in common?''

\end{quotation}

I've started this because, on my career journey, I've noticed that the
way I do things doesn't seem to match up with the way the books
\emph{say} it should be done. And, I found this odd and wanted to
explore it further. Hopefully, you, the reader, will find something of
use in this.

I started with this observation: \emph{Development Teams} put a lot of
faith in methodology. Sometimes, this faith is often so strong it
borders on religion. (Which in itself is a concern.) For some, this is
Prince2. For others, it might be Lean or Agile.

\emph{Developers} put a lot of faith in \emph{particular tools} too.
Some developers are pro-or-anti-Java, others are pro-or-anti-XML. All of
them have their views coloured by their \emph{experiences} (or lack of)
with these tools. Was this because their past projects \emph{succeeded}
or \emph{failed} because of them?

As time went by, I came to see that the choice of methodology, process
or tool was contingent on the problem being solved, and the person
solving the problem. We don't face a shortage of tools in IT, or a
shortage of methodologies, or a shortage of practices. Essentially, that
all the tools and methodologies that the industry had supplied were
there to help \emph{minimize the risk of my project failing}.

This book considers that perspective: that building software is all
about \emph{managing risk}, and that these methodologies are
acknowledgements of this fact, and they differ because they have
\emph{different ideas} about which are the most important \emph{risks to
manage}.

\hypertarget{what-this-is}{%
\section{What This Is}\label{what-this-is}}

Hopefully, after reading this, you'll come away with:

\begin{itemize}
\tightlist
\item
  An appreciation of how risk underpins everything we do as developers,
  whether we want it to or not.
\item
  A framework for evaluating methodologies, tools and practices and
  choosing the right one for the task-at-hand.
\item
  A recontextualization of the software process as being an exercise in
  mitigating different kinds of risk.
\item
  The tools to help you decide when a methodology or tool is
  \emph{letting you down}, and the vocabulary to argue for when it's a
  good idea to deviate from it.
\end{itemize}

This is not intended to be a rigorously scientific work: I don't believe
it's possible to objectively analyze a field like software development
in any meaningful, statistically significant way. (For one, things just
change too fast.)

\begin{quotation}

``I have this Pattern''

\sourceatright{\href{http://c2.com/ppr/wiki/WikiPagesAboutWhatArePatterns/HaveThisPattern.html}{\textemdash  Attributed to Ward Cunningham, \emph{Have This Pattern, C2 Wiki}}}
\end{quotation}

Does that diminish it? If you have visited the
\href{https://tvtropes.org}{TVTropes} website, you'll know that it's a
set of web-pages describing \emph{common patterns} of narrative,
production, character design etc. to do with fiction. For example:

\begin{quotation}

``Sometimes, at the end of a Dream Sequence or an All Just a Dream
episode, after the character in question has woken up and demonstrated
any {[}lesson{]} that the dream might have been communicating, there's
some small hint that it wasn't a dream after all, even though it quite
obviously was\ldots{} right?.''

\sourceatright{\href{https://tvtropes.org/pmwiki/pmwiki.php/Main/OrWasItADream}{\textemdash  Or Was It a Dream?, \emph{TVTropes}}}
\end{quotation}

Is it scientific? No.~Is it correct? Almost certainly. TVTropes is a set
of \emph{empirical patterns} for how stories on TV and other media work.
It's really useful, and a lot of fun. (Warning: it's also incredibly
addictive).

In the same way, ``\href{http://amzn.eu/d/3cOwTkH}{Design Patterns:
Elements of Reusable Object-Oriented Software}'', is a book detailing
patterns of \emph{structure} within Object-Oriented programming, such
as:

\begin{quotation}

``{[}The{]} Adapter {[}pattern{]} allows classes with incompatible
interfaces to work together by wrapping its own interface around that of
an already existing class\ldots{}''

\sourceatright{\href{https://en.wikipedia.org/wiki/Design_Patterns}{\textemdash  Design Patterns, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{patterns-for-practitioners}{%
\subsection{Patterns For
Practitioners}\label{patterns-for-practitioners}}

Design Patterns aimed to be a set of \emph{useful} patterns which
practitioners could use in their software to achieve certain goals. ``I
have this pattern'' was a phrase used to describe how they had seen a
certain set of constraints before, and how they had solved it in
software.

This book was a set of experts handing down their battle-tested
practices for other developers to use, and, whether you like patterns or
not, knowing them is an important part of being a software developer, as
you will see them used everywhere you go and probably use them yourself.

In the same way, Risk-First aims to be a set of \emph{Patterns for
Software Risk}. Hopefully after reading this book, you will see where
risk hides in software projects, and have a name for it when you see it.

\hypertarget{towards-a-periodic-table}{%
\subsection{Towards a ``Periodic
Table''}\label{towards-a-periodic-table}}

In the latter chapters of ``The Menagerie'' we try to assemble these
risk patterns into a cohesive whole. Projects fail because of risks, and
risks arise from predictable sources.

\hypertarget{what-this-is-not}{%
\subsection{What This is Not}\label{what-this-is-not}}

This is not intended to be a rigorously scientific work: I don't believe
it's possible to objectively analyze a field like software development
in any meaningful, statistically significant way. (For one, things just
change too fast.)

Neither is this site isn't going to be an exhaustive guide of every
possible software development practice and methodology. That would just
be too long and tedious.

Neither is this really a practitioner's guide to using any particular
methodology: If you've come here to learn the best way to do
Retrospectives, then you're in the wrong place. There are plenty of
places you can find that information already. Where possible, this site
will link to or reference concepts on Wikipedia or the wider internet
for further reading on each subject.

\hypertarget{who}{%
\section{Who}\label{who}}

This work is intended to be read by people who work on software
projects, and especially those who are involved in managing software
projects.

If you work collaboratively with other people in a software process, you
should find Risk-First a useful lexicon of terms to help describe the
risks you face.

But here's a warning: This is going to be a depressing book to read. It
is book one of a two-book series, but in \textbf{Book One} you only get
to meet the bad guy.

While \textbf{Book Two} is all about \emph{how to succeed}, This book is
all about how projects \emph{fail}. In it, we're going to try and put
together a framework for understanding the risk of failure, in order
that we can reconstruct our understanding of our activities on a project
based on avoiding it.

So, if you are interested in \emph{avoiding your project failing}, this
is probably going to be useful knowledge.

\hypertarget{for-developers}{%
\subsection{For Developers}\label{for-developers}}

Risk-First is a tool you can deploy to immediately improve your ability
to plan your work.

Frequently, as developers we find software methodologies ``done to us''
from above. Risk-First is a toolkit to help \emph{take apart}
methodologies like Scrum, Lean and Prince2, and understand them.
Methodologies are \emph{bicycles}, rather than \emph{religions}. Rather
than simply \emph{believing}, we can take them apart and see how they
work.

\hypertarget{for-project-managers-and-team-leads}{%
\subsection{For Project Managers and Team
Leads}\label{for-project-managers-and-team-leads}}

All too often, Project Managers don't have a full grasp of the technical
details of their projects. And this is perfectly normal, as the
specialization belongs below them. However, projects fail because risks
materialize, and risks materialize because the devil is in those
details.

This seems like a lost cause, but there is hope: the ways in which risks
materialize on technical projects is the same every time. With
Risk-First we are attempting to name each of these types of risk, which
allows for a dialog with developers about which risks they face, and the
order they should be tackled.

Risk-First allows a project manager to pry open the black box of
development and talk with developers about their work, and how it will
affect the project. It is another tool in the (limited) arsenal of
techniques a project manager can bring to bear on the task of delivering
a successful project.

\hypertarget{how}{%
\section{How}\label{how}}

One of the original proponents of the Agile Manifesto, Kent Beck, begins
his book Extreme Programming by stating:

\begin{quotation}

``It's all about risk''

\sourceatright{\href{http://amzn.eu/d/gUQjnbF}{\textemdash  Kent Beck, \emph{Extreme Programming Explained}}}
\end{quotation}

This is a promising start. From there, he introduces his methodology,
Extreme Programming, and explains how you can adopt it in your team, the
features to observe and the characteristics of success and failure.
However, while \emph{Risk} has clearly driven the conception of Extreme
Programming, there is no clear model of software risk underpinning the
work, and the relationship between the practices he espouses and the
risks he is avoiding are hidden.

In this book, we are going to introduce a model of software project
risk. This means that in \textbf{Book Two} (Risk-First: Tools and
Practices), we can properly analyse Extreme Programming (and Scrum,
Waterfall, Lean and all the others) and \emph{understand} what drives
them. Since they are designed to deliver successful software projects,
they must be about managing risks, and we will uncover \emph{exactly
which risks} and \emph{how they do it}.

\hypertarget{where}{%
\section{Where}\label{where}}

All of the material for this book is available Open Source on
\href{https://github.com}{github.com}, and at the
\href{https://risk-first.org}{risk-first.org} website. Please visit,
your feedback is appreciated.

There is no compulsion to buy a print or digital version of the book,
but we'd really appreciate the support. So, if you've read this and
enjoyed it, how about buying a copy for someone else to read?

\hypertarget{a-note-on-references}{%
\subsection{A Note on References}\label{a-note-on-references}}

Where possible, references are to the
\href{https://wikipedia.org}{Wikipedia} website. Wikipedia is not
perfect. There is a case for linking to the original articles and
papers, but by using Wikipedia references are free and easy for everyone
to access, and hopefully will exist for a long time into the future.

On to The Executive Summary

\hypertarget{quick-summary}{%
\chapter{Quick Summary}\label{quick-summary}}

\hypertarget{there-are-lots-of-ways-of-running-software-projects}{%
\section{1. There are Lots of Ways of Running Software
Projects}\label{there-are-lots-of-ways-of-running-software-projects}}

There are lots of different ways to look at a project in-flight. For
example, metrics such as ``number of open tickets'', ``story points'',
``code coverage'' or ``release cadence'' give us a numerical feel for
how things are going and what needs to happen next. We also judge the
health of projects by the practices used on them, such as Continuous
Integration, Unit Testing or Pair Programming.

Software methodologies, then, are collections of tools and practices:
``Agile'', ``Waterfall'', ``Lean'' or ``Phased Delivery'' all prescribe
different approaches to running a project, and are opinionated about the
way they think projects should be done and the tools that should be
used.

None of these is necessarily more ``right'' than another- they are
suitable on different projects at different times.

A key question then is: \textbf{how do we select the right tools for the
job?}

\hypertarget{we-can-look-at-projects-in-terms-of-risks}{%
\section{2. We can Look at Projects in Terms of
Risks}\label{we-can-look-at-projects-in-terms-of-risks}}

One way to examine the project in-flight is by looking at the risks it
faces.

Commonly, tools such as
\href{https://www.projectmanager.com/blog/raid-log-use-one}{RAID logs}
and \href{https://pmtips.net/blog-new/what-does-rag-status-mean}{RAG
status} reporting are used. These techniques should be familiar to
project managers and developers everywhere.

However, the Risk-First view is that we can go much further: that each
item of work being done on the project is to manage a particular risk.
Risk isn't something that just appears in a report, it actually drives
\emph{everything we do}.

For example:

\begin{itemize}
\tightlist
\item
  A story about improving the user login screen can be seen as reducing
  \emph{the risk of users not signing up}.
\item
  A task about improving the health indicators could be seen as
  mitigating \emph{the risk of the application failing and no-one
  reacting to it}.
\item
  Even a task as basic as implementing a new function in the application
  is mitigating \emph{the risk that users are dissatisfied and go
  elsewhere}.
\end{itemize}

One assertion of Risk-First is that \textbf{every action you take on a
project is to manage a risk.}

\hypertarget{we-can-break-down-risks-on-a-project-methodically}{%
\section{3. We Can Break Down Risks on a Project
Methodically}\label{we-can-break-down-risks-on-a-project-methodically}}

Although risk is usually complicated and messy, other industries have
found value in breaking down the types of risks that affect them and
addressing them individually.

For example:

\begin{itemize}
\tightlist
\item
  In manufacturing, \emph{tolerances} allow for calculating the
  likelihood of defects in production.
\item
  In finance, projects and teams are structured around monitoring risks
  like \emph{credit risk}, \emph{market risk} and \emph{liquidity risk}.
\item
  \emph{Insurance} is founded on identifying particular risks and
  providing financial safety-nets for when they occur, such as death,
  injury, accident and so on.
\end{itemize}

Software risks are difficult to quantify, and mostly, the effort
involved in doing so \emph{exactly} would outweigh the benefit.
Nevertheless, there is value in spending time building
\emph{classifications of risk for software}. That's what Risk-First
does: it describes a set of \emph{risk patterns} we see every day on
software projects.

With this in place, we can:

\begin{itemize}
\tightlist
\item
  Talk about the types of risks we face on our projects, using an
  appropriate language.
\item
  Anticipate Hidden Risks that we hadn't considered before.
\item
  Weigh the risks against each other, and decide which order to tackle
  them.
\end{itemize}

\hypertarget{we-can-analyse-tools-and-techniques-in-terms-of-how-they-manage-risk}{%
\section{4. We can Analyse Tools and Techniques in Terms of how they
Manage
Risk}\label{we-can-analyse-tools-and-techniques-in-terms-of-how-they-manage-risk}}

If we accept the assertion above that \emph{all} the actions we take on
a project are about mitigating risks, then it stands to reason that the
tools and techniques available to us on a project are there for
mitigating different types of risks.

For example:

\begin{itemize}
\tightlist
\item
  If we do a Code Review, we are partly trying to minimise the risks of
  bugs slipping through into production, and also manage the Key-Man
  Risk of knowledge not being widely-enough shared.
\item
  If we write Unit Tests, we're addressing the risk of bugs going to
  production, but we're also mitigating against the risk of
  \emph{regression}, and future changes breaking our existing
  functionality.
\item
  If we enter into a contract with a supplier, we are mitigating the
  risk of the supplier vanishing and leaving us exposed. With the
  contract in place, we have legal recourse against this risk.
\end{itemize}

From the above examples, it's clear that \textbf{different tools are
appropriate for managing different types of risks.}

\hypertarget{different-methodologies-are-for-different-risk-profiles}{%
\section{5. Different Methodologies are for Different Risk
Profiles}\label{different-methodologies-are-for-different-risk-profiles}}

In the same way that our tools and techniques are appropriate to dealing
with different risks, the same is true of the methodologies we use on
our projects. We can use a Risk-First approach to examine the different
methodologies, and see which risks they address.

For example:

\begin{itemize}
\tightlist
\item
  \textbf{Agile} methodologies prioritise the risk that requirements
  capture is complicated, error-prone and that requirements change
  easily.
\item
  \textbf{Waterfall} takes the view that development effort is an
  expensive risk, and that we should build plans up-front to avoid
  re-work.
\item
  \textbf{Lean} takes the view that risk lies in incomplete work and
  wasted work, and aims to minimise that.
\end{itemize}

Although many developers have a methodology-of-choice, the argument here
is that there are tradeoffs with all of these choices.

\begin{quotation}

``Methodologies are like \emph{bicycles}, rather than \emph{religions}.
Rather than simply \emph{believing}, we can take them apart and see how
they work. ''

\end{quotation}

\hypertarget{we-can-drive-development-with-a-risk-first-perspective}{%
\section{6. We can Drive Development With a Risk-First
Perspective}\label{we-can-drive-development-with-a-risk-first-perspective}}

We have described a model of risk within software projects, looking
something like this:

\begin{figure}
\centering
\includegraphics{images/generated/executive-summary/pattern_language-400dpi.png}
\caption{Methodologies, Risks, Practices\label{pattern_language.png}}
\end{figure}

How do we take this further?

One idea explored is the \emph{Risk Landscape}: Although the software
team can't remove risk from their project, they can take actions that
move them to a place in the Risk Landscape where the risks on the
project are more favourable than where they started.

From there, we examine basic risk archetypes you will encounter on the
software project, to build up a Taxonomy of Software Risk, and look at
which specific tools you can use to mitigate each kind of risk.

Then, we look at different software practices, and how they manage
various risks. Beyond this we examine the question: \emph{how can a
Risk-First approach inform the use of this practice?}

For example:

\begin{itemize}
\tightlist
\item
  If we are introducing a \textbf{Sign-Off} in our process, we have to
  balance the risks it \emph{mitigates} (coordination of effort, quality
  control, information sharing) with the risks it \emph{introduces}
  (delays and process bottlenecks).
\item
  If we build in \textbf{Redundancy}, this mitigates the risk of a
  \emph{single point of failure}, but introduces risks around
  \emph{synchronizing data} and \emph{communication} between the
  systems.
\item
  If we introduce \textbf{Process}, this may make it easier to
  \emph{coordinate as a team} and \emph{measure performance} but may
  lead to bureaucracy, focusing on the wrong goals or over-rigid
  interfaces to those processes.
\end{itemize}

Risk-First aims to provide a framework in which we can \emph{analyse
these actions} and weigh up \emph{accepting} versus \emph{mitigating}
risks.

\textbf{Still interested? Then dive into reading the introduction.}

\mainmatter
\part{Introduction}

\hypertarget{a-simple-scenario}{%
\chapter{A Simple Scenario}\label{a-simple-scenario}}

In this chapter, I'm going to introduce some terms for thinking about
risk.

Lets for a moment forget about software completely, and think about
\emph{any endeavour at all} in life. It could be passing a test, mowing
the lawn or going on holiday. Choose something now. I'll discuss from
the point of view of ``cooking a meal for some friends'', but you can
play along with your own example.

\hypertarget{goal-in-mind}{%
\section{Goal In Mind}\label{goal-in-mind}}

Now, in this endeavour, we want to be successful. That is to say, we
have a \textbf{Goal In Mind}: we want our friends to go home satisfied
after a decent meal, and not to feel hungry. As a bonus, we might also
want to spend time talking with them before and during the meal. So, now
to achieve our Goal In Mind we \emph{probably} have to do some tasks.

Since our goal only exists \emph{in our head}, we can say it is part of
our \textbf{Internal Model} of the world. That is, the model we have of
reality. This model extends to \emph{predicting what will happen}.

If we do nothing, our friends will turn up and maybe there's nothing in
the house for them to eat. Or maybe, the thing that you're going to cook
is going to take hours and they'll have to sit around and wait for you
to cook it and they'll leave before it's ready. Maybe you'll be some
ingredients short, or maybe you're not confident of the steps to prepare
the meal and you're worried about messing it all up.

\hypertarget{attendant-risk}{%
\section{Attendant Risk}\label{attendant-risk}}

These \emph{nagging doubts} that are going through your head I'll call
the Attendant Risks: they're the ones that will occur to you as you
start to think about what will happen.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/goal_in_mind-400dpi.png}
\caption{Goal In Mind, with the risks you know
about\label{goal_in_mind.png}}
\end{figure}

When we go about preparing this wonderful evening, we can choose to deal
with these risks: shop for the ingredients in advance, prepare parts of
the meal, maybe practice the cooking in advance. Or, we can wing it, and
sometimes we'll get lucky.

How much effort we expend on these Attendant Risks depends on how big we
think they are. For example, if you know there's a 24-hour shop, you'll
probably not worry too much about getting the ingredients well in
advance (although, the shop \emph{could still be closed}).

\hypertarget{hidden-risks}{%
\section{Hidden Risks}\label{hidden-risks}}

There are also \textbf{Hidden Risks} that you \emph{don't} know about:
if you're poaching eggs for dinner, perhaps you don't know that fresh
eggs poach best. The difference is, Attendant Risks are risks you are
aware of, but can't be sure of the amount they will impact you. Hidden
Risks are ones you are unaware of.

\href{https://en.wikipedia.org/wiki/There_are_known_knowns}{Donald
Rumsfeld} famously called these ``Unknown Unknowns''.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/hidden_risks-400dpi.png}
\caption{Goal In Mind, the risks you know about and the ones you
don't\label{hidden_risks.png}}
\end{figure}

Different people evaluate risks differently, and they'll also
\emph{know} about different risks. What is an Attendant Risk for one
person is a Hidden Risk for another.

Which risks we know about depends on our \textbf{knowledge} and
\textbf{experience}, then. And that varies from person to person (or
team to team).

\hypertarget{meeting-reality}{%
\section{Meeting Reality}\label{meeting-reality}}

As the dinner party gets closer, we make our preparations, and the
inadequacies of the Internal Model become apparent. We learn what we
didn't know and the Hidden Risks reveal themselves. Other things we were
worried about don't materialise. Things we thought would be minor risks
turn out to be greater.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/model_vs_reality-400dpi.png}
\caption{How Taking Action affects Reality, and also changes your
Internal Model\label{model_vs_reality.png}}
\end{figure}

Our model is forced to Meet Reality, and the model changes, forcing us
to deal with these risks, as shown in Figure \ref{model_vs_reality.png}.
Whenever we try to \emph{do something} about a risk, it is called Taking
Action. Taking Action \emph{changes} reality, and with it your Internal
Model of the risks you're facing. That's because it's only by
interacting with the world that we add knowledge to our Internal Model
about what works and what doesn't. Even something as passive as
\emph{checking the shop opening times} is an action, and it improves on
our Internal Model of the world.

If we had a good Internal Model, and took the right actions, we should
see positive outcomes. If we failed to manage the risks, or took
inappropriate actions, we'll probably see negative outcomes.

\hypertarget{on-to-software}{%
\section{On To Software}\label{on-to-software}}

Here, we've introduced some new terms that we're going to use a lot:
Meet Reality, Attendant Risk, Hidden Risk, Internal Model, Taking Action
and Goal In Mind. And, we've applied them in a simple scenario.

But Risk-First is about understanding risk in software development, so
let's examine the scenario of a new software project, and expand on the
simple model being outlined above: instead of a single person, we are
likely to have a team, and our model will not just exist in our heads,
but in the code we write.

On to Development Process\ldots{}

\hypertarget{development-process}{%
\chapter{Development Process}\label{development-process}}

In the previous chapter we introduced some terms for talking about risk
(such as Attendant Risk, Hidden Risk and Internal Model) via a simple
scenario.

Now, let's look at the everyday process of developing \emph{a new
feature} on a software project, and see how our risk model informs it.

\hypertarget{an-example-process}{%
\section{An Example Process}\label{an-example-process}}

Let's ignore for now the specifics of what methodology is being used -
we'll come to that later. Let's say your team have settled for a process
something like the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Specification}: A new feature is requested somehow, and a
  business analyst works to specify it.
\item
  \textbf{Code And Unit Test}: A developer writes some code, and some
  unit tests.
\item
  \textbf{Integration}: They integrate their code into the code base.
\item
  \textbf{UAT}: They put the code into a User Acceptance Test (UAT)
  environment, and user(s) test it.
\item
  \ldots{} All being well, the code is \textbf{Released to Production}.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_1-400dpi.png}
\caption{A Simple Development Process\label{development_process_1.png}}
\end{figure}

Now, the \emph{methodology} being used might be Waterfall, it might be
Agile. We're not going to commit to specifics at this stage. Also we
don't need to consider whether this is particularly a \emph{good}
process: you could add code review, a pilot phase, integration testing,
whatever. It's probably not perfect, but let's just assume that \emph{it
works for this project} and everyone is reasonably happy with it.

We're just doing some analysis of \emph{what process gives us}.

\hypertarget{minimizing-risks---overview}{%
\section{Minimizing Risks -
Overview}\label{minimizing-risks---overview}}

I am going to argue that this entire process is \emph{informed by
software risk}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We have \emph{a business analyst} who talks to users and fleshes out
  the details of the feature properly. This is to minimize the risk of
  \textbf{building the wrong thing}.
\item
  We \emph{write unit tests} to minimize the risk that our code
  \textbf{isn't doing what we expected, and that it matches the
  specifications}.
\item
  We \emph{integrate our code} to minimize the risk that it's
  \textbf{inconsistent with the other, existing code on the project}.
\item
  We have \emph{acceptance testing} and quality gates generally to
  \textbf{minimize the risk of breaking production}, somehow.
\end{enumerate}

We could skip all those steps above and just do this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Developer gets wind of new idea from user, logs onto production and
  changes some code directly.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_2-400dpi.png}
\caption{A Dangerous Development
Process\label{development_process_2.png}}
\end{figure}

We can all see this would be a disaster, but why?

Two reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  You're Meeting Reality all-in-one-go: All of these risks materialize
  at the same time, and you have to deal with them all at once.
\item
  Because of this, at the point you put code into the hands of your
  users, your Internal Model is at its least-developed. All the Hidden
  Risks now need to be dealt with at the same time, in production.
\end{enumerate}

\hypertarget{applying-the-model}{%
\section{Applying the Model}\label{applying-the-model}}

Let's look at how our process should act to prevent these risks
materializing by considering an unhappy path, one where at the outset,
we have lots of Hidden Risks. Let's say a particularly vocal user rings
up someone in the office and asks for new \textbf{Feature X} to be added
to the software. It's logged as a new feature request, but:

\begin{itemize}
\tightlist
\item
  Unfortunately, this feature once programmed will break an existing
  \textbf{Feature Y}.
\item
  Implementing the feature will use some api in a library, which
  contains bugs and have to be coded around.
\item
  It's going to get misunderstood by the developer too, who is new on
  the project and doesn't understand how the software is used.
\item
  Actually, this functionality is mainly served by \textbf{Feature
  Z}\ldots{}
\item
  which is already there but hard to find.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_3-400dpi.png}
\caption{Development Process - Exposing Hidden
Risks\label{development_process_3.png}}
\end{figure}

Figure \ref{development_process_3.png} shows how this plays out.

This is a slightly contrived example, as you'll see. But let's follow
our feature through the process and see how it meets reality slowly, and
the Hidden Risks are discovered:

\hypertarget{specification}{%
\subsection{Specification}\label{specification}}

The first stage of the journey for the feature is that it meets the
Business Analyst (BA). The \emph{purpose} of the BA is to examine new
goals for the project and try to integrate them with \emph{reality as
they understands it}. A good BA might take a feature request and vet it
against his Internal Model, saying something like:

\begin{itemize}
\tightlist
\item
  ``This feature doesn't belong on the User screen, it belongs on the
  New Account screen''
\item
  ``90\% of this functionality is already present in the Document Merge
  Process''
\item
  ``We need a control on the form that allows the user to select between
  Internal and External projects''
\end{itemize}

In the process of doing this, the BA is turning the simple feature
request \emph{idea} into a more consistent, well-explained
\emph{specification} or \emph{requirement} which the developer can pick
up. But why is this a useful step in our simple methodology? From the
perspective of our Internal Model, we can say that the BA is responsible
for:

\begin{itemize}
\tightlist
\item
  Trying to surface Hidden Risks
\item
  Trying to evaluate Attendant Risks and make them clear to everyone on
  the project.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_ba-400dpi.png}
\caption{BA Specification: exposing Hidden Risks as soon as
possible\label{development_process_ba.png}}
\end{figure}

In surfacing these risks, there is another outcome: while
\textbf{Feature X} might be flawed as originally presented, the BA can
``evolve'' it into a specification, and tie it down sufficiently to
reduce the risks. The BA does all this by simply \emph{thinking about
it}, \emph{talking to people} and \emph{writing stuff down}.

This process of evolving the feature request into a requirement is the
BA's job. From our Risk-First perspective, it is \emph{taking an idea
and making it Meet Reality}. Not the \emph{full reality} of production
(yet), but something more limited.

\hypertarget{code-and-unit-test}{%
\subsection{Code And Unit Test}\label{code-and-unit-test}}

The next stage for our feature, \textbf{Feature X} is that it gets coded
and some tests get written. Let's look at how our Goal In Mind meets a
new reality: this time it's the reality of a pre-existing codebase,
which has it's own internal logic.

As the developer begins coding the feature in the software, she will
start with an Internal Model of the software, and how the code fits into
it. But, in the process of implementing it, she is likely to learn about
the codebase, and her Internal Model will develop.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_code-400dpi.png}
\caption{Coding Process: exposing more hidden risks as you
code\label{development_process_code.png}}
\end{figure}

At this point, let's stop and discuss the visual grammar of the
Risk-First Diagrams we've been looking at. A Risk-First diagram shows
what you expect to happen when you Take Action. The action itself is
represented by the shaded, sign-post-shaped box in the middle. On the
left, we have the current state of the world, on the right is the
anticipated state \emph{after} taking the action.

The round-cornered rectangles represent our Internal Model, and these
contain our view of Risk, whether the risks we face right now, or the
Attendant Risks expected after taking the action. In Figure
\ref{development_process_code.png}, taking the action of ``coding and
unit testing'' is expected to mitigate the risks of ``Developer
Misimplementation'' and ``Duplicating Functionality''.

Beneath the internal models, we are also showing real-world tangible
artifacts. That is, the physical change we would expect to see as a
result of taking action. In Figure \ref{development_process_code.png},
the action will result in ``New Code'' being added to the project,
needed for the next steps of the development process.

\hypertarget{integration}{%
\subsection{Integration}\label{integration}}

Integration is where we run \emph{all} the tests on the project, and
compile \emph{all} the code in a clean environment, collecting together
the work from the whole development team.

So, this stage is about meeting a new reality: the clean build.

At this stage, we might discover the Hidden Risk that we'd break
\textbf{Feature Y}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_integration-400dpi.png}
\caption{Integration testing exposes Hidden Risks before you get to
production\label{development_process_integration.png}}
\end{figure}

\hypertarget{user-acceptance-test}{%
\subsection{User Acceptance Test}\label{user-acceptance-test}}

Next, User Acceptance Testing (UAT) is where our new feature meets
another reality: \emph{actual users}. I think you can see how the
process works by now. We're just flushing out yet more Hidden Risks.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/development_process_uat-400dpi.png}
\caption{UAT - putting tame users in front of your software is better
than real ones, where the risk is higher
\label{development_process_uat.png}}
\end{figure}

\begin{itemize}
\tightlist
\item
  Taking Action is the \emph{only} way to create change in the world.
\item
  It's also the only way we can \emph{learn} about the world, adding to
  our Internal Model.
\item
  In this case, we discover a Hidden Risk: the user's difficulty in
  finding the feature. (The cloud obscuring the risk shows that it is
  hidden).
\item
  In return, we can \emph{expect} the process of performing the UAT to
  delay our release (this is an attendant schedule risk).
\end{itemize}

\hypertarget{observations}{%
\section{Observations}\label{observations}}

\textbf{First}, the people setting up the development process
\emph{didn't know} about these \emph{exact} risks, but they knew the
\emph{shape that the risks take}. The process builds ``nets'' for the
different kinds of Hidden Risks without knowing exactly what they are.

\textbf{Second}, are these really risks, or are they \emph{problems we
just didn't know about}? I am using the terms interchangeably, to a
certain extent. Even when you know you have a problem, it's still a risk
to your deadline until it's solved. So, when does a risk become a
problem? Is a problem still just a schedule-risk, or cost-risk? We'll
come back to this question presently.

\textbf{Third}, the real take-away from this is that all these risks
exist because we don't know 100\% how reality is. We don't (and can't)
have a perfect view of the universe and how it'll develop. Reality is
reality, \emph{the risks just exist in our head}.

\textbf{Fourth}, hopefully you can see from the above that really
\emph{all this work is risk management}, and \emph{all work is testing
ideas against reality}.

In the next chapter, we're going to look at the concept of Meeting
Reality in a bit more depth.

\hypertarget{meeting-reality-1}{%
\chapter{Meeting Reality}\label{meeting-reality-1}}

In this chapter, we will look at how exposing your Internal Model to
reality is in itself a good risk management technique.

\hypertarget{revisiting-the-model}{%
\section{Revisiting the Model}\label{revisiting-the-model}}

In A Simple Scenario, we looked at a basic model for how
\textbf{Reality} and our Internal Model interacted with each other: we
take action based on out Internal Model, hoping to \textbf{change
Reality} with some positive outcome.

And, in Development Process we looked at how we can meet with reality in
\emph{different forms}: Analysis, Testing, Integration and so on, and
saw how the model could work in each stage of a project.

It should be no surprise to see that there is a \emph{recursive} nature
about this: The actions we take each day have consequences: they expose
new hidden risks**, which inform our Internal Model, and at the same
time, they change reality in some way. As a result, we then have to take
\emph{new actions} to deal with these new risks.

So, let's see how this kind of recursion looks on our model.

\includegraphics{images/generated/introduction/model_vs_reality_2-400dpi.png}
.

\hypertarget{navigating-the-risk-landscape}{%
\section{``Navigating the Risk
Landscape''}\label{navigating-the-risk-landscape}}

Figure \ref{model_vs_reality_2.png} shows \emph{just one possible
action}, in reality, you'll have choices. We often have multiple ways of
achieving a Goal In Mind.

What's the best way?

I would argue that the best way is the one which mitigates the most
existing risk while accruing the least attendant risk to get it done.

Ideally, when you take an action, you are trading off a big risk for a
smaller one. Take Unit Testing for example. Clearly, writing Unit Tests
adds to the amount of development work, so on it's own, it adds Schedule
Risk. However, if you write \emph{just enough} of the right Unit Tests,
you should be short-cutting the time spent finding issues in the User
Acceptance Testing (UAT) stage, so you're hopefully trading off a larger
Schedule Risk from UAT and adding a smaller Schedule Risk to
Development. There are other benefits of Unit Testing too: once written,
a suite of unit tests is almost cost-free to run repeatedly, whereas
repeating a UAT is costly as it involves people's time.

You can think of Taking Action as moving your project on a ``Risk
Landscape'': ideally, when you take an action, you move to some place
with worse risk to somewhere more favourable.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/risk_landscape_1-400dpi.png}
\caption{Navigating The Risk Landscape\label{risk_landscape_1.png}}
\end{figure}

Sometimes, you can end up somewhere \emph{worse}: the actions you take
to manage a risk will leave you with worse Attendant Risks afterwards.
Almost certainly, this will have been a Hidden Risk when you embarked on
the action, otherwise you'd not have chosen it.

\hypertarget{an-example-automation}{%
\subsection{An Example: Automation}\label{an-example-automation}}

For example, \emph{automating processes} is very tempting: it
\emph{should} save time, and reduce the amount of boring, repetitive
work on a project. But sometimes, it turns into an industry in itself,
and consumes more effort than it's worth.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/risk_landscape_2_automating-400dpi.png}
\caption{Hidden Risks of
Automation\label{risk_landscape_2_automating.png}}
\end{figure}

\hypertarget{another-example-mongodb}{%
\subsection{Another Example: MongoDB}\label{another-example-mongodb}}

On a recent project in a Bank, we had a requirement to store a modest
amount of data and we needed to be able to retrieve it fast. The
developer chose to use \href{https://www.mongodb.com}{MongoDB} for this.
At the time, others pointed out that other teams in the bank had had
lots of difficulty deploying MongoDB internally, due to licensing issues
and other factors internal to the bank.

Other options were available, but the developer chose MongoDB because of
their \emph{existing familiarity} with it: therefore, they felt that the
Hidden Risks of MongoDB were \emph{lower} than the other options, and
disregarded the others' opinions.

This turned out to be a mistake: The internal bureacracy eventually
proved too great, and MongoDB had to be abandoned after much investment
of time.

This is not a criticism of MongoDB: it's simply a demonstration that
sometimes, the cure is worse than the disease. Successful projects are
\emph{always} trying to \emph{reduce} Attendant Risks.

\hypertarget{pay-off}{%
\section{Pay-Off}\label{pay-off}}

We can't know in advance how well any action we take will work out.
Therefore, Taking Action is a lot like placing a bet.

\textbf{Pay Off} then is our judgement about whether we expect an action
to be worthwhile: Are the risks we escape \emph{worth} the attendant
risks we will encounter? We should be able to \emph{weigh these separate
risks in our hands} and figure out whether the (Glossary\#pay-off) makes
a given Action worthwhile.

The fruits of this gambling are revealed when we meet reality, and we
can see whether our bets were worthwhile.

\hypertarget{the-cost-of-meeting-reality}{%
\section{The Cost Of Meeting
Reality}\label{the-cost-of-meeting-reality}}

Meeting reality \emph{in full} is costly. For example, going to
production can look like this:

\begin{itemize}
\tightlist
\item
  Releasing software
\item
  Training users
\item
  Getting users to use your system
\item
  Gathering feedback
\end{itemize}

All of these steps take a lot of effort and time. But you don't have to
meet the whole of reality in one go. But we can meet it in a limited way
which is less expensive.

In all, to de-risk, you should try and meet reality:

\begin{itemize}
\tightlist
\item
  \textbf{Sooner}, so you have time to mitigate the hidden risks it
  uncovers
\item
  \textbf{More Frequently}: so the hidden risks don't hit you all at
  once
\item
  \textbf{In Smaller Chunks}: so you're not over-burdened by hidden
  risks all in one go.
\item
  \textbf{With Feedback}: if you don't collect feedback from the
  experience of meeting reality, hidden risks \emph{stay hidden}.
\end{itemize}

In Development Process, we performed a UAT in order to Meet Reality more
cheaply and sooner. The \emph{cost} of this is that we delayed the
release to do it, adding risk to the schedule.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/meeting_reality_testing-400dpi.png}
\caption{Testing flushes out Hidden Risk, but increases Schedule
Risk\label{meeting_reality_testing.png}}
\end{figure}

\hypertarget{practice-1-yagni}{%
\section{Practice 1: YAGNI}\label{practice-1-yagni}}

As a flavour of what's to come, let's look at YAGNI, an acronym for You
Aren't Gonna Need It:

\begin{quotation}

YAGNI originally is an acronym that stands for ``You Aren't Gonna Need
It''. It is a mantra from Extreme Programming that's often used
generally in agile software teams. It's a statement that some capability
we presume our software needs in the future should not be built now
because ``you aren't gonna need it''.

\sourceatright{\href{https://www.martinfowler.com/bliki/Yagni.html}{\textemdash  YAGNI, \emph{Martin Fowler}}}
\end{quotation}

The idea makes sense: if you take on extra work that you don't need,
\emph{of course} you'll be accreting Attendant Risks.

But, there is always the opposite opinion:
\href{http://wiki.c2.com/?YouAreGonnaNeedIt}{You \emph{Are} Gonna Need
It}. As a simple example, we often add log statements in our code as we
write it (so we can trace what happened when things go wrong), though
strictly following YAGNI strictly says we shouldn't.

\hypertarget{which-is-right}{%
\subsection{Which is right?}\label{which-is-right}}

Now, we can say: do the work \emph{if there is a worthwhile Pay-Off}.

\begin{itemize}
\tightlist
\item
  Logging statements are \emph{good}, because otherwise, you're
  increasing the risk that in production, no one will be able to
  understand \emph{how the software went wrong}.
\item
  However, adding them takes time, which might introduce Schedule Risk.
\end{itemize}

So, it's a trade-off: continue adding logging statements so long as you
feel that overall, the activity pays-off reducing overall risk.

\hypertarget{practice-2-do-the-simplest-thing-that-could-possibly-work}{%
\section{Practice 2: Do The Simplest Thing That Could Possibly
Work}\label{practice-2-do-the-simplest-thing-that-could-possibly-work}}

Another mantra from Kent Beck (originator of the
\href{https://en.wikipedia.org/wiki/Extreme_programming}{Extreme
Programming} methodology), is ``Do The Simplest Thing That Could
Possibly Work'', which is closely related to YAGNI and is an excellent
razor for avoiding over-engineering. At the same time, by adding ``Could
Possibly'', Kent is encouraging us to go beyond straightforward
iteration, and use our brains to pick apart the simple solutions,
avoiding them if we can logically determine when they would fail.

Our risk-centric view of this strategy would be:

\begin{itemize}
\tightlist
\item
  Every action you take on a project has it's own Attendant Risks.
\item
  The bigger or more complex the action, the more Attendant Risk it'll
  have.
\item
  The reason you're taking action \emph{at all} is because you're trying
  to reduce risk elsewhere on the project
\item
  Therefore, the biggest Pay-Off is likely to be the one with the least
  Attendant Risk.
\item
  So, usually this is going to be the simplest thing.
\end{itemize}

So, ``Do The Simplest Thing That Could Possibly Work'' is really a
helpful guideline for Navigating the Risk Landscape, but this analysis
shows clearly where it's left wanting:

\begin{itemize}
\tightlist
\item
  \emph{Don't} do the simplest thing if there are other things with a
  better Pay-Off available.
\end{itemize}

\hypertarget{summary}{%
\section{Summary}\label{summary}}

So, here we've looked at Meeting Reality, which basically boils down to
taking actions to manage risk and seeing how it turns out:

\begin{itemize}
\tightlist
\item
  Each Action you take is a step on the Risk Landscape
\item
  Each Action exposes new Hidden Risks, changing your Internal Model.
\item
  Ideally, each action should reduce the overall Attendant Risk on the
  project (that is, puts it in a better place on the Risk Landscape
\end{itemize}

Could it be that \emph{everything} you do on a software project is risk
management? This is an idea explored in the next chapter.

\hypertarget{all-risk-management}{%
\chapter{All Risk Management}\label{all-risk-management}}

In this chapter, I am going to propose the idea that everything you do
on a software project is Risk Management.

In the last chapter, we observed that all the activities in a simple
methodology had a part to play in exposing different risks. They worked
to manage risk prior to them creating bigger problems in production.

Here, we'll look at one of the tools in the Project Manager's tool-box,
the \href{http://pmtips.net/blog-new/raid-logs-introduction}{RAID Log},
and observe how risk-centric it is.

\hypertarget{raid-log}{%
\section{RAID Log}\label{raid-log}}

Many project managers will be familiar with the RAID Log. It's simply
four columns on a spreadsheet: \textbf{Risks}, \textbf{Actions},
\textbf{Issues} and \textbf{Decisions}.

Let's try and put the following Risk into the RAID Log:

\begin{quotation}

``Debbie needs to visit the client to get them to choose the logo to use
on the product, otherwise we can't size the screen areas exactly.''

\end{quotation}

\begin{itemize}
\tightlist
\item
  So, is this an \textbf{action}? Certainly. There's definitely
  something for Debbie to do here.
\item
  Is it an \textbf{issue}? Yes, because it's holding up the screen-areas
  sizing thing.
\item
  Is it a \textbf{decision}? Well, clearly, it's a decision for someone.
\item
  Is it a \textbf{risk}? Probably: Debbie might go to the client and
  they \emph{still} don't make a decision. What then?
\end{itemize}

\hypertarget{lets-go-again}{%
\section{Let's Go Again}\label{lets-go-again}}

This is a completely made-up example, deliberately chosen to be hard to
categorise. Normally, items are more one thing than another. But often,
you'll have to make a choice between two categories, if not all four.

This \emph{hints} at the fact that at some level it's all about risk:

\hypertarget{every-action-attempts-to-mitigate-risk}{%
\section{Every Action Attempts to Mitigate
Risk}\label{every-action-attempts-to-mitigate-risk}}

The reason you are \emph{taking} an action is to mitigate a risk. For
example:

\begin{itemize}
\tightlist
\item
  If you're coding up new features in the software, this is mitigating
  Feature Risk (which we'll explore in more detail later).
\item
  If you're getting a business sign-off for something, this is
  mitigating the risk of everone not agreeing on a course of action (a
  Coordination Risk).
\item
  If you're writing a specification, that's mitigating the type of
  ``Developer Misimplementation Risk'' we saw in the last chapter.
\end{itemize}

\hypertarget{every-action-has-attendant-risk.}{%
\section{Every Action Has Attendant
Risk.}\label{every-action-has-attendant-risk.}}

\begin{itemize}
\tightlist
\item
  How do you know if the action will get completed?
\item
  Will it overrun, or be on time?
\item
  Will it lead to yet more actions?
\item
  What Hidden Risk will it uncover?
\end{itemize}

Consider \emph{coding a feature} (as we did in the earlier Development
Process chapter). We saw here how the whole process of coding was an
exercise in learning what we didn't know about the world, uncovering
problems and improving our Internal Model. That is, flushing out the
Attendant Risk of the Goal In Mind.

And, as we saw in the Introduction, even something \emph{mundane} like
the Dinner Party had risks.

\hypertarget{an-issue-is-just-a-type-of-risk}{%
\section{An Issue is Just A Type of
Risk}\label{an-issue-is-just-a-type-of-risk}}

\begin{itemize}
\tightlist
\item
  Because issues need to be fixed\ldots{}
\item
  And fixing an issue is an action\ldots{}
\item
  Which, as we just saw also carry risk.
\end{itemize}

One retort to this might be to say: ``An issue is a problem I have now,
whereas a risk is a problem that \emph{might} occur.'' I am going to try
and break that mind-set in the coming pages, but I'll just start with
this:

\begin{itemize}
\tightlist
\item
  Do you know \emph{exactly} how much damage this issue will do?
\item
  Can you be sure that the issue might not somehow go away?
\end{itemize}

\emph{Issues} then, just seem more ``definite'' and ``now'' than
\emph{risks}, right? This classification is arbitrary: they're all just
part of the same spectrum, they all have inherent uncertainty, so there
should be no need to agonise over which column to put them in.

\hypertarget{goals-are-risks-too}{%
\section{Goals Are Risks Too}\label{goals-are-risks-too}}

In the previous chapters, we've introduced something of a ``diagram
language'' of risk. Let's review it:

\begin{figure}
\centering
\includegraphics{images/generated/introduction/all_risk_management_language-400dpi.png}
\caption{Risk-First Diagram
Language\label{all_risk_management_language.png}}
\end{figure}

Goals live inside our Internal Model, just like Risks. It turns out,
that functionally, Goals and Risks are equivalent. For example, The Goal
of ``Implementing Feature X'' is equivalent to mitigating ``Risk of
Feature X not being present''.

Let's try and back up that assertion with a few more examples:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.32\columnwidth}\raggedright
Goal\strut
\end{minipage} & \begin{minipage}[b]{0.62\columnwidth}\raggedright
Restated As A Risk\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.32\columnwidth}\raggedright
Build a Wall\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
Mitigate the risk of something getting in / out\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.32\columnwidth}\raggedright
Land a man on the moon\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
Mitigate the risk of looking technically inferior during the cold
war\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.32\columnwidth}\raggedright
Move House\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
Mitigate the risks/problems of where you currently live\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

There is a certain ``interplay'' between the concepts of risks, actions
and goals. After all, on the Risk Landscape they correspond to a
starting point, a movement, and a destination. From a redundancy
perspective, any one of these can be determined by knowing the other
two.

Psychologically, humans are very goal-driven: they like to know where
they're going, and are good at organising around a goal. However, by
focusing on goals (``solutionizing'') it's easy to ignore alternatives.
By focusing on ``Risk-First'', we don't ignore the reasons we're doing
something.

\hypertarget{every-decision-is-about-pay-off.}{%
\section{Every Decision is About
Pay-Off.}\label{every-decision-is-about-pay-off.}}

\begin{itemize}
\tightlist
\item
  By the very nature of having to make a decision, there's the risk
  you'll decide wrongly.
\item
  And, making a decision takes time, which could add risk to your
  schedule.
\item
  And what's the risk if the decision doesn't get made?
\end{itemize}

Sometimes, there will be multiple moves available on the Risk Landscape
and you have to choose. Let's take a hypothetical example: You're on a
project and you're faced with the decision - release now or do more
testing?

Obviously, in the ideal world, we want to get to the place on the Risk
Landscape where we have a tested, bug-free system in production. But
we're not there yet, and we have funding pressure to get the software
into the hands of some paying customers. The table below shows an
example:

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.19\columnwidth}\raggedright
Risk Managed\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright
Action\strut
\end{minipage} & \begin{minipage}[b]{0.35\columnwidth}\raggedright
Attendant Risk\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright
Pay-Off\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.19\columnwidth}\raggedright
Funding Risk\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Go Live\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Reputational Risk, Operational Risk\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
MEDIUM\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright
Implementation Risk\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
User Acceptance Test\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Worse Funding Risk, Operational Risk\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
LOW\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

This is (a simplification of) the dilemma on lots of software projects -
\emph{test further}, to reduce the risk of users discovering bugs
(Implementation Risk) which would cause us reputational damage, or
\emph{get the release done} and reduce our Funding Risk by getting
paying clients sooner.

In the above table, it \emph{appears} to be better to do the ``Go Live''
action, as there is a greater Pay Off. The problem is, actions are not
\emph{commutative}, i.e.~the order you do them in counts.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/risk_landscape_3_moves-400dpi.png}
\caption{UAT or Go Live: Where will you end
up?\label{risk_landscape_3_moves.png}}
\end{figure}

Figure \ref{risk_landscape_3_moves.png} shows our decision as
\emph{moves on the Risk Landscape}. Whether you ``Go Live'' first, or
``UAT'' first makes a difference to where you will end up. Is there a
further action you can take to get you from the ``Dead End'' to the
``Goal''? Perhaps.

\hypertarget{failure}{%
\subsection{Failure}\label{failure}}

So, when we talk about a project ``failing'', what do we mean?

Usually, we mean we've failed to achieve a goal, and since \emph{goals
are risks}, it is simply the scenario where we are overwhelmed by
Attendant Risks: there is \emph{no} action to take that has a
good-enough Pay Off to get us out of our hole.

\hypertarget{what-to-do}{%
\section{What To Do?}\label{what-to-do}}

It makes it much easier to tackle the RAID log if there's only one list.
But you still have to choose a \emph{strategy}: Do you tackle the
\emph{most important} risk on the list, or the \emph{most urgent}, or
take the action with the biggest Pay Off and deal with it?

In the next chapter, Evaluating Risk we'll look at some approaches to
choosing what to do.

\hypertarget{evaluating-risk}{%
\chapter{Evaluating Risk}\label{evaluating-risk}}

Here, I am going to re-cap on some pre-existing risk management theory
in order to set the scene for the next chapter which heads back to
looking at risk on software projects.

\hypertarget{risk-registers}{%
\section{Risk Registers}\label{risk-registers}}

Most developers are familiar with recording issues in an issue tracker.
For all of the same reasons, it's good practice to record the risks you
face running a project or an operation in a
\href{https://en.wikipedia.org/wiki/Risk_register}{Risk Register}.
Typically, this will include for each risk:

\begin{itemize}
\tightlist
\item
  The \textbf{name} of the risk, or other identifier.
\item
  A \textbf{categories} to which the risk belongs (this is the focus of
  the Risk Landscape chapter in Part 2).
\item
  A \textbf{brief description} or name of the risk to make the risk easy
  to discuss
\item
  Some estimate for the \textbf{Impact}, \textbf{Probability} or
  \textbf{Risk Score} of the risk.
\item
  Proposed actions and a log of the progress made to manage the risk.
\end{itemize}

Some points about this description:

\hypertarget{a-continuum-of-formality}{%
\subsection{A Continuum of Formality}\label{a-continuum-of-formality}}

Remember back to the Dinner Party example at the start: the Risk
Register happened \emph{entirely in your head}. There is a continuum all
the way from ``in your head'' through ``using a spreadsheet'' to
dedicated Risk Management software.

It's also going to be useful \emph{in conversation}, and this is where
the value of the Risk-First approach is: providing a vocabulary to
\emph{talk about risks} with your team.

\hypertarget{probability-and-impact}{%
\subsection{Probability And Impact}\label{probability-and-impact}}

\textbf{Probability} is how likely something is to happen, whilst
\textbf{Impact} is the cost (usually financial) when it does happen.

In a financial context (or a gambling one), we can consider the overall
\textbf{Risk Score} as being the sum of the \textbf{Impact} of each
outcome multiplied by it's \textbf{Probability}. For example, if you buy
a 1-Euro ticket in a raffle, there are two outcomes: win or lose. The
impact of \emph{winning} would be (say) a hundred Euros, but the
\textbf{probability} might be 1 in 200. The impact of \emph{losing}
would be the loss of 1 Euro, with

\begin{longtable}[]{@{}llll@{}}
\toprule
Outcome & Impact & Probabilty & Risk Score\tabularnewline
\midrule
\endhead
Win & + 99 EUR & 1 in 200 & .5 EUR\tabularnewline
Lose & - 1 EUR & 199 in 200 & -.99 EUR\tabularnewline
\bottomrule
\end{longtable}

Risk Management in the finance industry \emph{starts} here, and gets
more complex, but often (especially on a software project), it's better
to skip all this, and just figure out a Risk Score. This is because if
you think about ``impact'', it implies a definite, discrete event
occurring, or not occurring, and asks you then to consider the
probability of that occurring.

Risk-First takes a view that risks are a continuous quantity, more like
\emph{money} or \emph{water}: by taking an action before delivering a
project you might add a degree of Schedule Risk, but decrease the
Operational Risk later on by a greater amount.

\hypertarget{risk-matrix}{%
\section{Risk Matrix}\label{risk-matrix}}

A risk matrix presents a graphical view on where risks exist. Here is an
example, showing the risks from the dinner party in the A Simple
Scenario chapter:

\begin{figure}
\centering
\includegraphics{images/generated/introduction/risk_matrix-400dpi.png}
\caption{Risk Register of Dinner Party Risks\label{risk_matrix.png}}
\end{figure}

This type of graphic is \emph{helpful} in deciding what to do next,
although alternatively, you can graph the overall \textbf{Risk Score}
against the Pay-Off. Easily mitigated risk (on the right), and worse
risks (at the top) can therefore be dealt with first (hopefully).

\begin{figure}
\centering
\includegraphics{images/generated/introduction/risk_matrix_2-400dpi.png}
\caption{Risk Register of Dinner Party Risks, Considering
Pay-Off\label{risk_matrix_2.png}}
\end{figure}

\hypertarget{unknown-unknowns}{%
\section{Unknown Unknowns}\label{unknown-unknowns}}

One of the criticisms of the Risk Register approach is that of mistaking
the map for the territory. That is, mistakenly believing that what's on
the Risk Register \emph{is all there is}.

In the preceding discussions, I have been careful to point out the
existence of Hidden Risks for that very reason. Or, to put another way:

\begin{quotation}

``What we don't know is what usually gets us killed''

\sourceatright{\href{https://medium.com/@TanyaMardi/petyr-baelishs-best-quotes-on-game-of-thrones-1ea92968db5c}{\textemdash  Petyr Baelish, \emph{Game of Thrones}}}
\end{quotation}

Donald Rumsfeld's famous Known Knowns is also a helpful
conceptualisation:

\begin{itemize}
\tightlist
\item
  \textbf{A \emph{known} unknown} is an Attendant Risk. i.e.~something
  you are aware of, but where the precise degree of threat can't be
  established.
\item
  \textbf{An \emph{unknown} unknown} is a Hidden Risk. i.e a risk you
  haven't even thought to exist yet.
\end{itemize}

\hypertarget{risk-and-uncertainty}{%
\section{Risk And Uncertainty}\label{risk-and-uncertainty}}

Arguably, this site uses the term `Risk' wrongly: most literature
suggests
\href{https://keydifferences.com/difference-between-risk-and-uncertainty.html}{risk
can be measured} whereas uncertainty represents things that cannot.

I am using \textbf{risk} everywhere because later we will talk about
specific risks (e.g.~Boundary Risk or Complexity Risk), and it doesn't
feel grammatically correct to talk about those as
\textbf{uncertainties}, especially given the pre-existing usage in
Banking of terms like
\href{https://en.wikipedia.org/wiki/Operational_risk}{Operational Risk}
or
\href{https://www.investopedia.com/terms/r/reputational-risk.asp}{Reputational
risk} which are also not really a-priori measurable.

\hypertarget{the-opposite-of-risk-management}{%
\section{The Opposite Of Risk
Management}\label{the-opposite-of-risk-management}}

Let's look at the classic description of Risk Management:

\begin{quotation}

``Risk Management is the process of thinking out corrective actions
before a problem occurs, while it's still an abstraction. The opposite
of risk management is crisis management, trying to figure out what to do
about the problem after it happens.''

\sourceatright{\href{http://amzn.eu/d/i0IDFA2}{\textemdash  Waltzing With Bears, \emph{De Marco, Lister}}}
\end{quotation}

This is not how Risk-First sees it:

First, we have the notion that Risks are discrete events, again. Some
risks \emph{are} (like gambling on a horse race), but most
\emph{aren't}. In the Dinner Party, for example, bad preparation is
going to mean a \emph{worse} time for everyone, but how good a time
you're having is a spectrum, it doesn't divide neatly into just ``good''
or ``bad''.

Second, the opposite of ``Risk Management'' (or trying to minimise the
``Down-side'') is either ``Upside Risk Management'', (trying to maximise
the good things happening), or it's trying to make as many bad things
happen as possible.

Third, Crisis Management is \emph{still just Risk Management}: the
crisis (Earthquake, whatever) has \emph{happened}. You can't manage it
because it's in the past. All you can do is Risk Manage the future
(minimize further casualties and human suffering, for example).

Yes, it's fine to say ``we're in crisis'', but to assume there is a
different strategy for dealing with it is a mistake: this is the
\href{https://en.wikipedia.org/wiki/Escalation_of_commitment}{Fallacy of
Sunk Costs}.

\hypertarget{invariances-1-panic-invariance}{%
\section{Invariances \#1: Panic
Invariance}\label{invariances-1-panic-invariance}}

You would expect then, that any methods for managing software delivery
should be \emph{invariant} to the level of crisis in the project. If,
for example, a project proceeds using
\href{https://en.wikipedia.org/wiki/Scrum_(software_development)}{Scrum}
for eight months, and then the deadline looms and everyone agrees to
throw Scrum out of the window and start hacking, then \emph{this implies
there is a problem with Scrum}, and that it is not \emph{Panic
Invariant}. In fact, many tools like Scrum don't consider this:

\begin{itemize}
\tightlist
\item
  If there is a production outage during the working week, we don't wait
  for the next Scrum Sprint to fix it.
\item
  Although a 40-hour work-week \emph{is a great idea}, this goes out of
  the window if the databases all crash on a Saturday morning.
\end{itemize}

In these cases, we (hopefully calmly) \emph{evaluate the risks and Take
Action}.

This is \textbf{Panic Invariance}: your methodology shouldn't need to
change given the amount of pressure or importance on the table.

\hypertarget{invariances-2-scale-invariance}{%
\section{Invariances \#2: Scale
Invariance}\label{invariances-2-scale-invariance}}

Another test of a methodology is that it shouldn't fall down when
applied at different \emph{scales}. Because, if it does, this implies
that there is something wrong with the methodology. The same is true of
physical laws: if they don't apply under all circumstances, then that
implies something is wrong. For example, Newton's Laws of Motion fail to
calculate the orbital period of Mercury, which led to Einstein trying to
improve on them with the
\href{https://en.wikipedia.org/wiki/Theory_of_relativity}{Theory of
Relativity}.

Some methodologies are designed for certain scales: Extreme Programming
is designed for small, co-located teams. And, that's useful. But the
fact it doesn't scale tells us something about it: chiefly, that it
considers certain \emph{kinds} of risk, while ignoring others. At small
scales, that works ok, but at larger scales, other risks (such as team
Coordination Risk) increase too fast for it to work.

So ideally, a methodology should be applicable at \emph{any} scale:

\begin{itemize}
\tightlist
\item
  A single class or function
\item
  A collection of functions, or a library
\item
  A project team
\item
  A department
\item
  An entire organisation
\end{itemize}

If the methodology \emph{fails at a particular scale}, this tells you
something about the risks that the methodology isn't addressing. It's
fine to have methodologies that work at different scales, and on
different problems. One of the things Risk-First explores is trying to
place methodologies and practices within a framework to say \emph{when}
they are applicable.

\hypertarget{value-vs-speed}{%
\section{Value vs Speed}\label{value-vs-speed}}

\hypertarget{upside-risk}{%
\subsection{``Upside Risk''}\label{upside-risk}}

``Upside Risk'' isn't a commonly used term: industry tends to prefer
``value'', as in ``Is this a value-add project?''. There is plenty of
theory surrounding \textbf{Value}, such as Porter's
\href{https://en.wikipedia.org/wiki/Value_chain}{Value Chain} and
\href{https://en.wikipedia.org/wiki/Net_present_value}{Net Present
Value}. This is all fine so long as we remember:

\begin{itemize}
\tightlist
\item
  \textbf{The probability of Pay-Off is risky}: Since the value is
  created in the future, we can't be certain about it happening - we
  should never consider it a done-deal. \textbf{Future Value} is always
  at risk. In finance, for example, we account for this in our future
  cash-flows by discounting them according to the risk of default.
\item
  \textbf{The Pay-Off amount is risky}: Additionally, whereas in a
  financial transaction (like a loan, say), we might know the size of a
  future payment, in IT projects we can rarely be sure that they will
  deliver a certain return. On some fixed-contract projects this
  sometimes is not true: there may be a date when the
  payment-for-delivery gets made, but mostly we'll be expecting an
  uncertain pay-off.
\item
  Humans tend to be optimists (especially when there are lots of Hidden
  Risks), hence our focus on Downside Risk. Sometimes though, it's good
  to stand back and look at a scenario and think: am I capturing all the
  Upside Risk here?
\end{itemize}

\hypertarget{speed}{%
\subsection{Speed}\label{speed}}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/pillars_smc-400dpi.png}
\caption{Pillars, From Rapid Development By Steve
McConnell\label{pillars_smc.png}}
\end{figure}

Figure \ref{pillars_smc.png} reproduces a figure from
\href{http://a.co/d/ddWGTB2}{Rapid Development} by Steve McConnell. This
is \emph{fine}, McConnell is structuring the process from the
perspective of \emph{delivering as quickly as possible}. However, here,
I want to turn this on it's head. Software Development from a risk-first
perspective is an under-explored technique, and I believe it offers some
useful insights. So the aim here is to present the case for viewing
software development like this:

\begin{figure}
\centering
\includegraphics{images/generated/introduction/pillars_kite9-400dpi.png}
\caption{Pillars, re-arranged\label{pillars_kite9.png}}
\end{figure}

As we will see, \emph{Speed} (or Schedule Risk as we will term it) is
one risk amongst others that need to be considered from a
risk-management perspective. There's no point in prioritising
\emph{speed} if the software fails in production due to Operational Risk
issues and damages trust in the product.

\hypertarget{eisenhowers-box}{%
\subsection{Eisenhower's Box}\label{eisenhowers-box}}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/eisenhowers_box.png}
\caption{A basic ``Eisenhower box'' to help evaluate urgency and
importance. Items may be placed at more precise points within each
quadrant. - Adapted From
\href{https://en.wikipedia.org/wiki/Time_management}{Time Management,
\emph{Wikipedia}}}
\end{figure}

Eisenhower's Box is a simple model allowing us to consider \emph{two}
aspects of risk at the same time:

\begin{itemize}
\tightlist
\item
  How valuable the work is (Importance, Value).
\item
  How soon it is needed (Urgency, Time).
\end{itemize}

The problem is, we now need to take a call on whether to do something
that is \emph{urgent} or something that is \emph{important}.

\hypertarget{discounting}{%
\section{Discounting}\label{discounting}}

Net Present Value allows us to discount value in the future, which
offers us a way to reconcile these two variables. The further in the
future the value is realised, the bigger the discount. This is done
because payment \emph{now} is better than payment in the future: there
is the risk that something will happen to prevent that future payment.
This is why we have \emph{interest rates} on loan payments.

\begin{figure}
\centering
\includegraphics{images/numbers/npv.png}
\caption{Net Present Value Discounting\label{npv.png}}
\end{figure}

In Figure \ref{npv.png}, you can see two future payments, Payment
\textbf{A} of \pounds100 due in one year, and Payment \textbf{B} of
\pounds150 due in 10 years. By discounting at a given rate (here at a
high rate of 20\% per year) we can compare their worth \emph{now}. At
this discount rate, Payment \textbf{A}, - arriving next year - has a far
greater value.

Can we do the same thing with risk? Let's introduce the concept of
\textbf{Net Present Risk}, or NPR:

\begin{quotation}

Net Present Risk is the \emph{Impact} of a Future risk, discounted to a
common level of \emph{Urgency}.

\end{quotation}

Let's look at a quick example to see how this could work out. Let's say
you had the following risks:

\begin{itemize}
\tightlist
\item
  Risk \textbf{A}, which will cost you \pounds50 in 5 day's time.
\item
  Risk \textbf{B}, which will cost you \pounds70 in 8 day's time.
\end{itemize}

Which has the biggest NPR? Well, it depends on the discount rate that
you apply. Let's assume we are discounting at 6\% per \emph{day}. A
graph of the discounted risks looks like this:

\begin{figure}
\centering
\includegraphics{images/numbers/npr1.png}
\caption{Net Present Risk, 6\% Discount Rate\label{npr1.png}}
\end{figure}

On this basis, the biggest NPR is \textbf{B}, at about \pounds45. If we
increase the discount factor to 20\%, we get a different result:

\begin{figure}
\centering
\includegraphics{images/numbers/npr2.png}
\caption{Net Present Risk, 20\% Discount Rate\label{npr2.png}}
\end{figure}

Now, risk \textbf{A} is bigger.

Because this is \emph{Net} Present Risk, we can also use it to make
decisions about whether or not to mitigate risks. Let's assume the cost
of mitigating any risk \emph{right now} is \pounds40. Under the 6\%
regime, only Risk \textbf{B} is worth mitigating today, because you
spend \pounds40 today to get rid of \pounds45 of risk (today).

Under the 20\% regime, neither are worth mitigating. The 20\% Discount
Rate may reflect that sometimes, future risks just don't materialise.

\hypertarget{discounting-the-future-to-zero}{%
\subsection{Discounting the Future To
Zero}\label{discounting-the-future-to-zero}}

I have worked in teams sometimes where the blinkers go down, and the
only thing that matters is \emph{now}. Anything with a horizon over a
week is irrelevant. Regimes of such
\href{https://en.wikipedia.org/wiki/Hyperinflation}{hyper-inflation} are
a sure sign that something has \emph{really broken down} within a
project. Consider in this case a Discount Factor of 60\% per day, and
the following risks:

\begin{itemize}
\tightlist
\item
  Risk A: \pounds10 cost, happening \emph{tomorrow}
\item
  Risk B: \pounds70 cost, happening in \emph{5 days}.
\end{itemize}

Risk B is almost irrelevant under this regime, as this graph shows:

\begin{figure}
\centering
\includegraphics{images/numbers/npr3.png}
\caption{Net Present Risk, 60\% Discount Rate\label{npr3.png}}
\end{figure}

Why do things like this happen? Often, the people involved are under
incredible job-stress: usually they are threatened on a daily basis, and
therefore feel they have to react. In a similar way, publicly-listed
companies also often apply short-term focus, because they only care
about the \emph{next annual report}, which limits their horizons and
ability to consider future risk.

Under these circumstances, we often see \emph{Pooh-Bear
Procrastination}:

\begin{quotation}

``Here is Edward Bear coming downstairs now, bump, bump, bump, on the
back of his head, behind Christopher Robin. It is, as far as he knows,
the only way of coming downstairs, but sometimes he feels that there
really is another way\ldots{}if only he could stop bumping for a moment
and think of it!''

\sourceatright{\href{http://amzn.eu/d/acJ5a2j}{\textemdash  A. A. Milne, \emph{Winne-the-Pooh}}}
\end{quotation}

\hypertarget{is-this-scientific}{%
\section{Is This Scientific?}\label{is-this-scientific}}

Enough with the numbers and the theory: Risk-First is an attempt to
provide a practical framework, rather than a scientifically rigorous
analysis. For software development, you should probably \emph{give up}
on trying to compute risk numerically. You \emph{can't} work out how
long a software project will take based purely on an analysis of (say)
\emph{function points}. (Whatever you define them to be).

\begin{itemize}
\tightlist
\item
  First, there isn't enough scientific evidence for an approach like
  this. We \emph{can} look at collected data about IT projects, but
  techniques and tools advance rapidly.
\item
  Second, IT projects have too many confounding factors, such as
  experience of the teams, technologies used etc. That is, the risks
  faced by IT projects are \emph{too diverse} and \emph{hard to
  quantify} to allow for meaningful comparison from one to the next.
\item
  Third, as soon as you \emph{publish a date} it changes the
  expectations of the project (see Student Syndrome).
\item
  Fourth, metrics get misused and gamed (as we will see in a later
  chapter).
\end{itemize}

Reality is messy. Dressing it up with numbers doesn't change that and
you risk fooling yourself. If this is the case, is there any hope at all
in what we're doing? Yes: \emph{forget precision}. You should, with
experience be able to hold up two separate risks and answer the
question, ``is this one bigger than this one?''

With that in mind, let's look at how we can meet reality as fast and
often as possible.

\hypertarget{cadence}{%
\chapter{Cadence}\label{cadence}}

Let's go back to the model again, introduced in Meeting Reality:

\begin{figure}
\centering
\includegraphics{images/generated/introduction/model_vs_reality_2-400dpi.png}
\caption{Meeting Reality: reality is changed and so is your internal
model.\label{model_vs_reality_2.png}}
\end{figure}

As you can see, it's an idealized \textbf{Feedback Loop}.

How \emph{fast} should we go round this loop? The longer you leave your
goal in mind, the longer it'll be before you find out how it really
stacks up against reality.

Testing your goals in mind against reality early and safely is how
you'll manage risk effectively, and to do this, you need to set up
\textbf{Feedback Loops}. e.g.

\begin{itemize}
\tightlist
\item
  \textbf{Bug Reports and Feature Requests} tell you how the users are
  getting on with the software.
\item
  \textbf{Monitoring Tools and Logs} allow you to find out how your
  software is doing in reality.
\item
  \textbf{Dog-Fooding} i.e using the software you write yourself might
  be faster than talking to users.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Continuous_delivery}{Continuous
  Delivery}} is about putting software into production as soon as it's
  written.
\item
  \textbf{Integration Testing} is a faster way of meeting \emph{some}
  reality than continually deploying code and re-testing it manually.
\item
  \textbf{Unit Testing} is a faster feedback loop than Integration
  Testing.
\item
  \textbf{Compilation} warns you about logical inconsistencies in your
  code.
\end{itemize}

.. and so on.

\hypertarget{time-reality-trade-off}{%
\subsection{Time / Reality Trade-Off}\label{time-reality-trade-off}}

This list is arranged so that at the top, we have the most visceral,
most \emph{real} feedback loop, but at the same time, the slowest.

At the bottom, a good IDE can inform you about errors in your Internal
Model in real time, by way of highlighting compilation errors . So, this
is the fastest loop, but it's the most \emph{limited} reality.

Imagine for a second that you had a special time-travelling machine.
With it, you could make a change to your software, and get back a report
from the future listing out all the issues people had faced using it
over its lifetime, instantly.

That'd be neat, eh? If you did have this, would there be any point at
all in a compiler? Probably not, right?

The whole \emph{reason} we have tools like compilers is because they
give us a short-cut way to get some limited experience of reality
\emph{faster} than would otherwise be possible. Because, cadence is
really important: the faster we test our ideas, the more quickly we'll
find out if they're correct or not.

\hypertarget{development-cycle-time}{%
\subsection{Development Cycle Time}\label{development-cycle-time}}

Developers often ignore the fast feedback loops at the bottom of the
list above, because the ones nearer the top \emph{will do}. In the worst
cases, changing two lines of code, running the build script, deploying
and then manually testing out a feature. And then repeating.

If you're doing it over and over, this is a terrible waste of time. And,
you get none of the benefit of a permanent suite of tests to run again
in the future.

The
\href{http://www.agilenutshell.com/episodes/41-testing-pyramid}{Testing
Pyramid} hints at this truth:

\begin{itemize}
\tightlist
\item
  \textbf{Unit Tests} have a \emph{fast feedback loop}, so have
  \emph{lots of them}.
\item
  \textbf{Integration Tests} have a slightly \emph{slower feedback
  loop}, so have \emph{few of them}. Use them when you can't write unit
  tests (at the application boundaries).
\item
  \textbf{Manual Tests} have a \emph{very slow feedback loop}, so have
  \emph{even fewer of them}. Use them as a last resort.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/testing_pyramid-400dpi.png}
\caption{The Testing Pyramid\label{testing_pyramid.png}}
\end{figure}

\hypertarget{production}{%
\subsection{Production}\label{production}}

You could take this chapter to mean that Continuous Delivery (CD) is
always and everywhere a good idea. That's not a bad take-away, but it's
clearly more nuanced than that.

Yes, CD will give you faster feedback loops, but even getting things
into production is not the whole story: the feedback loop isn't complete
until people have used the code, and reported back to the development
team.

The right answer is to use multiple feedback loops:

\begin{figure}
\centering
\includegraphics{images/generated/introduction/cadence-400dpi.png}
\caption{Different actions have different feedback
loops\label{cadence.png}}
\end{figure}

In the next chapter De-Risking we're going to introduce a few more
useful terms for thinking about risk.

\hypertarget{de-risking}{%
\chapter{De Risking}\label{de-risking}}

It's important not only to consider the Attendant Risks you're trying to
mitigate, but the ones you're likely to pick up in the process. This
means picking a careful path through the Risk Landscape. This is the
essence of \emph{De-Risking}.

\begin{quotation}

``To take steps to make (something) less risky or less likely to involve
a financial loss.''

\sourceatright{\href{https://en.oxforddictionaries.com/definition/de-risk}{\textemdash  De-Risk,\emph{OxfordDictionaries.com}}}
\end{quotation}

Some simple examples of this might be:

\begin{itemize}
\tightlist
\item
  \textbf{Safety-nets and ropes} de-risk climbing. But, the activity of
  climbing itself is otherwise much unchanged.
\item
  \textbf{Backups and Source-Control} de-risk the development process by
  reducing the impact of computer failure. Our process is changed
  \emph{slightly} by this imposition, but we're not massively
  inconvenienced.
\item
  \textbf{Insurance} de-risks owning a house, going on holiday or
  driving a car. Usually, the payment is small enough not to impact us
  too much.
\item
  \textbf{The National Health Service (NHS)} de-risks medical expense by
  pooling health-care costs across the entire population. If you were
  struck down with a debilitating illness, then at least you wouldn't
  also have to pay to get better.
\end{itemize}

Let's look at some common strategies for De-Risking.

\hypertarget{mitigate}{%
\section{Mitigate}\label{mitigate}}

\textbf{Mitigating} the risk is taking steps towards minimising either
it's likelihood or impact (as we discussed in the Evaluating Risk
chapter). This is the main approach we will be looking at in Part 2.
We'll break down risk into its different types and look at the general
mitigations for each. The examples above of De-Risking were all
mitigations. (Safety-nets, for example, mitigate the impact of hitting
the ground.)

\hypertarget{avoid}{%
\section{Avoid}\label{avoid}}

\textbf{Avoiding} a risk, means taking a route on the Risk Landscape
\emph{around} the risk. For example, if you are working in a team which
has no experience of relational databases, then \emph{storing data in
files} might be a way to avoid the Learning-Curve Risk associated with
this technology.

Of course, you may pick up other, more serious Attendant Risks as a
result: Relational Databases are software solutions to many kinds of
Coordination Risk problem.

\emph{Not} launching an online service \emph{avoids} the Operational
Risk involved in running one. Although you avoid the upsides too.

\hypertarget{transfer}{%
\section{Transfer}\label{transfer}}

\textbf{Transferring} risk means \emph{making it someone else's
problem}. For example, when I buy home insurance, the impact of my house
burning down is reduced. It hasn't gone away completely, but at least
the financial element of it is handled by the insurance company.

In part 2, we'll see how \textbf{Transfer} of risk is an essential
feature of Software as a Service. Inside organisations,
\textbf{Transfer} of risk can become a political game:

\begin{quotation}

``\ldots{} ownership results in `one throat to choke' for audit
functions {[}and{]} from ownership comes responsibility. A lot of the
political footwork in an enterprise revolves around trying to not own
technologies. Who wants to be responsible for Java usage across a
technology function of dozens of thousands of staff, any of whom might
be doing crazy stuff? You first, mate.''

\sourceatright{\href{https://zwischenzugs.com/2018/10/02/why-are-enterprises-so-slow/}{\textemdash  Why Are Enterprises So Slow?, \emph{zwischenzugs.com}}}
\end{quotation}

\hypertarget{ignore-accept}{%
\section{Ignore / Accept}\label{ignore-accept}}

\textbf{Accepting} a risk is to deal with it when it arises. One example
is the Key-Man Risk involved in having a super-star programmer on the
team. Although there would be fallout if they left, they are often
mitigating more risk than they cause.

Another example is using particular software dependencies: Building a
mobile application which requires a Facebook account to log in might
give rise to the risk that people without Facebook accounts can't log
in, but might simplify the software to such an extent that it's
worthwhile.

Whereas \textbf{Accepting} a risk seems to imply an eyes-wide-open
examination, \textbf{Ignoring} seems to imply that either the risk is so
insignificant it doesn't warrant evaluation, or so daunting that it
can't be stared down. Either way, \textbf{Ignoring} a risk amounts to
the same thing as \textbf{Accepting} it, since you're not doing anything
about it.

\textbf{Accepting} a risk has to occur \emph{before} we can
\textbf{Mitigate} it.

\hypertarget{a-nice-problem-to-have}{%
\subsection{A Nice Problem To Have}\label{a-nice-problem-to-have}}

\textbf{Ignoring} or \textbf{Accepting} risks is a lot less work than
\textbf{Mitigating} them, and sometimes it can feel negligent to just
add them to the backlog or risk-register without doing anything
immediately about them. One useful test I have found is whether ``This
would be a nice problem to have''. For example:

\begin{quotation}

``Running out of space in the database would be a nice problem to have,
because it would mean we have lots of users''

\end{quotation}

\begin{quotation}

``Users complaining about lacking function X would be a nice problem to
have, because it would mean they were using the system''

\end{quotation}

Applying this kind of logic at the start of a project leads you towards
building a
\href{https://en.wikipedia.org/wiki/Minimum_viable_product}{Minimum
Viable Product}.

\hypertarget{learned-helplessness}{%
\subsection{Learned Helplessness}\label{learned-helplessness}}

Sometimes, risks just go away on their own.
\href{https://en.wikipedia.org/wiki/Learned_helplessness}{Learned
Helplessness} on the other hand, is where we \emph{could} do something
about the risk, but fail to see that as an option:

\begin{quotation}

``Learned helplessness is behaviour typical of animals, and in rare
cases humans, that occurs when the subject endures repeatedly painful or
otherwise aversive stimuli which it is unable to escape or avoid. After
such experience, the organism often fails to learn or accept''escape" or
``avoidance'' in new situations where such behavior would likely be
effective. "

\sourceatright{\href{https://en.wikipedia.org/wiki/Learned_helplessness}{\textemdash  Learned Helplessness, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{contain}{%
\section{Contain}\label{contain}}

\textbf{Containing} risks means setting aside sufficient time or money
to deal with them if they occur. This is an excellent approach for
Hidden Risk or entire sets of minor Attendant Risks.

Whenever a project-manager builds slack into a project plan, this is
\textbf{Containment}. ``Time-Boxing'' is also containment: this is where
you give a piece of work a week (say) to prove itself. If it can't be
done in this time, we move on and try a different approach.

In the chapter on Schedule Risk we are going to look in detail at how
this works.

\hypertarget{exploit}{%
\section{Exploit}\label{exploit}}

\textbf{Exploiting} as a strategy usually means taking advantage of the
upside of a risk. For example, ensuring enough stock is available to
mitigate the risk of a rush on sales over the Christmas period, or
ensuring your website has enough bandwidth to capture all the traffic
headed towards it after it's featured on television.

Going back to the example of home insurance, the Insurance company is
\textbf{exploiting} the risk of my house burning down by selling me
insurance. This is a common pattern: wherever there is risk, there is
likely to be a way to profit from it.

Later, in the chapter on Process Risk we'll be looking at how
\textbf{exploiting risk} can happen organically within a company.

\hypertarget{re-cap}{%
\section{Re-cap}\label{re-cap}}

Let's look at the journey so far:

\begin{itemize}
\item
  In A Simple Scenario we looked at how risk pervades every goal we have
  in life, big or small. We saw that risk stems from the fact that our
  Internal Model of the world couldn't capture everything about reality,
  and so some things were down to chance.
\item
  In the Development Process we looked at how common software
  engineering conventions like Unit Testing, User Acceptance Testing and
  Integration could help us manage the risk of taking an idea to
  production, by \emph{gradually} introducing it to reality in stages.
\item
  Then, generalizing the lessons of the Development Process article, we
  examined the idea that Meeting Reality frequently helps flush out
  Hidden Risks and improve your Internal Model.
\item
  In It's All Risk Management we took a leap of faith: Could
  \emph{everything} we do just be risk management? And we looked at the
  RAID log and thought that maybe it could be.
\item
  Next, in A Software Project Scenario we looked at how you could treat
  the project-as-a-whole as a risk management exercise, and treat the
  goals from one day to the next as activities to mitigate risk.
\item
  Evaluating Risk was an aside, looking at some terminology and the
  useful concept of a Risk Register.
\item
  We looked at Cadence, and how feedback loops allow you Navigate the
  Risk Landscape more effectively, by showing you more quickly when
  you're going wrong.
\end{itemize}

What this has been building towards is supplying us with a vocabulary
with which to communicate to our team-mates about which Risks are
important to us, which actions we believe are the right ones, and which
tools we should use.

In the next chapter we will see an example of this in action.

\hypertarget{a-conversation}{%
\chapter{A Conversation}\label{a-conversation}}

After so much theory, it seems like it's time to look at how we can
apply these principles in the real world.

The following is based the summary of a real issue around the time of
writing. It's heavily edited and anonymized, and I've tried to add the
Risk-First vocabulary along the way, but otherwise, it's real.

Some background: \textbf{Synergy} is an online service with an
app-store, and \textbf{Eve} and \textbf{Bob} are developers working for
\textbf{Large Corporation LTD}, which wants to have an application
accepted into Synergy's app-store.

Synergy's release process means that the app-store submission must
happen in a few weeks, so this is something of a hard deadline: if we
miss it, the next opportunity for release will be four months away.

\hypertarget{a-risk-conversation}{%
\section{A Risk Conversation}\label{a-risk-conversation}}

\textbf{Eve}: We've got a problem with the Synergy security review.

\textbf{Bob}: Tell me.

\textbf{Eve}: Well, you know Synergy did their review and asked us to
upgrade our Web Server to only allow TLS version 1.1 and greater?

\textbf{Bob}: Yes, I remember: We discussed it as a team and thought the
simplest thing would be to change the security settings on the Web
Server, but we all felt it was pretty risky. We decided that in order to
flush out Hidden Risk, we'd upgrade our entire production site to use it
\emph{now}, rather than wait for the app launch.

\textbf{Eve}: Right, and it \emph{did} flush out Hidden Risk: some of
our existing software broke on Windows 7, which sadly we still need to
support. So, we had to back it out.

\textbf{Bob}: Ok, well I guess it's good we found out \emph{now}. It
would have been a disaster to discover this after the app had gone live
on Synergy's app-store.

\textbf{Eve}: Yes. So, what's our next-best action to mitigate this?

\textbf{Bob}: Well, we could go back to Synergy and ask them for a
reprieve, but I think it'd be better to mitigate this risk now if we
can\ldots{} they'll definitely want it changed at some point.

\textbf{Eve}: How about we run two web-servers? One for the existing
content, and one for our new Synergy app? We'd have to get a new
external IP address, handle DNS setup, change the firewalls, and then
deploy a new version of the Web Server software on the production boxes.

\textbf{Bob}: This feels like there'd be a lot of Attendant Risk: we're
adding Complexity Risk to our estate, and all of this needs to be
handled by the Networking Team, so we're picking up a lot of Bureaucracy
Risk. I'm also worried that there are too many steps here, and we're
going to discover loads of Hidden Risks as we go.

\textbf{Eve}: Well, you're correct on the first one. But, I've done this
before not that long ago for a Chinese project, so I know the process -
we shouldn't run into any new Hidden Risk.

\textbf{Bob}: OK, fair enough. But isn't there something simpler we can
do? Maybe some settings in the Web Server?

\textbf{Eve}: Well, if we were using Apache, yes, it would be easy to do
this. But, we're using Baroque Web Server, and it \emph{might} support
it, but the documentation isn't very clear.

\textbf{Bob}: OK, and upgrading to Apache is a \emph{big} risk, right?
We'd have to migrate all of our configuration\ldots{}

\textbf{Eve}: Yes, let's not go there. So, \emph{changing} the settings
on Baroque, we have the risk that it's not supported by the software and
we're back where we started. Also, if we isolate the Synergy app stuff
now, we can mess around with it at any point in future, which is a big
win in case there are other Hidden Risks with the security changes that
we don't know about yet.

\textbf{Bob}: OK, I can see that buys us something, but time is really
short and we have holidays coming up.

\textbf{Eve}: Yes. How about for now, we go with the isolated server,
and review next week? If it's working out, then great, we continue with
it. Otherwise, if we're not making progress next week, then it'll be
because our isolation solution is meeting more risk than we originally
thought. In that case, we can attempt the settings change instead.

\textbf{Bob}: Fair enough, it sounds like we're managing the risk
properly, and because we can hand off a lot of this to the Networking
Team, we can get on with mitigating our biggest risk on the project, the
authentication problem, in the meantime.

\textbf{Eve}: Right. I'll check in with the Networking Team each day and
make sure it doesn't get forgotten.

\hypertarget{isnt-it-obvious}{%
\section{Isn't It Obvious?}\label{isnt-it-obvious}}

At this point, you might be wondering what all the fuss is about. This
stuff is all obvious! It's what we do anyway! Perhaps. Risk management
\emph{is} what we do anyway:

\begin{quotation}

``We've survived 200,000 years as humans. Don't you think there's a
reason why we survived? We're good at risk management.''

\sourceatright{\href{https://www.zerohedge.com/news/2018-03-13/taleb-best-thing-society-bankruptcy-goldman-sachs}{\textemdash  Nassim Nicholas Taleb, author of \emph{The Black Swan}}}
\end{quotation}

The problem is that although all this \emph{is} obvious, it appears to
have largely escaped codification within the literature, practices and
methodologies of software development. Further, while it is obvious,
there is a huge hole: Successful De-Risking depends heavily on
individual experience and talent.

In the next chapter, we are going to briefly look at software
methodology, and how it comes up short in when addressing risk.

\hypertarget{one-size-fits-no-one}{%
\chapter{One Size Fits No One}\label{one-size-fits-no-one}}

In All Risk Management we made the case that any action you take on a
software project is to do with managing risk, and the last chapter, A
Conversation was an example of this happening.

Therefore, it stands to reason that software methodologies are all about
risk management too. Since they are prescribing a particular day-to-day
process, or set of actions to take, they are also prescribing a
particular approach to managing the risks on the project.

Back in the Development Process chapter, we introduced an example
software methodology that a development team might follow when building
software. It included steps like \emph{analysis}, \emph{coding} and
\emph{testing}. And, we looked at how each of these actions reduces risk
in the software delivery process.

We looked at how following a process would expose risks that might be
hidden to the members of the team: it doesn't matter if a developer
doesn't know that he's going to break ``Feature Y'', because the
\emph{Integration Testing} part of the process will mitigate this risk
in the testing stage, rather than in production (where it becomes more
expensive).

In this chapter, we're going to have a brief look at some different
software methodologies, and see how different methodologies prioritise
different risks.

\hypertarget{waterfall}{%
\section{Waterfall}\label{waterfall}}

\begin{quotation}

``The waterfall development model originated in the manufacturing and
construction industries; where the highly structured physical
environments meant that design changes became prohibitively expensive
much sooner in the development process. When first adopted for software
development, there were no recognized alternatives for knowledge-based
creative work.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Waterfall_model}{\textemdash  Waterfall Model, \emph{Wikipedia}}}
\end{quotation}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/waterfall-400dpi.png}
\caption{Waterfall Actions\label{waterfall.png}}
\end{figure}

Waterfall is a family of methodologies advocating a linear, stepwise
approach to the processes involved in delivering a software system. The
basic idea behind Waterfall-style methodologies was that the software
process is broken into distinct stages, usually including:

\begin{itemize}
\tightlist
\item
  Requirements Capture
\item
  Specification
\item
  Implementation
\item
  Verification
\item
  Delivery and Operations
\item
  Sign Offs at each stage
\end{itemize}

Because Waterfall methodologies are borrowed from \emph{the construction
industry}, they manage the risks that you would care about in a
construction project. Specifically, minimising the risk of rework, and
the risk of costs spiralling during the physical phase of the project.
For example, pouring concrete is significantly easier than digging it
out again after it sets.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/waterfall2-400dpi.png}
\caption{Waterfall, Specifications and Requirements
Capture\label{waterfall2.png}}
\end{figure}

Construction projects are often done by tender. This means that the
supplier will bid for the job of completing the project, and deliver it
to a fixed price. This is a risk-management strategy for the client:
they are transferring the risk of construction difficulties to the
supplier, and avoiding the Agency Risk that the supplier will ``pad''
the project and take longer to implement it than necessary, charging
them more in the process. In order for this to work, both sides need to
have a fairly close understanding of what will be delivered, and this is
why a specification is created.

In a construction scenario, this makes a lot of sense. But,
\emph{software projects are not the same as building projects}. There
are two key criticisms of the Waterfall approach when applied to
software:

\begin{quotation}

``1. Clients may not know exactly what their requirements are before
they see working software and so change their requirements, leading to
redesign, redevelopment, and re-testing, and increased costs.''

\end{quotation}

\begin{quotation}

``2. Designers may not be aware of future difficulties when designing a
new software product or feature.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Waterfall_model\#Supporting_arguments}{\textemdash  Waterfall Model, \emph{Wikipedia}}}
\end{quotation}

So, the same actions Waterfall prescribes to mitigate rework and
cost-overruns in the building industry do not address (and perhaps
exacerbate) the two issues raised above when applied to software.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/waterfall3-400dpi.png}
\caption{Waterfall, Applied to a Software Project\label{waterfall3.png}}
\end{figure}

As you can see in Figure \ref{waterfall3.png}, some of the risks on the
left \emph{are the same} as the ones on the right: the actions taken to
manage them made no difference (or made things worse). The inability to
manage these risks led to the identification of a ``Software Crisis'',
in the 1970's:

\begin{quotation}

``Software crisis is a term used in the early days of computing science
for the difficulty of writing useful and efficient computer programs in
the required time\ldots{} The software crisis was due to the rapid
increases in computer power and the complexity of the problems that
could not be tackled.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Software_crisis}{\textemdash  Software Crisis, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{alternative-methodologies}{%
\section{Alternative Methodologies}\label{alternative-methodologies}}

The software crisis showed that, a lot of the time, up-front
requirements-capture, specification and fixed-price bids did little to
manage risk on software projects. So it's not surprising that by the
1990's, various different groups of software engineers were advocating
``Agile'' techniques, which did away with these actions.

\begin{figure}
\centering
\includegraphics{images/generated/introduction/xp-400dpi.png}
\caption{Risks, and the practices that manage them in Extreme
Programming\label{xp.png}}
\end{figure}

In \href{http://amzn.eu/d/1vSqAWa}{Extreme Programming Explained}, Kent
Beck breaks down his methodology, Extreme Programming, listing the risks
he wants to address and the actions he proposes to address them with.
Figure \ref{xp.png} summarises the main risks and actions he talks
about. These are \emph{different} risks to those addressed by Waterfall,
and unsurprisingly, this leads to different actions too.

Here are some high-level differences we see in some other popular
methodologies:

\begin{itemize}
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Lean_software_development}{Lean
  Software Development}}: While Waterfall borrows from risk management
  techniques in the construction industry, Lean Software Development
  applies the principles from
  \href{https://en.wikipedia.org/wiki/Lean_manufacturing}{Lean
  Manufacturing}, which was developed at Toyota in the last century.
  Lean takes the view that the biggest risk in manufacturing is from
  \emph{waste}, where waste is inventory, over-production,
  work-in-progress, time spent waiting or defects in production.
  Applying this approach to software means minimising work-in-progress,
  frequent releases and continuous improvement.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Project_Management_Body_of_Knowledge}{Project
  Management Body Of Knowledge (PMBoK)}}: This is a formalisation of
  traditional project management practice. It prescribes best practices
  for managing scope, schedule, resources, communications, dependencies,
  stakeholders etc. on a project. Although ``risk'' is seen as a
  separate entity to be managed, all of the above areas are sources of
  risk within a project, as we will see in Part 2.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Scrum}{Scrum}}: Is a
  popular Agile methodology. Arguably, it is less ``extreme'' than
  Extreme Programming, as it promotes a limited set, more achievable set
  of agile practices, such as frequent releases, daily meetings, a
  product owner and retrospectives. This simplicity arguably makes it
  simpler to learn and adapt to and probably contributes to Scrum's
  popularity over XP.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/DevOps}{DevOps}}: Many
  software systems struggle at the boundary between ``in development''
  and ``in production''. DevOps is an acknowledgement of this, and is
  about more closely aligning the feedback loops between the developers
  and the production system. It champions activities such as continuous
  deployment, automated releases and automated monitoring.
\end{itemize}

\hypertarget{effectiveness}{%
\section{Effectiveness}\label{effectiveness}}

\begin{quotation}

``All methodologies are based on fear. You try to set up habits to
prevent your fears from becoming reality.''

\sourceatright{\href{http://amzn.eu/d/1vSqAWa}{\textemdash  Extreme Programming Explained, \emph{Kent Beck}}}
\end{quotation}

The promise of any methodology is that it will help you manage certain
Hidden Risks. But this comes at the expense of the \emph{effort} you put
into the practices of the methodology. As we've said many times, a lot
of the problems on a software project are Hidden Risks, and so there is
an act of faith here: we are following a methodology because it purports
to avoid risks we don't actually know about.

A methodology offers us a route through the Risk Landscape, based on the
risks that the designers of the methodology care about. When we use the
methodology, it means that we are baking into our behaviour actions to
avoid those risks.

When we take action according to a methodology, we expect the Pay-Off,
and if this doesn't materialise, then we feel the methodology is failing
us. But it could just be that it is inappropriate to the \emph{type of
project} we are running. Our Risk Landscape may not be the one the
designers of the methodology envisaged. For example:

\begin{itemize}
\item
  NASA can't do Agile when launching space craft: there's no two-weekly
  launch that they can iterate over, and the the risks of losing a
  rocket or satellite are simply too great to allow for iteration in
  production. The risk profile is just all wrong for Agile: you need to
  manage the risk of \emph{losing hardware} over the risk of
  \emph{requirements changing}.
\item
  Equally, regulatory projects often require big, up-front,
  waterfall-style design: keeping regulators happy is often about
  showing that you have a well-planned path to achieving the regulation.
  Often, the changes need to be reviewed and approved by regulators and
  other stakeholders in advance of their implementation. This can't be
  done with an approach of ``iterate for a few months''.
\item
  At the other end of the spectrum,
  \href{https://mashable.com/2014/04/30/facebooks-new-mantra-move-fast-with-stability/?europe=true}{Facebook
  used to have} an approach of ``move fast and break things''. This may
  have been optimal when they were trying mitigate the risk of being
  out-innovated by competitors within the fast-evolving sphere of social
  networking.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/introduction/one_size-400dpi.png}
\caption{Inappropriate Methodologies create their own
risks\label{one_size.png}}
\end{figure}

\hypertarget{choosing-a-methodology}{%
\section{Choosing A Methodology}\label{choosing-a-methodology}}

There is value in adopting a methodology as a complete collection of
processes: Choosing a methodology (or any process) reduces the amount of
thinking individuals have to do. Following a process may avoid the
risks, whether the implementer knows about them or not. And, it becomes
the process that is responsible for failure, not the individual (as
shown in Figure \ref{one_size.png}).

If we genuinely care about our projects, then it's critical that we
match the choice of methodology to the risk profile of the project. We
need to understand exactly what risks our methodology will help us with,
and which it won't; where it is appropriate, and where it isn't.

An off-the-shelf methodology is unlikely to fit the risks of our project
exactly. Sometimes, we need to break down methodologies into their
component practices, and apply just the practices we need. This requires
a much more fine-grained understanding of how the practices work, and
what they bring.

So different methodologies advocate different practices, and different
practices manage different risks. If we want to understand
methodologies, or even choose the right practices from one, we really
need to understand the \emph{types of risks} we face on software
projects. This is where we go next in Part 2.

\part{The Risk Landscape}

\hypertarget{risk-landscape}{%
\chapter{Risk Landscape}\label{risk-landscape}}

In the previous chapter, we saw how \emph{Lean Software Development}
owed its existence to production-line manufacturing techniques developed
at Toyota. And, we saw that the \emph{Waterfall} approach originally
came from engineering. If Risk-First is anything, it's about applying
the techniques of \emph{Risk Management} to the discipline of
\emph{Software Development} (there's nothing new under the sun, after
all).

One key activity of Risk Management we haven't discussed yet is
\emph{categorizing} risks. Thus, Part 2 of Risk-First is all about
developing categories of risks for use in Software Development.

\hypertarget{the-risk-landscape-again}{%
\section{The Risk Landscape Again}\label{the-risk-landscape-again}}

In Meeting Reality, we looked at the concept of the Risk Landscape, and
how a software project tries to \emph{navigate} across this landscape,
testing the way as it goes, and trying to get to a position of
\emph{more favourable risk}.

It's tempting to think of our Risk Landscape as being like a
\href{https://en.wikipedia.org/wiki/Fitness_landscape}{Fitness
Landscape}. That is, you have a ``cost function'' which is your height
above the landscape, and you try and optimise by moving downhill in a
\href{https://en.wikipedia.org/wiki/Gradient_descent}{Gradient Descent}
fashion.

However, there's a problem with this: As we said in Evaluating Risk, we
don't have a cost function. We can only guess at what risks there are.
And, we have to go on our \emph{experience}. For this reason, I prefer
to think of the Risk Landscape as a terrain which contains \emph{fauna}
and \emph{obstacles} (or, specifically \emph{Boundaries}).

Just as I can tell you that the landscape outside your window will
probably will have some trees, fields and buildings, and that the
buildings are likely to be joined together by roads, we can make
generalisations about risks too.

\hypertarget{why-should-we-categorise-the-risks}{%
\section{Why Should We Categorise The
Risks?}\label{why-should-we-categorise-the-risks}}

A lot of knowledge and understanding of the world starts by naming and
categorising things.

If we were studying insects, this might be a guide giving you a
description and a picture of each insect, telling you where to find it
and what it does. That doesn't mean that this is \emph{all} there is to
know. Just as a scientist could spend her entire life studying a
particular species of bee, each of the risks we'll look at really has a
whole sub-discipline of Computer Science attached to it, which we can't
possibly hope to cover in any great depth.

As software developers, we can't hope to know the detailed specifics of
the whole discipline of
\href{https://en.wikipedia.org/wiki/Complexity_theory}{Complexity
Theory}, or
\href{https://en.wikipedia.org/wiki/Concurrency_(computer_science)}{Concurrency
Theory}. But, we're still required to operate in a world where these
things exist. So, we may as well get used to them, and ensure that we
respect their primacy. We are operating in \emph{their} world, so we
need to know the rules.

Once we can spot and name different types of risk, we can then think
about their characteristics, and how to manage or avoid them. In each of
the following chapters, we'll be looking at a different category of
risk, some of it's characteristics and sometimes suggesting actions to
take to deal with it.

But foremost, this is a ``spotters' guide'' to software risks and where
to find them.

\hypertarget{our-tour-itinerary}{%
\section{Our Tour Itinerary}\label{our-tour-itinerary}}

Below is a table outlining the different risks we'll see. There
\emph{is} an order to this: the later risks are written assuming a
familiarity with the earlier ones. Hopefully, you'll stay to the end and
see everything, but you're free to choose your own tour if you want to.

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
Risk\strut
\end{minipage} & \begin{minipage}[b]{0.58\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Feature Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
When you haven't built features the market needs, or they contain bugs,
or the market changes underneath you. \strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Communication Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks associated with getting messages heard and understood.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Complexity Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Your software is so complex it makes it hard to change, understand or
run.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Dependency Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks of depending on other people, products, software, functions, etc.
This is a general look at dependencies, before diving into specifics
like\ldots{}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Scarcity Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks associated with having limited time, money or some other
resource.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Deadline Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
The risk of having a date to hit.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Software Dependency Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
The risk of depending on a software library, service or function.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Process Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
When you depend on a business process, or human process to give you
something you need.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Boundary Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks due to making decisions that limit your choices later on.
Sometimes, you go the wrong way on the Risk Landscape and it's hard to
get back to where you want to be.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Agency Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks that staff have their own Goals, which might not align with those
of the project or team.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks due to the fact that systems contain multiple agents, which need
to work together.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Map And Territory Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Risks due to the fact that people don't see the world as it really is.
(After all, they're working off different, imperfect Internal
Models.)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
Operational Risk\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Software is embedded in a system containing people, buildings, machines
and other services. Operational risk considers this wider picture of
risk associated with running a software service or business in the real
world.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

On each page we'll start by looking at the category of the risk \emph{in
general}, and then break this down into some specific sub-types. At the
end, in Staging and Classifying we'll have a recap about what we've seen
and make some guesses about how things fit together.

\hypertarget{correlation-causation}{%
\section{Correlation \& Causation}\label{correlation-causation}}

Although we're going to try and categorise the kinds of things we see on
this Risk Landscape, this isn't going to be perfect:

\begin{itemize}
\tightlist
\item
  One risk can ``blend'' into another just like sometimes a ``field'' is
  also a ``car-park'' or a building might contain some trees (but isn't
  a forest).
\item
  As we know from Part 1, mitigating one risk probably means accepting
  another.
\item
  There is \emph{correlation} between different risks: one risk may
  cause another, or two risks may be due to the same underlying cause.
\end{itemize}

Risk is messy. It's not always easy to tease apart the different
components of risk and look at them individually. Let's look at a
high-profile recent example to see why.

\hypertarget{the-financial-crisis}{%
\subsection{The Financial Crisis}\label{the-financial-crisis}}

In the \href{https://en.wikipedia.org/wiki/Financial_services}{Financial
Services} industry, whole \emph{departments} exist to calculate things
like:

\begin{itemize}
\tightlist
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Market_risk}{Market
  Risk}:} the risk that the amount some asset is going to change in
  value.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Credit_risk}{Credit
  Risk}:} the risk that someone who owes you a payment at a specific
  point in time might not pay it back.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Liquidity_risk}{Liquidity
  Risk}:} the risk that you can't find a market to sell/buy something,
  usually leading to a shortage of ready cash.
\end{itemize}

In the financial crisis of 2007, these models of risk didn't turn out to
be much use. Although there are lots of conflicting explanations of what
happened, one way to look at it is this:

\begin{itemize}
\tightlist
\item
  Liquidity difficulties (i.e.~amount of cash you have for day-to-day
  running of the bank) caused some banks to not be able to cover their
  short term payment obligations.
\item
  This caused credit defaults (the thing that Credit Risk measures were
  meant to guard against) even though the banks \emph{technically} were
  solvent.
\item
  Once credit defaults started, this worried investors in the banks,
  which had massive Market Risk impacts that none of the models foresaw.
\end{itemize}

All the Risks were
\href{https://www.investopedia.com/terms/c/correlation.asp}{correlated}.
That is, they were affected by the \emph{same underlying events}, or
\emph{each other}.

\begin{figure}
\centering
\includegraphics{images/generated/risks/landscape/causation-400dpi.png}
\caption{Causation shown on a Risk-First Diagram: More complexity is
likely to lead to more Operational Risk\label{causation.png}}
\end{figure}

It's like this with software risks, too, sadly. For example, Operational
Risk is going to be heavily correlated with Complexity Risk: the more
complex your operation, the more risky it will be. In the Risk-First
diagrams, we will sometimes show correlation or causation with an arrow,
like in Figure \ref{causation.png}.

\hypertarget{were-all-naturalists-now}{%
\section{We're all Naturalists Now}\label{were-all-naturalists-now}}

Just as naturalists are able to head out and find new species of insects
and plants, we should expect to do the same. Risk-First is by no means a
complete picture - it's barely a sketch.

It's a big, crazy, evolving world of software. Help to fill in the
details. Report back what you find.

So, let's get started with Feature Risk.

\hypertarget{feature-risk}{%
\chapter{Feature Risk}\label{feature-risk}}

Feature Risks are risks to do with functionality that you need to have
in your software.

As a simple example, if your needs are served perfectly by Microsoft
Excel, then you don't have any Feature Risk. However, the day you find
Microsoft Excel wanting, and decide to build an Add-On is the day when
you first appreciate some Feature Risk.

In a way, Feature Risk is very fundamental: if there were \emph{no}
feature risk, the job would be done already, either by you, or by
another product, and the product would be perfect!

Not considering Feature Risk means that you might be building the wrong
functionality, for the wrong audience or at the wrong time. And
eventually, this will come down to lost money, business, acclaim, or
whatever else reason you are doing your project for. So let's unpack
this concept into some of it's variations.

\hypertarget{feature-fit-risk}{%
\section{Feature Fit Risk}\label{feature-fit-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-fit-risk-400dpi.png}
\caption{Feature Risk\label{feature-fit-risk.png}}
\end{figure}

This is the one we've just discussed above - the feature that you (or
your clients) want to use in the software \emph{isn't there}:

\begin{itemize}
\tightlist
\item
  This might manifest itself as complete \emph{absence} of something you
  need, e.g ``Why is there no word count in this editor?''
\item
  It could be that the implementation isn't complete enough, e.g ``why
  can't I add really long numbers in this calculator?''
\end{itemize}

Feature risks are mitigated by talking to clients and building things,
which leads on to\ldots{}

\hypertarget{implementation-risk}{%
\section{Implementation Risk}\label{implementation-risk}}

Feature Risk also includes things that don't work as expected: That is
to say, \href{https://en.wikipedia.org/wiki/Software_bug}{bugs}.
Although the distinction between ``a missing feature'' and ``a broken
feature'' might be worth making in the development team, we can consider
these both the same kind of risk: \emph{the software doesn't do what the
user expects}.

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-implementation-risk-400dpi.png}
\caption{Implementation Risk\label{feature-implementation-risk.png}}
\end{figure}

At this point, it's worth pointing out that sometimes, \emph{the user
expects the wrong thing}. This is a different but related risk, which
could be down to training, documentation or simply a poor user
interface. We'll look at that more in Communication Risk.

\hypertarget{regression-risk}{%
\section{Regression Risk}\label{regression-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-regression-risk-400dpi.png}
\caption{Regression Risk\label{feature-regression-risk.png}}
\end{figure}

Regression Risk is the risk of breaking existing features in your
software when you add new ones. As with the previous risks, the eventual
result is the same; customers don't have the features they expect. This
can become a problem as your code-base gains Complexity, as it becomes
impossible to keep a complete Internal Model of the whole thing in your
head.

Delivering new features can delight your customers, breaking existing
ones will annoy them. This is something we'll come back to in
Operational Risk.

\hypertarget{conceptual-integrity-risk}{%
\section{Conceptual Integrity Risk}\label{conceptual-integrity-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/conceptual-integrity-risk-400dpi.png}
\caption{Conceptual Integrity Risk\label{conceptual-integrity-risk.png}}
\end{figure}

Sometimes, users \emph{swear blind} that they need some feature or
other, but it runs at odds with the design of the system, and plain
\emph{doesn't make sense}. Often, the development team can spot this
kind of conceptual failure as soon as it enters the Backlog. Usually,
it's in coding that this becomes apparent.

Sometimes, it can go for a lot longer. I once worked on some software
that was built as a score-board within a chat application. However,
after we'd added much-asked-for commenting and reply features to our
score-board, we realised we'd implemented a chat application
\emph{within a chat application}, and had wasted our time enormously.

\href{https://en.wikipedia.org/wiki/Feature_phone}{Feature Phones} are a
real-life example: although it \emph{seemed} like the market wanted more
and more features added to their phones,
\href{https://en.wikipedia.org/wiki/IPhone}{Apple's iPhone} was able to
steal huge market share by presenting a much more enjoyable, more
coherent user experience, despite being more expensive and having fewer
features. Feature Phones had been drowning in increasing Conceptual
Integrity Risk without realising it.

This is a particularly pernicious kind of Feature Risk which can only be
mitigated by good Design. Human needs are fractal in nature: the more
you examine them, the more complexity you can find. The aim of a product
is to capture some needs at a \emph{general} level: you can't hope to
anticipate everything.

Conceptual Integrity Risk is the risk that chasing after features leaves
the product making no sense, and therefore pleasing no-one.

\hypertarget{feature-access-risk}{%
\section{Feature Access Risk}\label{feature-access-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-access-risk-400dpi.png}
\caption{Feature Access Risk\label{feature-access-risk.png}}
\end{figure}

Sometimes, features can work for some people and not others: this could
be down to
\href{https://en.wikipedia.org/wiki/Accessibility}{Accessibility}
issues, language barriers or localisation.

You could argue that the choice of \emph{platform} is also going to
limit access: writing code for XBox-only leaves PlayStation owners out
in the cold. This is \emph{largely} Feature Access Risk, though
Dependency Risk is related here.

In Marketing, minimising Feature Access Risk is all about
\href{https://en.wikipedia.org/wiki/Market_segmentation}{Segmentation}:
trying to work out \emph{who} your product is for, and tailoring it to
that particular market. For developers, increasing Feature Access means
increasing complexity: you have to deliver the software on more
platforms, localised in more languages, with different configurations of
features. Mitigating Feature Access Risk therefore means increased
effort and complexity (which we'll come to later).

\hypertarget{market-risk}{%
\subsection{Market Risk}\label{market-risk}}

Feature Access Risk is related to Market Risk, which I introduced on the
Risk Landscape page as being the value that the market places on a
particular asset.

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/market-risk-400dpi.png}
\caption{Market Risk\label{market-risk.png}}
\end{figure}

\begin{quotation}

``Market risk is the risk of losses in positions arising from movements
in market prices.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Market_risk}{\textemdash  Market Risk, \emph{Wikipedia}}}
\end{quotation}

I face market risk when I own (i.e.~have a \emph{position} in) some
\href{http://apple.com}{Apple} stock. Apple's's stock price will decline
if a competitor brings out an amazing product, or if fashions change and
people don't want their products any more.

Since the product you are building is your asset, it makes sense that
you'll face Market Risk on it: the \emph{market} decides what it is
prepared to pay for this, and it tends to be outside your control.

\hypertarget{feature-drift-risk}{%
\section{Feature Drift Risk}\label{feature-drift-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-drift-risk-400dpi.png}
\caption{Feature Drift Risk\label{feature-drift-risk.png}}
\end{figure}

\textbf{Feature Drift} is the tendency that the features people need
\emph{change over time}. For example, at one point in time, supporting
IE6 was right up there for website developers, but it's not really
relevant anymore. The continual improvements we see in processor speeds
and storage capacity of our computers is another example: the
\href{https://en.wikipedia.org/wiki/Wii}{Wii} was hugely popular in the
early 2000's, but expectations have moved on now.

The point is: Requirements captured \emph{today} might not make it to
\emph{tomorrow}, especially in the fast-paced world of IT. This is
partly because the market \emph{evolves} and becomes more discerning.
This happens in several ways:

\begin{itemize}
\tightlist
\item
  Features present in competitor's versions of the software become
  \emph{the baseline}, and they're expected to be available in your
  version.
\item
  Certain ways of interacting become the norm (e.g.
  \href{https://en.wikipedia.org/wiki/QWERTY}{querty} keyboards, or the
  control layout in cars: these don't change with time).
\item
  Features decline in usefulness: \emph{Printing} is less important now
  than it was, for example.
\end{itemize}

As we will see later in Boundary Risk, Feature Drift Risk is often a
source of Complexity Risk, since you often need to add new features,
while not dismantling old features as some users still need them.

Feature Drift Risk is \emph{not the same thing} as \textbf{Requirements
Drift}, which is the tendency projects have to expand in scope as they
go along. There are lots of reasons they do that, a key one being the
Hidden Risks uncovered on the project as it progresses.

\hypertarget{fashion}{%
\subsection{Fashion}\label{fashion}}

Fashion plays a big part in IT. By being \emph{fashionable}, web-sites
are communicating: \emph{this is a new thing}, \emph{this is relevant},
\emph{this is not terrible}: all of which is mitigating a Communication
Risk. Users are all-too-aware that the Internet is awash with terrible,
abandon-ware sites that are going to waste their time. How can you
communicate that you're not one of them to your users?

\hypertarget{delight}{%
\section{Delight}\label{delight}}

If this breakdown of Feature Risk seems reductive, then try not to think
of it that way: the aim \emph{of course} should be to delight users, and
turn them into fans.

Consider Feature Risk from both the down-side and the up-side:

\begin{itemize}
\tightlist
\item
  What are we missing?
\item
  How can we be \emph{even better}?
\end{itemize}

\hypertarget{analysis}{%
\section{Analysis}\label{analysis}}

So far in this chapter, we've simply seen a bunch of different types of
Feature Risk. But we're going to be relying heavily on Feature Risk as
we go on in order to build our understanding of other risks, so it's
probably worth spending a bit of time up front to classify what we've
found.

The Feature Risks identified here basically exist in a space with at
least 3 dimensions:

\begin{itemize}
\tightlist
\item
  \textbf{Fit}: How well the features fit for a particular client.
\item
  \textbf{Audience}: The range of clients (the \emph{market}) that may
  be able to use this feature.
\item
  \textbf{Evolution}: The way the fit and the audience changes and
  evolves as time goes by.
\end{itemize}

Let's examine each in turn.

\hypertarget{fit}{%
\subsection{Fit}\label{fit}}

\begin{quotation}

``This preservation, during the battle for life, of varieties which
possess any advantage in structure, constitution, or instinct, I have
called Natural Selection; and Mr.~Herbert Spencer has well expressed the
same idea by the Survival of the Fittest''

\sourceatright{\href{https://en.wikipedia.org/wiki/Survival_of_the_fittest}{\textemdash  Charles Darwin (Survival of the Fittest), \emph{Wikipedia}}.}
\end{quotation}

Darwin's conception of fitness was not one of athletic prowess, but how
well an organism worked within the landscape, with the goal of
reproducing itself.

Feature Fit Risk, Conceptual Integrity Risk and Implementation Risk all
hint at different aspects of this ``fitness''. We can conceive of them
as the gaps between the following entities:

\begin{itemize}
\tightlist
\item
  Perceived Need: What the developers \emph{think} the users want.
\item
  Expectation: What the user \emph{expects}.
\item
  Reality: What they actually \emph{get}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/all-feature-risk-400dpi.png}
\caption{Feature Risks Assembled: Fit Risks, shown as \emph{gaps}, as in
the \emph{Service Quality Model}\label{all-feature-risk.png}}
\end{figure}

For further reading, you can check out
\href{http://en.wikipedia.org/SERVQUAL}{The Service Quality Model},
which Figure \ref{all-feature-risk.png} is derived from. This model
analyses the types of \emph{quality gaps} in services, and how consumer
expectations and perceptions of a service arise.

In the Staging And Classifying chapter, we'll come back and build on
this model further.

\hypertarget{fit-and-audience}{%
\subsection{Fit and Audience}\label{fit-and-audience}}

Two risks, Feature Access Risk and Market Risk considers \emph{Fit} for
a whole \emph{Audience} of users. They are different: just as it's
possible to have a small audience, but a large revenue, it's possible to
have a product which has low Feature Access Risk (i.e lots of users can
access it without difficulty) but high Market Risk (i.e.~the market is
highly volatile or capricious in it's demands). \emph{Online services}
often suffer from this Market Risk roller-coaster, being one moment
highly valued and the next irrelevant.

\begin{itemize}
\tightlist
\item
  \textbf{Market Risk} is therefore risk to \emph{income} from the
  market changing.
\item
  \textbf{Feature Access Risk} is risk to \emph{audience} changing.
\end{itemize}

\hypertarget{fit-audience-and-evolution}{%
\subsection{Fit, Audience and
Evolution}\label{fit-audience-and-evolution}}

Two risks further consider how the \textbf{Fit} and \textbf{Audience}
\emph{change}: Regression Risk and Feature Drift Risk. We call this
\emph{evolution} in the sense that:

\begin{itemize}
\tightlist
\item
  Our product's features \emph{evolve} with time, and changes made by
  the development team.
\item
  Our audience changes and evolves as it is exposed to our product and
  competing products.
\item
  The world as a whole is an evolving system within which our product
  exists.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/all-feature-risk2-400dpi.png}
\caption{Risks of Evolution/Change either of the product or the
expectations of clients.\label{all-feature-risk2.png}}
\end{figure}

\hypertarget{applying-feature-risk}{%
\section{Applying Feature Risk}\label{applying-feature-risk}}

Next time you are grooming the backlog, why not apply this:

\begin{itemize}
\tightlist
\item
  Can you judge which tasks mitigate the most Feature Risk?
\item
  Are you delivering features that are valuable across a large audience?
  Or of less value across a wider audience?
\item
  How does writing a specification mitigate Fit Risk? For what other
  reasons are you writing specifications?
\item
  Does the audience \emph{know} that the features exist? How do you
  communicate feature availability to them?
\end{itemize}

In the next chapter, we are going to unpack this last point further.
Somewhere between ``what the customer wants'' and ``what you give them''
is a \emph{dialog}. In using a software product, users are engaging in a
\emph{dialog} with its features. If the features don't exist, hopefully
they will engage in a dialog with the development team to get them
added.

These dialogs are prone to risk, and this is the subject of the next
chapter, Communication Risk.

\hypertarget{communication-risk}{%
\chapter{Communication Risk}\label{communication-risk}}

If we all had identical knowledge, there would be no need to do any
communicating at all, and therefore and also no Communication Risk.

But, people are not all-knowing oracles. We rely on our \emph{senses} to
improve our Internal Models of the world. There is Communication Risk
here - we might overlook something vital (like an on-coming truck) or
mistake something someone says (like ``Don't cut the green wire'').

\hypertarget{a-model-of-communication}{%
\section{A Model Of Communication}\label{a-model-of-communication}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_1-400dpi.png}
\caption{Shannon's Communication Model\label{communication_1.png}}
\end{figure}

In 1948, Claude Shannon proposed this definition of communication:

\begin{quotation}

``The fundamental problem of communication is that of reproducing at one
point, either exactly or approximately, a message selected at another
point.''

\sourceatright{\href{https://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication}{\textemdash  A Mathematical Theory Of Communication, \emph{Claude Shannon}}  <!-- tweet-end -->}
\end{quotation}

And from this same paper, we get Figure \ref{communication_1.png}: We
move from top-left (``I want to send a message to someone'') to bottom
left, clockwise, where we hope the message has been understood and
believed. (I've added this last box to Shannon's original diagram.)

One of the chief concerns in Shannon's paper is the risk of error
between \textbf{Transmission} and \textbf{Reception}. He creates a
theory of information (measured in \textbf{bits}), the upper-bounds of
information that can be communicated over a channel and ways in which
Communication Risk between these processes can be mitigated by clever
\textbf{Encoding} and \textbf{Decoding} steps.

But it's not just transmission. Communication Risk exists at each of
these steps. Let's imagine a human example, where someone,
\textbf{Alice} is trying to send a simple message to \textbf{Bob}:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.26\columnwidth}\raggedright
Step\strut
\end{minipage} & \begin{minipage}[b]{0.68\columnwidth}\raggedright
Potential Risk\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Motivation\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\textbf{Alice} might be \textbf{motivated} to send a message to tell
\textbf{Bob} something, only to find out that \emph{he already knew
it}.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Composition\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\textbf{Alice} might mess up the \emph{intent} of the message: instead
of ``Please buy chips'' she might say, ``Please buy chops''.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Encoding\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\textbf{Alice} might not speak clearly enough to be understood.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Transmission\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\textbf{Alice} might not say it \emph{loudly} enough for \textbf{Bob} to
hear.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Reception\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\textbf{Bob} doesn't hear the message clearly (maybe there is background
noise).\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Decoding\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\textbf{Bob} might not decode what was said into a meaningful
sentence.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Interpretation\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
Assuming \textbf{Bob} \emph{has} heard, will he correctly
\textbf{interpret} which type of chips (or chops) \textbf{Alice} was
talking about?\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Reconciliation\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
Does \textbf{Bob} believe the message? Will he \textbf{reconcile} the
information into his Internal Model and act on it? Perhaps not, if
\textbf{Bob} thinks that there are chips at home already.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{approach-to-communication-risk}{%
\section{Approach To Communication
Risk}\label{approach-to-communication-risk}}

There is a symmetry about the steps going on in Figure
\ref{communication_1.png}, and we're going to exploit this in order to
break down Communication Risk into it's main types.

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_2-400dpi.png}
\caption{Communication Risk 2\label{communication_2.png}}
\end{figure}

To get inside Communication Risk, we need to understand
\textbf{Communication} itself, whether between \emph{machines},
\emph{people} or \emph{products}: we'll look at each in turn. In order
to do that, we're going to examine four basic concepts in each of these
settings:

\begin{itemize}
\tightlist
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Communication_channel}{Channels}}:
  the medium via which the communication is happening.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Communication_protocol}{Protocols}}:
  the systems of rules that allow two or more entities of a
  communications system to transmit information.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Message}{Messages}}: The
  information we want to convey.
\item
  \textbf{Internal Models}: the sources and destinations for the
  messages. Updating internal models (whether in our heads or machines)
  is the reason why we're communicating.
\end{itemize}

And, as we look at these four areas, we'll consider the Attendant Risks
of each.

\hypertarget{channels}{%
\section{Channels}\label{channels}}

There are lots of different types of media for communicating (e.g.~TV,
Radio, DVD, Talking, Posters, Books, Phones, The Internet, etc. ) and
they all have different characteristics. When we communicate via a given
medium, it's called a \emph{channel}.

The channel \emph{characteristics} depend on the medium, then. Some
obvious ones are cost, utilisation, number of people reached, simplex or
duplex (parties can transmit and receive at the same time), persistence
(a play vs a book, say), latency (how long messages take to arrive) and
bandwidth (the amount of information that can be transmitted in a period
of time).

Channel characteristics are important: in a high-bandwidth, low-latency
situation, \textbf{Alice} and \textbf{Bob} can \emph{check} with each
other that the meaning was transferred correctly. They can discuss what
to buy, they can agree that \textbf{Alice} wasn't lying or playing a
joke.

The channel characteristics also imply suitability for certain
\emph{kinds} of messages. A documentary might be a great way of
explaining some economic concept, whereas an opera might not be.

\hypertarget{channel-risk}{%
\section{Channel Risk}\label{channel-risk}}

Shannon discusses that no channel is perfect: there is always the
\textbf{risk of noise} corrupting the signal. A key outcome from
Shannon's paper is that there is a tradeoff: within the capacity of the
channel (the \textbf{Bandwidth}), you can either send lots of
information with \emph{higher} risk that it is wrong, or less
information with \emph{lower} risk of errors.

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_channel_risks-400dpi.png}
\caption{Communication Channel
Risk\label{communication_channel_risks.png}}
\end{figure}

But channel risk goes wider than just this mathematical example:
messages might be delayed or delivered in the wrong order, or not be
acknowledged when they do arrive. Sometimes, a channel is just an
inappropriate way of communicating. When you work in a different
time-zone to someone else on your team, there is \emph{automatic}
Channel Risk, because instantaneous communication is only available for
a few hours' a day.

When channels are \textbf{poor-quality}, less communication occurs.
People will try to communicate just the most important information. But,
it's often impossible to know a-priori what constitutes ``important''.
This is why Extreme Programming recommends the practice of
\href{https://en.wikipedia.org/wiki/Pair_programming}{Pair Programming}
and siting all the developers together: although you don't know whether
useful communication will happen, you are mitigating Channel Risk by
ensuring high-quality communication channels are in place.

At other times, channels are crowded, and can contain so much
information that we can't hope to receive all the messages. In these
cases, we don't even observe the whole channel, just parts of it.

\hypertarget{marketing-communications}{%
\subsubsection{Marketing
Communications}\label{marketing-communications}}

When we are talking about a product or a brand, mitigating Channel Risk
is the domain of
\href{https://en.wikipedia.org/wiki/Marketing_communications}{Marketing
Communications}. How do you ensure that the information about your
(useful) project makes it to the right people? How do you address the
right channels?

This works both ways. Let's looks at some of the \textbf{Channel Risks}
from the point of view of a hypothetical software tool, \textbf{D},
which would really useful in my software:

\begin{itemize}
\tightlist
\item
  The concept that there is such a thing as \textbf{D} which solves my
  problem isn't something I'd even considered.
\item
  I'd like to use something like \textbf{D}, but how do I find it?
\item
  There are multiple implementations of \textbf{D}, which is the best
  one for the task?
\item
  I know \textbf{D}, but I can't figure out how to solve my problem in
  it.
\item
  I've chosen \textbf{D}, I now need to persuade my team that \textbf{D}
  is the correct solution\ldots{}
\item
  \ldots{} and then they also need to understand \textbf{D} to do their
  job too.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_marketing-400dpi.png}
\caption{Communication Marketing\label{communication_marketing.png}}
\end{figure}

Internal Models don't magically get populated with the information they
need: they fill up gradually, as shown in Figure
\ref{communication_marketing.png}. Popular products and ideas
\emph{spread}, by word-of-mouth or other means. Part of the job of being
a good technologist is to keep track of new \textbf{Ideas},
\textbf{Concepts} and \textbf{Options}, so as to use them as
Dependencies when needed.

\hypertarget{protocols}{%
\section{Protocols}\label{protocols}}

\begin{quotation}

``A communication protocol is a system of rules that allow two or more
entities of a communications system to transmit information.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Communication_protocol}{Communication Protocol, Wikipedia}}
\end{quotation}

In this chapter, I want to examine the concept of Communication
Protocols and how they relate to Abstraction, which is implicated over
and over again in different types of risk we will be looking at.

Abstraction means separating the \emph{definition} of something from the
\emph{use} of something. It's a widely applicable concept, but our
example below will be specific to communication, and looking at the
abstractions involved in loading a web page.

First, we need to broaden our terminology. Although so far we've talked
about \textbf{Senders} and \textbf{Receivers}, we now need to talk from
the point of view of who-depends-on-who. That is, Clients and Suppliers.

\begin{itemize}
\tightlist
\item
  If you're \emph{depended on}, then you're a \textbf{``Supplier''} (or
  a \textbf{``Server''}, when we're talking about actual hardware).
\item
  If you require communication with something else, you're a
  \textbf{``Client''}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_protocols-400dpi.png}
\caption{Protocol Stack\label{communication_protocols.png}}
\end{figure}

In order that a web browser (a \textbf{client}) can load a web-page from
a \textbf{server}, they both need to communicate with shared protocols.
In this example, this is going to involve (at least) six separate
protocols, as shown in Figure \ref{communication_protocols.png}.

Let's examine each protocol in turn when I try to load the web page at
the following address using a web browser:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{http}\NormalTok{://google.com/preferences}
\end{Highlighting}
\end{Shaded}

\hypertarget{dns---domain-name-system}{%
\subsection{1. DNS - Domain Name
System}\label{dns---domain-name-system}}

The first thing that happens is that the name ``google.com'' is
\emph{resolved} by DNS. This means that the browser looks up the domain
name ``google.com'' and gets back an IP address.

This is some Abstraction: instead of using the machine's
\href{https://en.wikipedia.org/wiki/IP_address}{IP Address} on the
network, \texttt{216.58.204.78}, I can use a human-readable address,
\texttt{google.com}.

The address \texttt{google.com} doesn't necessarily resolve to that same
address each time: \emph{They have multiple IP addresses for
\texttt{google.com}}, but as a user, I don't have to worry about this
detail.

\hypertarget{ip---internet-protocol}{%
\subsection{2. IP - Internet Protocol}\label{ip---internet-protocol}}

But this hints at what is beneath the abstraction: although I'm loading
a web-page, the communication to the Google server happens by
\href{https://en.wikipedia.org/wiki/Internet_Protocol}{IP Protocol} -
it's a bunch of discrete ``packets'' (streams of binary digits). You can
think of a packet as being like a real-world parcel or letter.

Each packet consists of two things:

\begin{itemize}
\tightlist
\item
  An \textbf{IP Address}, which tells the network components (such as
  routers and gateways) where to send the packet, much like you'd write
  the address on the outside of a parcel.
\item
  The \textbf{Payload}, the stream of bytes for processing at the
  destination. Like the contents of the parcel.
\end{itemize}

But, even this concept of ``packets'' is an Abstraction. Although all
the components of the network understand this protocol, we might be
using Wired Ethernet cables, or WiFi, 4G or \emph{something else}
beneath that.

\hypertarget{wifi-protocol}{%
\subsection{3. 802.11 - WiFi Protocol}\label{wifi-protocol}}

I ran this at home, using WiFi, which uses
\href{https://en.wikipedia.org/wiki/IEEE_802.11}{IEEE 802.11 Protocol},
which allows my laptop to communicate with the router wirelessly, again
using an agreed, standard protocol. But even \emph{this} isn't the
bottom, because this is actually probably specifying something like
\href{https://en.wikipedia.org/wiki/MIMO-OFDM}{MIMO-OFDM}, giving
specifications about frequencies of microwave radiation, antennas,
multiplexing, error-correction codes and so on. And WiFi is just the
first hop: after the WiFi receiver, there will be protocols for
delivering the packets via the telephony system.

\hypertarget{tcp---transmission-control-protocol}{%
\subsection{4. TCP - Transmission Control
Protocol}\label{tcp---transmission-control-protocol}}

Another Abstraction going on here is that my browser believes it has a
``connection'' to the server. This is provided by the TCP protocol.

But, this is a fiction - my ``connection'' is built on the IP protocol,
which as we saw above is just packets of data on the network. So there
are lots of packets floating around which say ``this connection is still
alive'' and ``I'm message 5 in the sequence'' and so on in order to
maintain this fiction.

This all means that the browser can forget about all the details of
packet ordering and so on, and work with the fiction of a connection.

\hypertarget{http---hypertext-transfer-protocol}{%
\subsection{5. HTTP - Hypertext Transfer
Protocol}\label{http---hypertext-transfer-protocol}}

If we examine what is being sent on the TCP connection, we see something
like this:

bash

\begin{quotation}
```
GET /preferences HTTP/1.1
```{=latex}
\end{quotation}

```

\begin{quotation}

Host: google.com

\end{quotation}

\begin{quotation}

Accept: \emph{/}

\end{quotation}

\begin{quote}
```
\end{quote}

This is now the HTTP protocol proper, and these 4 lines are sending
information \emph{over the connection} to the Google server, to ask it
for the page. Finally, Google's server gets to respond:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{<} \ExtensionTok{HTTP/1.1}\NormalTok{ 301 Moved Permanently}
\OperatorTok{<} \ExtensionTok{Location}\NormalTok{: http://www.google.com/preferences}
\ExtensionTok{...}
\end{Highlighting}
\end{Shaded}

In this case, Google's server is telling us that the web page has
changed address. The \texttt{301} is a status code meaning the page has
moved: Instead of \texttt{http://google.com/preferences}, we want
\texttt{http://www.google.com/preferences}.

\hypertarget{summary-1}{%
\subsection{Summary}\label{summary-1}}

By having a stack of protocols, we are able to apply
\href{https://en.wikipedia.org/wiki/Separation_of_concerns}{Separation
Of Concerns}, each protocol handling just a few concerns:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.29\columnwidth}\raggedright
Protocol\strut
\end{minipage} & \begin{minipage}[b]{0.65\columnwidth}\raggedright
Abstractions\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.29\columnwidth}\raggedright
\texttt{HTTP}\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
URLs, error codes, pages.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
\texttt{DNS}\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
Names of servers to IP Addresses.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
\texttt{TCP}\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
The concept of a ``connection'' with guarantees about ordering and
delivery.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
\texttt{IP}\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
``Packets'' with addresses and payloads.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
\texttt{WiFi}\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
``Networks'', 802.11 flavours, Transmitters, Antennas, error correction
codes.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\texttt{HTTP} ``stands on the shoulders of giants'': Not only does it
get to use pre-existing protocols like \texttt{TCP} and \texttt{DNS} to
make it's life easier, it got \texttt{802.11} ``for free'' when this
came along and plugged into the existing \texttt{IP} protocol. This is
the key value of abstraction: you get to piggy-back on \emph{existing}
patterns, and use them yourself.

\hypertarget{protocol-risk}{%
\section{Protocol Risk}\label{protocol-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_protocol_risks-400dpi.png}
\caption{Communication Protocols
Risks\label{communication_protocol_risks.png}}
\end{figure}

Hopefully, the above example gives an indication of the usefulness of
protocols within software. But for every protocol we use, we have
Protocol Risk. This is a problem in human communication protocols, but
it's really common in computer communication because we create protocols
\emph{all the time} in software.

For example, as soon as we define a Javascript function (called
\textbf{b} here), we are creating a protocol for other functions
(\textbf{a} here) to use it:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{b}\NormalTok{(a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c) }\OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ a}\OperatorTok{+}\NormalTok{b}\OperatorTok{+}\NormalTok{c}\OperatorTok{;}
\OperatorTok{\}}

\KeywordTok{function} \AttributeTok{a}\NormalTok{() }\OperatorTok{\{}
    \KeywordTok{var}\NormalTok{ bOut }\OperatorTok{=} \AttributeTok{b}\NormalTok{(}\DecValTok{1}\OperatorTok{,}\DecValTok{2}\OperatorTok{,}\DecValTok{3}\NormalTok{)}\OperatorTok{;}
    \ControlFlowTok{return} \StringTok{"something "}\OperatorTok{+}\NormalTok{bOut}\OperatorTok{;}       \CommentTok{// returns "something 6"}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

If function \textbf{b} then changes, say:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{b}\NormalTok{(a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c}\OperatorTok{,}\NormalTok{ d }\CommentTok{/* new parameter */}\NormalTok{) }\OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ a}\OperatorTok{+}\NormalTok{b}\OperatorTok{+}\NormalTok{c}\OperatorTok{+}\NormalTok{d}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Then, \textbf{a} will instantly have a problem calling it and there will
be an error of some sort.

Protocol Risk also occurs when we use
\href{https://en.wikipedia.org/wiki/Data_type}{Data Types}: whenever we
change the data type, we need to correct the usages of that type. Note
above, I've given the \texttt{JavaScript} example, but I'm going to
switch to \texttt{TypeScript} now:

\begin{verbatim}
interface BInput {
    a: string,
    b: string,
    c: string,
    d: string
}

function b(in: BInput): string {
    return in.a + in.b + in.c + in.d;
}

function a() {
    var bOut = b({a: 1, b: 2, c: 3);        // new parameter d missing
    return "something "+bOut;
}
\end{verbatim}

By using a
\href{https://en.wikipedia.org/wiki/Type_system\#Static_type_checking}{static
type checker}, we can identify issues like this, but there is a
tradeoff: we mitigate Protocol Risk, because we define the protocols
\emph{once only} in the program, and ensure that usages all match the
specification. But the tradeoff is (as we can see in the TypeScript
code) more \emph{finger-typing}, which means Codebase Risk in some
circumstances.

Nevertheless, static type checking is so prevalent in software that
clearly in most cases, the trade-off has been worth it: Even languages
like \href{https://clojure.org}{Clojure} have been retro-fitted with
\href{https://github.com/clojure/core.typed/wiki/User-Guide}{type
checkers}.

Let's look at some further types of Protocol Risk:

\hypertarget{protocol-incompatibility-risk}{%
\subsection{Protocol Incompatibility
Risk}\label{protocol-incompatibility-risk}}

The people you find it \emph{easiest} to communicate with are your
friends and family, those closest to you. That's because you're all
familiar with the same protocols. Someone from a foreign country,
speaking a different language and having a different culture, will
essentially have a completely incompatible protocol for spoken
communication to you.

Within software, there are also competing, incompatible protocols for
the same things, which is maddening when your protocol isn't supported.
Although the world seems to be standardizing, there used to be
\emph{hundreds} of different image formats. Photographs often use
\href{https://en.wikipedia.org/wiki/TIFF}{TIFF},
\href{https://en.wikipedia.org/wiki/Raw_image_format}{RAW} or
\href{https://en.wikipedia.org/wiki/JPEG}{JPEG}, whilst we also have
\href{https://en.wikipedia.org/wiki/Scalable_Vector_Graphics}{SVG} for
vector graphics, \href{https://en.wikipedia.org/wiki/GIF}{GIF} for
images and animations and
\href{https://en.wikipedia.org/wiki/Portable_Network_Graphics}{PNG} for
other bitmap graphics.

\hypertarget{protocol-versioning-risk}{%
\subsection{Protocol Versioning Risk}\label{protocol-versioning-risk}}

Even when systems are talking the same protocol, there can be problems.
When we have multiple, different systems owned by different parties, on
their own upgrade cycles, we have \textbf{Protocol Versioning Risk}: the
risk that either client or supplier could start talking in a version of
the protocol that the other side hasn't learnt yet. There are various
mitigating strategies for this. We'll look at two now: \textbf{Backwards
Compatibility} and \textbf{Forwards Compatibility}.

\hypertarget{backward-compatibility}{%
\subsubsection{Backward Compatibility}\label{backward-compatibility}}

Backwards Compatibility mitigates Protocol Versioning Risk. Quite
simply, this means, supporting the old format until it falls out of use.
If a supplier is pushing for a change in protocol it either must ensure
that it is Backwards Compatible with the clients it is communicating
with, or make sure they are upgraded concurrently. When building
\href{https://en.wikipedia.org/wiki/Web_service}{web services}, for
example, it's common practice to version all APIs so that you can manage
the migration. Something like this:

\begin{itemize}
\tightlist
\item
  Supplier publishes \texttt{/api/v1/something}.
\item
  Clients use \texttt{/api/v1/something}.
\item
  Supplier publishes \texttt{/api/v2/something}.
\item
  Clients start using \texttt{/api/v2/something}.
\item
  Clients (eventually) stop using \texttt{/api/v2/something}.
\item
  Supplier retires \texttt{/api/v2/something} API.
\end{itemize}

\hypertarget{forward-compatibility}{%
\subsubsection{Forward Compatibility}\label{forward-compatibility}}

\texttt{HTML} and \texttt{HTTP} provide ``graceful failure'' to mitigate
Protocol Risk: while its expected that all clients can parse the syntax
of \texttt{HTML} and \texttt{HTTP}, it's not necessary for them to be
able to handle all of the tags, attributes and rules they see. The
specification for both these standards is that if you don't understand
something, ignore it. Designing with this in mind means that old clients
can always at least cope with new features, but it's not always
possible.

\texttt{JavaScript} \emph{can't} support this: because the meaning of
the next instruction will often depend on the result of the previous
one.

Do human languages support this? To some extent! New words are added to
our languages all the time. When we come across a new word, we can
either ignore it, guess the meaning, ask or look it up. In this way,
human language has \textbf{Forward Compatibility} features built in.

\hypertarget{protocol-implementation-risk}{%
\subsection{Protocol Implementation
Risk}\label{protocol-implementation-risk}}

A second aspect of Protocol Risk exists in heterogeneous computing
environments, where protocols have been independently implemented based
on standards. For example, there are now so many different browsers, all
supporting variations of \texttt{HTTP}, \texttt{HTML} and
\texttt{JavaScript} that it becomes impossible to test comprehensively
over all the different versions. To mitigate as much Protocol Risk as
possible, generally we test web sites in a subset of browsers, and use a
lowest-common-denominator approach to choosing protocol and language
features.

\hypertarget{messages}{%
\section{Messages}\label{messages}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_message_risks-400dpi.png}
\caption{Message Risk\label{communication_message_risks.png}}
\end{figure}

Although Shannon's Communication Theory is about transmitting
\textbf{Messages}, messages are really encoded \textbf{Ideas} and
\textbf{Concepts}, from an \textbf{Internal Model}. Let's break down
some of the risks associated with this:

\hypertarget{internal-model-risk}{%
\subsection{Internal Model Risk}\label{internal-model-risk}}

When we construct messages in a conversation, we have to make judgements
about what the other person already knows. For example, if I want to
tell you about a new
\href{https://en.wikipedia.org/wiki/JDBC_driver}{JDBC Driver}, this
pre-assumes that you know what JDBC is: the message has a dependency on
prior knowledge. Or, When talking to children, it's often hard work
because they \emph{assume} that you have knowledge of everything they
do.

This is called
\href{https://en.wikipedia.org/wiki/Theory_of_mind}{Theory Of Mind}: the
appreciation that your knowledge is different to other people's, and
adjusting you messages accordingly. When teaching, this is called
\href{https://en.wikipedia.org/wiki/Curse_of_knowledge}{The Curse Of
Knowledge}: teachers have difficulty understanding students' problems
\emph{because they already understand the subject}.

\hypertarget{message-risk}{%
\subsection{Message Risk}\label{message-risk}}

A second, related problem is actually Dependency Risk, which is covered
more thoroughly in a later chapter. Often, to understand a new message,
you have to have followed everything up to that point already.

The same \textbf{Message Dependency Risk} exists for computer software:
if there is replication going on between instances of an application,
and one of the instances misses some messages, you end up with a
``\href{https://en.wikipedia.org/wiki/Split-brain_(computing)}{Split
Brain}'' scenario, where later messages can't be processed because they
refer to an application state that doesn't exist. For example, a message
saying:

\begin{verbatim}
Update user 53's surname to 'Jones'
\end{verbatim}

only makes sense if the application has previously processed the message

\begin{verbatim}
Create user 53 with surname 'Smith'
\end{verbatim}

\hypertarget{misinterpretation-risk}{%
\subsection{Misinterpretation Risk}\label{misinterpretation-risk}}

For people, nothing exists unless we have a name for it. The world is
just atoms, but we don't think like this. \emph{The name is the thing}.

\begin{quotation}

``The famous pipe. How people reproached me for it! And yet, could you
stuff my pipe? No, it's just a representation, is it not? So if I had
written on my picture ``This is a pipe'', I'd have been lying!''

\sourceatright{\href{https://en.wikipedia.org/wiki/The_Treachery_of_Images}{\textemdash  Rene Magritte, of \emph{The Treachery of Images}}}
\end{quotation}

People don't rely on rigorous definitions of abstractions like computers
do; we make do with fuzzy definitions of concepts and ideas. We rely on
Abstraction to move between the name of a thing and the \emph{idea of a
thing}.

This brings about Misinterpretation Risk: names are not \emph{precise},
and concepts mean different things to different people. We can't be sure
that other people have the same meaning for a name that we have.

\hypertarget{invisibility-risk}{%
\subsection{Invisibility Risk}\label{invisibility-risk}}

Another cost of Abstraction is Invisibility Risk. While abstraction is a
massively powerful technique, (as we saw above, Protocols allow things
like the Internet to happen) it lets the function of a thing hide behind
the layers of abstraction and become invisible.

\hypertarget{invisibility-risk-in-conversation}{%
\subsubsection{Invisibility Risk In
Conversation}\label{invisibility-risk-in-conversation}}

Invisibility Risk is risk due to information not sent. Because humans
don't need a complete understanding of a concept to use it, we can cope
with some Invisibility Risk in communication, and this saves us time
when we're talking. It would be \emph{painful} to have conversations if,
say, the other person needed to understand everything about how cars
worked in order to discuss cars.

For people, Abstraction is a tool that we can use to refer to other
concepts, without necessarily knowing how the concepts work. This
divorcing of ``what'' from ``how'' is the essence of abstraction and is
what makes language useful.

The debt of Invisibility Risk comes due when you realise that \emph{not}
being given the details \emph{prevents} you from reasoning about it
effectively. Let's think about this in the context of a project status
meeting, for example:

\begin{itemize}
\tightlist
\item
  Can you be sure that the status update contains all the details you
  need to know?
\item
  Is the person giving the update wrong or lying?
\item
  Do you know enough about the details of what's being discussed in
  order to make informed decisions about how the project is going?
\end{itemize}

\hypertarget{invisibility-risk-in-software}{%
\subsubsection{Invisibility Risk In
Software}\label{invisibility-risk-in-software}}

Invisibility Risk is everywhere in software. Let's consider what happens
when, in your program, you create a new function, \textbf{f}:

\begin{itemize}
\tightlist
\item
  First, by creating \textbf{f}, you have \emph{given a piece of
  functionality a name}, which is abstraction.
\item
  Second, \textbf{f} \emph{supplies} functionality to clients, so we
  have created a client-supplier relationship.
\item
  Third, these parties now need to communicate, and this will require a
  protocol. In a programming language, this protocol is the arguments
  passed to \textbf{f}, and the response \emph{back} from \textbf{f}.
\end{itemize}

But something else also happens: By creating \textbf{f}, you are saying
``I now have this operation. The details, I won't mention again, but
from now on, it's called \textbf{f}'' Suddenly, the implementation of
``\textbf{f}'' hides and it is working invisibly. Things go on in
\textbf{f} that people don't necessarily need to understand. There may
be some documentation, or tacit knowledge around what \textbf{f} is, and
what it does, but it's not necessarily right.

\emph{Referring to \textbf{f} is a much simpler job than understanding
\textbf{f}.}

We try to mitigate this via (for the most part) documentation, but this
is a terrible deal: because we can't understand the original,
(un-abstracted) implementation, we now need to write some simpler
documentation, which \emph{explains} the abstraction, in terms of
further abstractions, and this is where things start to get murky.

Invisibility Risk is mainly Hidden Risk. (Mostly, \emph{you don't know
what you don't know}.) But you can carelessly \emph{hide things from
yourself} with software:

\begin{itemize}
\tightlist
\item
  Adding a thread to an application that doesn't report whether it's
  worked, failed, or is running out of control and consuming all the
  cycles of the CPU.
\item
  Redundancy can increase reliability, but only if you know when servers
  fail, and fix them quickly. Otherwise, you only see problems when the
  last server fails.
\item
  When building a web-service, can you assume that it's working for the
  users in the way you want it to?
\end{itemize}

When you build a software service, or even implement a thread, ask
yourself: ``How will I know next week that this is working properly?''
If the answer involves manual work and investigation, then your
implementation has just cost you in Invisibility Risk.

\hypertarget{internal-models}{%
\section{Internal Models}\label{internal-models}}

So finally, we are coming to the root of the problem: communication is
about transferring ideas and concepts from one Internal Model to
another.

The communication process so far has been fraught with risks, but we
have a few more to come.

\hypertarget{trust-belief-risk}{%
\subsection{Trust \& Belief Risk}\label{trust-belief-risk}}

Although protocols can sometimes handle security features of
communication (such as
\href{https://en.wikipedia.org/wiki/Authentication}{Authentication} and
preventing
\href{https://en.wikipedia.org/wiki/Man-in-the-middle_attack}{man-in-the-middle
attacks}), trust goes further than this, it is the flip-side of Agency
Risk, which we will look at later: can you be sure that the other party
in the communication is acting in your best interests?

Even if the receiver trusts the communicator, they may not believe the
message. Let's look at some reasons for that:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/World_view}{Weltanschauung (World
  View)}: The ethics, values and beliefs in the receiver's Internal
  Model may be incompatible to those from the sender.
\item
  \href{https://en.wikipedia.org/wiki/Relativism}{Relativism} is the
  concept that there are no universal truths. Every truth is from a
  frame of reference. For example, what constitutes \emph{offensive
  language} is dependent on the listener.
\item
  \href{https://en.wikipedia.org/wiki/Psycholinguistics}{Psycholinguistics}
  is the study of humans aquire languages. There are different languages
  and dialects, (and \emph{industry dialects}), and we all understand
  language in different ways, take different meanings and apply
  different contexts to the messages.
\end{itemize}

From the point-of-view of Marketing Communications, choosing the right
message is part of the battle. You are trying to communicate your idea
in such a way as to mitigate Trust \& Belief Risk.

\hypertarget{learning-curve-risk}{%
\subsection{Learning-Curve Risk}\label{learning-curve-risk}}

If the messages we are receiving force us to update our Internal Model
too much, we can suffer from the problem of ``too steep a
\href{https://en.wikipedia.org/wiki/Learning_curve}{Learning Curve}'' or
``\href{https://en.wikipedia.org/wiki/Information_overload}{Information
Overload}'', where the messages force us to adapt our Internal Model too
quickly for our brains to keep up.

Commonly, the easiest option is just to ignore the information channel
completely in these cases.

\hypertarget{reading-code}{%
\subsection{Reading Code}\label{reading-code}}

It's often been said that code is \emph{harder to read than to write}:

\begin{quotation}

``If you ask a software developer what they spend their time doing,
they'll tell you that they spend most of their time writing code.
However, if you actually observe what software developers spend their
time doing, you'll find that they spend most of their time trying to
understand code.'' -
\href{https://blog.codinghorror.com/when-understanding-means-rewriting/}{When
Understanding Means Rewriting, \emph{Coding Horror}}

\end{quotation}

By now it should be clear that it's going to be \emph{both} quite hard
to read and write: the protocol of code is actually designed for the
purpose of machines communicating, not primarily for people to
understand. Making code human readable is a secondary concern to making
it machine readable.

But now we should be able to see the reasons it's harder to read than
write too:

\begin{itemize}
\tightlist
\item
  When reading code, you are having to shift your Internal Model to
  wherever the code is, accepting decisions that you might not agree
  with and accepting counter-intuitive logical leaps. i.e.~Learning
  Curve Risk. \emph{(cf.
  \href{https://en.wikipedia.org/wiki/Principle_of_least_astonishment}{Principle
  of Least Surprise})}
\item
  There is no Feedback Loop between your Internal Model and the Reality
  of the code, opening you up to Misinterpretation Risk. When you write
  code, your compiler and tests give you this.
\item
  While reading code \emph{takes less time} than writing it, this also
  means the Learning Curve is steeper.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_internal_model_risks-400dpi.png}
\caption{Internal Model
Risks\label{communication_internal_model_risks.png}}
\end{figure}

\hypertarget{communication-risk-wrap-up}{%
\section{Communication Risk Wrap Up}\label{communication-risk-wrap-up}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_3-400dpi.png}
\caption{Communication Marketing\label{communication_3.png}}
\end{figure}

In this chapter, we've looked at Communication Risk itself, and broken
it down into six sub-types of risk, as shown in Figure
\ref{communication_3.png}. Again, we are calling out \emph{patterns}
here: you can equally classify communication risks in other ways.
However, concepts like Learning-Curve Risk and Invisibility Risk we will
need again. Also, note how these risks are, in a sense, opposite:

\begin{itemize}
\tightlist
\item
  The higher the level of abstraction you use, the less you need to
  learn, but at the expense of extra invisibility.
\item
  The more you peel back abstractions, the more you expose, but the more
  complex things are to understand.
\end{itemize}

In the next chapter, we will address complexity head-on, and understand
how Complexity Risk manifests in software projects.

\hypertarget{complexity-risk}{%
\chapter{Complexity Risk}\label{complexity-risk}}

Complexity Risk are the risks to your project due to its underlying
``complexity''. Over the next few chapters, we'll break down exactly
what we mean by complexity, looking at Dependency Risk and Boundary Risk
as two particular sub-types of Complexity Risk.

\hypertarget{codebase-risk}{%
\section{Codebase Risk}\label{codebase-risk}}

In this chapter, we're going to start by looking at \emph{code you
write}: the size of your code-base, the number of modules, the
interconnectedness of the modules and how well-factored the code is.

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/complexity-risk-400dpi.png}
\caption{Complexity Risk and Codebase Risk\label{complexity-risk.png}}
\end{figure}

You could think of this as Codebase Risk. We'll look at three separate
measures of codebase complexity and talk about Technical Debt, before
looking at areas in which Complexity Risk is at it's greatest.

\hypertarget{kolmogorov-complexity}{%
\section{Kolmogorov Complexity}\label{kolmogorov-complexity}}

The standard Computer-Science definition of complexity, is
\href{https://en.wikipedia.org/wiki/Kolmogorov_complexity}{Kolmogorov
Complexity}. This is:

\begin{quotation}

``\ldots{}the length of the shortest computer program (in a
predetermined programming language) that produces the object as
output.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Kolmogorov_complexity}{Kolmogorov Complexity, Wikipedia}}
\end{quotation}

This is a fairly handy definition for us, as it means that to in writing
software to solve a problem, there is a lower bound on the size of the
software we write. In practice, this is pretty much impossible to
quantify. But that doesn't really matter: the techniques for
\emph{moving in that direction} are all that we are interested in, and
this basically amounts to compression.

Let's say we wanted to write a JavaScript program to output this string:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd}
\end{Highlighting}
\end{Shaded}

We might choose this representation:

\begin{Shaded}
\begin{Highlighting}[]

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return} \StringTok{"abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd"}\NormalTok{ (}\DecValTok{45}\NormalTok{)}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

The numbers in brackets indicate how many symbols each line contains, so
in total, this code block contains \textbf{53 symbols}, if you count
\texttt{function}, \texttt{out} and \texttt{return} as one symbol each.

But, if we write it like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                                    (}\DecValTok{11}\NormalTok{)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return}\NormalTok{ ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{        (}\DecValTok{16}\NormalTok{)}
\NormalTok{        ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{+}\NormalTok{ABCD}\OperatorTok{;}\NormalTok{                               (}\DecValTok{6}\NormalTok{ )}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

With this version, we now have \textbf{41 symbols} (\textbf{ABCD} is a
single symbol, because we could have called it anything). And with this
version:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                                    (}\DecValTok{11}\NormalTok{)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                                      (}\DecValTok{7}\NormalTok{ )}
    \ControlFlowTok{return} \VariableTok{ABCD}\NormalTok{.}\AttributeTok{repeat}\NormalTok{(}\DecValTok{10}\NormalTok{)                            (}\DecValTok{7}\NormalTok{ )}
\OperatorTok{\}}\NormalTok{                                                     (}\DecValTok{1}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\ldots{} we have \textbf{26 symbols}.

\hypertarget{abstraction}{%
\subsection{Abstraction}\label{abstraction}}

What's happening here is that we're \emph{exploiting a pattern}: we
noticed that \texttt{ABCD} occurs several times, so we defined it a
single time and then used it over and over, like a stamp.

By applying abstraction, we can improve in the direction of the
Kolmogorov limit. And, by allowing ourselves to say that \emph{symbols}
(like \texttt{out} and \texttt{ABCD}) are worth one complexity point,
we've allowed that we can be descriptive in our \texttt{function} name
and \texttt{const}. Naming things is an important part of abstraction,
because to use something, you have to be able to refer to it.

\hypertarget{trade-off}{%
\subsection{Trade-Off}\label{trade-off}}

Generally, the more complex a piece of software is, the more difficulty
users will have understanding it, and the more difficulty developers
will have changing it. We should prefer the third version of our code
over either the first or second because of it's brevity.

But we could go further down into
\href{https://en.wikipedia.org/wiki/Code_golf}{Code Golf} territory.
This javascript program plays
\href{https://en.wikipedia.org/wiki/Fizz_buzz}{FizzBuzz} up to 100, but
is less readable than you might hope:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{<}\DecValTok{100}\OperatorTok{;}\NormalTok{)}\VariableTok{document}\NormalTok{.}\AttributeTok{write}\NormalTok{(((}\OperatorTok{++}\NormalTok{i}\OperatorTok{%}\DecValTok{3}\OperatorTok{?}\StringTok{''}\NormalTok{:}\StringTok{'Fizz'}\NormalTok{)}\OperatorTok{+}
\NormalTok{(i}\OperatorTok{%}\DecValTok{5}\OperatorTok{?}\StringTok{''}\NormalTok{:}\StringTok{'Buzz'}\NormalTok{)}\OperatorTok{||}\NormalTok{i)}\OperatorTok{+}\StringTok{"<br>"}\NormalTok{)                           (}\DecValTok{62}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

So there is at some point a trade-off to be made between Complexity Risk
and Communication Risk. After a certain point, reducing Kolmogorov
Complexity further risks making the program less intelligible.

\hypertarget{connectivity}{%
\section{Connectivity}\label{connectivity}}

A second, useful measure of complexity comes from graph theory, and that
is the connectivity of a graph:

\begin{quotation}

``\ldots{}the minimum number of elements (nodes or edges) that need to
be removed to disconnect the remaining nodes from each other''

\sourceatright{\href{https://en.wikipedia.org/wiki/Connectivity_(graph_theory}{\textemdash  Connectivity, \emph{Wikipedia}})}
\end{quotation}

To see this in action, have a look at the below graph:

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/connectivity_1-400dpi.png}
\caption{Graph 1, 2-Connected\label{connectivity_1.png}}
\end{figure}

It has 10 vertices, labelled \textbf{a} to \textbf{j}, and it has 15
edges (or links) connecting the vertices together. If any single edge
were removed from Figure \ref{connectivity_1.png}, the 10 vertices would
still be linked together. Because of this, we can say that the graph is
\emph{2-connected}. That is, to disconnect any single vertex, you'd have
to remove \emph{at least} two edges.

As a slight aside, let's consider the \textbf{Kolmogorov Complexity} of
this graph, by inventing a mini-language to describe graphs. It could
look something like this:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{<}\NormalTok{item}\OperatorTok{>} \OperatorTok{:}\NormalTok{ [}\OperatorTok{<}\NormalTok{item}\OperatorTok{>,}\NormalTok{]}\OperatorTok{*} \OperatorTok{<}\NormalTok{item}\OperatorTok{>}\NormalTok{    # Indicates that the item}
\NormalTok{                              # before the colon}
\NormalTok{                              # has a connection to all}
\NormalTok{                              # the items after the colon}
\end{Highlighting}
\end{Shaded}

So our graph could be defined like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{:}\NormalTok{ b}\OperatorTok{,}\NormalTok{c}\OperatorTok{,}\NormalTok{d}
\NormalTok{b}\OperatorTok{:}\NormalTok{ c}\OperatorTok{,}\NormalTok{f}\OperatorTok{,}\NormalTok{e}
\NormalTok{c}\OperatorTok{:}\NormalTok{ f}\OperatorTok{,}\NormalTok{d}
\NormalTok{d}\OperatorTok{:}\NormalTok{ j}
\NormalTok{e}\OperatorTok{:}\NormalTok{ h}\OperatorTok{,}\NormalTok{j}
\NormalTok{f}\OperatorTok{:}\NormalTok{ h}
\NormalTok{g}\OperatorTok{:}\NormalTok{ j}
\NormalTok{h}\OperatorTok{:}\NormalTok{ i}
\NormalTok{i}\OperatorTok{:}\NormalTok{ j}
\NormalTok{                                                      (}\DecValTok{39}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's remove some of those extra links:

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/connectivity_2-400dpi.png}
\caption{Graph 2, 1-Connected\label{connectivity_2.png}}
\end{figure}

In this graph, I've removed 6 of the edges. Now, we're in a situation
where if any single edge is removed, the graph becomes
\emph{unconnected}. That is, it's broken into distinct chunks. So, it's
\emph{1-connected}.

The second graph is clearly simpler than the first. And, we can show
this by looking at the \textbf{Kolmogorov Complexity} in our little
language:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{:}\NormalTok{ d}\OperatorTok{,}\NormalTok{g}
\NormalTok{b}\OperatorTok{:}\NormalTok{ f}
\NormalTok{c}\OperatorTok{:}\NormalTok{ d}\OperatorTok{,}\NormalTok{f}
\NormalTok{d}\OperatorTok{:}\NormalTok{ j}
\NormalTok{f}\OperatorTok{:}\NormalTok{ h}
\NormalTok{e}\OperatorTok{:}\NormalTok{ h}
\NormalTok{h}\OperatorTok{:}\NormalTok{ i}
\NormalTok{                                                      (}\DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Connectivity} is also \textbf{Complexity}. This carries over
into software too: because heavily connected software is more complex
than less-connected software, it is harder to reason about and work
with, and the reason programs with greater connectivity are harder to
work with is that changing one module potentially impacts many others.
Let's dig into this further.

\hypertarget{hierarchies-and-modularisation}{%
\section{Hierarchies and
Modularisation}\label{hierarchies-and-modularisation}}

In the second, simplified graph, I've arranged it as a hierarchy, which
I can do now that it's only 1-connected. For 10 vertices, we need 9
edges to connect everything up. It's always:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  edges }\OperatorTok{=}\NormalTok{ vertices }\OperatorTok{-} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

Note that I could pick any hierarchy here: I don't have to start at
\textbf{c} (although it has the nice property that it has two roughly
even sub-trees attached to it).

How does this help us? Imagine if \textbf{a} - \textbf{j} were modules
of a software system, and the edges of the graph showed communications
between the different sub-systems. In the first graph, we're in a worse
position:

\begin{itemize}
\tightlist
\item
  Who's in charge? What deals with what?
\item
  Can I isolate a component and change it safely?
\item
  What happens if one component disappears?
\end{itemize}

But, in the second graph, it's easier to reason about, because of the
reduced number of connections and the new hierarchy of organisation.

On the down-side, perhaps our messages have farther to go now: in the
original, \textbf{i} could send a message straight to \textbf{j}, but
now we have to go all the way via \textbf{c}. But this is the basis of
\href{https://en.wikipedia.org/wiki/Modular_programming}{Modularisation}
and \href{https://en.wikipedia.org/wiki/Hierarchy}{Hierarchy}.

As a tool to battle complexity, we don't just see this in software, but
everywhere in our lives. Society, business, nature and even our bodies:

\begin{itemize}
\tightlist
\item
  \textbf{Organelles} - such as
  \href{https://en.wikipedia.org/wiki/Mitochondrion}{Mitochondria}.
\item
  \textbf{Cells} - such as blood cells, nerve cells, skin cells in the
  \href{https://en.wikipedia.org/wiki/List_of_distinct_cell_types_in_the_adult_human_body}{Human
  Body}.
\item
  \textbf{Organs} - like hearts livers, brains etc.
\item
  \textbf{Organisms} - like you and me.
\end{itemize}

The great complexity-reducing mechanism of modularisation is that
\emph{you only have to consider your local environment}.

\hypertarget{more-abstraction}{%
\section{More Abstraction}\label{more-abstraction}}

A variation on this graph connectivity metric is our third measure of
complexity,
\href{https://en.wikipedia.org/wiki/Cyclomatic_complexity}{Cyclomatic
Complexity}. This is:

\begin{verbatim}
Cyclomatic Complexity = edges  vertices + 2P,
\end{verbatim}

Where \textbf{P} is the number of \textbf{Connected Components}
(i.e.~distinct parts of the graph that aren't connected to one another
by any edges).

So, our first graph had a \textbf{Cyclomatic Complexity} of 7.
\texttt{(15\ -\ 10\ +\ 2)}, while our second was 1.
\texttt{(9\ -\ 10\ +\ 2)}.

Cyclomatic complexity is all about the number of different routes
through the program. The more branches a program has, the greater it's
cyclomatic complexity. Hence, this is a useful metric in Testing and
\href{https://en.wikipedia.org/wiki/Code_coverage}{Code Coverage}: the
more branches you have, the more tests you'll need to exercise them all.

Our second graph has a \textbf{Cyclomatic Complexity} of 1 (the
minimum), but we can go further through abstraction, because this
representation isn't minimal from a \textbf{Kolmogorov Complexity}
point-of-view. For example, we might observe that there are further
similarities in the graph that we can ``draw out'':

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/connectivity_3-400dpi.png}
\caption{Complexity 3\label{connectivity_3.png}}
\end{figure}

Here, we've spotted that the structure of subgraphs \textbf{P1} and
\textbf{P2} are the same: we can have the same functions there to
assemble those. Noticing and exploiting patterns of repetition is one of
the fundamental tools we have in the fight against Complexity Risk.

So, we've looked at some measures of software structure complexity, in
order that we can say ``this is more complex than this''. However, we've
not really said why complexity entails Risk. So let's address that now
by looking at two analogies, Mass and Technical Debt.

\hypertarget{complexity-is-mass}{%
\section{Complexity is Mass}\label{complexity-is-mass}}

The first way to look at complexity is as \textbf{Mass} : a software
project with more complexity has greater mass than one with less
complexity. Newton's Second Law states:

\begin{quotation}

F = \emph{m}\textbf{a}, ( Force = Mass x Acceleration )

\end{quotation}

That is, in order to move your project \emph{somewhere new}, and make it
do new things, you need to give it a push, and the more mass it has, the
more \textbf{Force} you'll need to move (accelerate) it.

You could stop here and say that the more lines of code a project
contains, the higher it's mass. And, that makes sense, because in order
to get it to do something new, you're likely to need to change more
lines.

But there is actually some underlying sense in which this is true in the
real, physical world too, as discussed in this
\href{https://www.youtube.com/user/1veritasium}{Veritasium} video. To
paraphrase:

\begin{quotation}

``Most of your mass you owe due to \(E=mc^2\) , you owe to the fact that
your mass is packed with energy, because of the \textbf{interactions}
between these quarks and gluon fluctuations in the gluon field\ldots{}
what we think of as ordinarily empty space\ldots{} that turns out to be
the thing that gives us most of our mass.''

\sourceatright{\href{https://www.youtube.com/watch?annotation_id=annotation_3771848421&feature=iv&src_vid=Xo232kyTsO0&v=Ztc6QPNUqls}{\textemdash  Your Mass is NOT From the Higgs Boson, \emph{Veritasium}}}
\end{quotation}

I'm not an expert in physics, \emph{at all}, and so there is every
chance that I am pushing this analogy too hard. But, substituting quarks
and gluons for pieces of software we can (in a very handwaving-y way)
say that more complex software has more \textbf{interactions} going on,
and therefore has more mass than simple software.

If we want to move \emph{fast} we need simple codebases.

At a basic level, Complexity Risk heavily impacts on Schedule Risk: more
complexity means you need more force to get things done, which takes
longer.

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/complexity-risk2-400dpi.png}
\caption{Complexity Risk and some
mitigations\label{complexity-risk2.png}}
\end{figure}

\hypertarget{technical-debt}{%
\section{Technical Debt}\label{technical-debt}}

The most common way we talk about unnecessary complexity in software is
as Technical Debt:

\begin{quotation}

``Shipping first time code is like going into debt. A little debt speeds
development so long as it is paid back promptly with a rewrite\ldots{}
The danger occurs when the debt is not repaid. Every minute spent on
not-quite-right code counts as interest on that debt. Entire engineering
organisations can be brought to a stand-still under the debt load of an
unconsolidated implementation, object-oriented or otherwise.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Technical_debt}{Ward Cunningham, 1992}}
\end{quotation}

Building a perfect first-time solution is a waste, because perfection
takes a long time. You're taking on more attendant Schedule Risk than
necessary and Meeting Reality more slowly than you could.

A quick-and-dirty, over-complex implementation mitigates the same
Feature Risk and allows you to Meet Reality faster.

But, having mitigated the Feature Risk, you are now carrying more
Complexity Risk than you necessarily need, and it's time to think about
how to \href{https://en.wikipedia.org/wiki/Code_refactoring}{Refactor}
the software to reduce this risk again.

\hypertarget{kitchen-analogy}{%
\section{Kitchen Analogy}\label{kitchen-analogy}}

It's often hard to make the case for minimising Technical Debt: it often
feels that there are more important priorities, especially when
technical debt can be ``swept under the carpet'' and forgotten about
until later. (See Discounting The Future.)

One helpful analogy I have found is to imagine your code-base is a
kitchen. After preparing a meal (i.e.~delivering the first
implementation), \emph{you need to tidy up the kitchen}. This is just
something everyone does as a matter of \emph{basic sanitation}.

Now of course, you could carry on with the messy kitchen. When tomorrow
comes and you need to make another meal, you find yourself needing to
wash up saucepans as you go, or working around the mess by using
different surfaces to chop on.

It's not long before someone comes down with food poisoning.

We wouldn't tolerate this behaviour in a restaurant kitchen, so why put
up with it in a software project?

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/complexity-risk-impact-400dpi.png}
\caption{Complexity Risk and it's
implications\label{complexity-risk-impact.png}}
\end{figure}

\hypertarget{feature-creep}{%
\section{Feature Creep}\label{feature-creep}}

In Brooks' essay ``No Silver Bullet - Essence and Accident in Software
Engineering'', a distinction is made between:

\begin{quotation}

\begin{itemize}
\tightlist
\item
  \textbf{Essence}: \emph{the difficulties inherent in the nature of the
  software.}
\end{itemize}

\end{quotation}

\begin{quotation}

\begin{itemize}
\tightlist
\item
  \textbf{Accident}: \emph{those difficulties that attend its production
  but are not inherent.}
\end{itemize}

\sourceatright{\href{https://en.wikipedia.org/wiki/No_Silver_Bullet}{\textemdash   Fred Brooks, \emph{No Silver Bullet}}}
\end{quotation}

The problem with this definition is that we are accepting features of
our software as \emph{essential}.

Applying Risk-First, if you want to mitigate some Feature Risk then you
have to pick up Complexity Risk as a result. But, that's a \emph{choice
you get to make}.

\begin{figure}
\centering
\includegraphics{images/generated/risks/feature/feature-fit-risk-400dpi.png}
\caption{Mitigating Feature Fit Risk (from Feature
Risk)\label{feature-fit-risk.png}}
\end{figure}

Therefore, \href{https://en.wikipedia.org/wiki/Feature_creep}{Feature
Creep} (or
\href{https://en.wikipedia.org/wiki/Gold_plating_(software_engineering)}{Gold
Plating}) is a failure to observe this basic equation: instead of
considering this trade off, you're building every feature possible. This
has an impact on Complexity Risk, which in turn impacts Communication
Risk and also Schedule Risk.

Sometimes, feature-creep happens because either managers feel they need
to keep their staff busy, or the staff decide on their own that they
need to keep themselves busy. This is something we'll return to in
Agency Risk.

\hypertarget{dead-end-risk}{%
\section{Dead-End Risk}\label{dead-end-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/complexity/dead-end-risk-400dpi.png}
\caption{Dead-End Risk\label{dead-end-risk.png}}
\end{figure}

Dead-End Risk is where you take an action that you \emph{think} is
useful, only to find out later that actually, it was a dead-end, and
your efforts were wasted.

For example, let's say that the Accounting sub-system needed password
protection (so you built this). Then the team realised that you needed a
way to \emph{change the password} (so you built that). Then, that you
needed to have more than one user of the Accounting system so they would
all need passwords (OK, fine).

Finally, the team realises that actually logging-in would be something
that all the sub-systems would need, and that it had already been
implemented more thoroughly by the Approvals sub-system.

At this point, you realise you're in a \textbf{Dead End}:

\begin{itemize}
\tightlist
\item
  \textbf{Option 1: Continue.} You carry on making minor incremental
  improvements to the accounting password system (carrying the extra
  Complexity Risk of the duplicated functionality).
\item
  \textbf{Option 2: Merge.} You rip out the accounting password system,
  and merge in the Approvals system, surfacing new, hidden Complexity
  Risk in the process, due to the difficulty in migrating users from the
  old to new way of working. There is Implementation Risk here.
\item
  \textbf{Option 3: Remove} You start again, trying to take into account
  both sets of requirements at the same time, again, possibly surfacing
  new hidden Complexity Risk due to the combined approach. Rewriting
  code or a whole project can seem like a way to mitigate Complexity
  Risk, but it usually doesn't work out too well. As Joel Spolsky says:
\end{itemize}

\begin{quotation}

There's a subtle reason that programmers always want to throw away the
code and start over. The reason is that they think the old code is a
mess. And here is the interesting observation: they are probably wrong.
The reason that they think the old code is a mess is because of a
cardinal, fundamental law of programming: \emph{It's harder to read code
than to write it.}

\sourceatright{\href{https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/}{\textemdash  Things You Should Never Do, Part 1, \emph{Joel Spolsky}}}
\end{quotation}

Sometimes, the path across the Risk Landscape will take you to dead
ends, and the only benefit to be gained is experience. No one
deliberately chooses a dead end - often you can take an action that
doesn't pay off, but frequently the dead end appears from nowhere: it's
a Hidden Risk. The source of a lot of this hidden risk is the complexity
of the risk landscape.

\href{https://en.wikipedia.org/wiki/Version_control}{Version Control
Systems} like \href{https://en.wikipedia.org/wiki/Git}{Git} are a useful
mitigation of Dead-End Risk, because using them means that at least you
can \emph{go back} to the point where you made the bad decision and go a
different way. Additionally, they provide you with backups against the
often inadvertent Dead-End Risk of someone wiping the hard-disk.

\hypertarget{where-complexity-hides}{%
\section{Where Complexity Hides}\label{where-complexity-hides}}

So far, we've focused mainly on Codebase Risk, but this isn't the only
place complexity appears in software. We're going to cover a few of
these areas now, but be warned, this is not a complete list by any
means:

\begin{itemize}
\tightlist
\item
  Algorithmic (Space and Time) Complexity
\item
  Memory Management
\item
  Protocols / Types
\item
  Concurrency / Mutability
\item
  Networks / Security
\item
  The Environment
\end{itemize}

\hypertarget{space-and-time-complexity}{%
\subsection{Space and Time Complexity}\label{space-and-time-complexity}}

There is a whole branch of complexity theory devoted to how the software
\emph{runs}, namely
\href{https://en.wikipedia.org/wiki/Big_O_notation}{Big O Complexity}.

Once running, an algorithm or data structure will consume space or
runtime dependent on it's performance characteristics, which may well
have an impact on the Operational Risk of the software. Using
off-the-shelf data structures and algorithms helps, but you still need
to know their performance characteristics.

The \href{http://bigocheatsheet.com}{Big O Cheat Sheet} is a wonderful
resource to investigate this further.

\hypertarget{memory-management}{%
\subsection{Memory Management}\label{memory-management}}

Memory Management (and more generally, all resource management in
software) is another place where Complexity Risk hides:

\begin{quotation}

``Memory leaks are a common error in programming, especially when using
languages that have no built in automatic garbage collection, such as C
and C++.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Memory_leak}{\textemdash  Memory Leak, \emph{Wikipedia}}}
\end{quotation}

\href{https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)}{Garbage
Collectors} (as found in Javascript or Java) offer you the deal that
they will mitigate the Complexity Risk of you having to manage your own
memory, but in return perhaps give you fewer guarantees about the
\emph{performance} of your software. Again, there are times when you
can't accommodate this Operational Risk, but these are rare and usually
only affect a small portion of an entire software-system.

\hypertarget{protocols-and-types}{%
\subsection{Protocols And Types}\label{protocols-and-types}}

As we saw in Communication Risk, whenever two components of a software
system need to interact, they have to establish a protocol for doing so.
As systems become more complex, and the connectedness increases, it
becomes hard to manage the risk around versioning protocols. This
becomes especially true when operating beyond the edge of the compiler's
domain.

Although type checking helps mitigate Protocol Risk in the small, when
software systems grow large it becomes hard to communicate their intent
and keep their degree of connectivity low, and you end up with the Big
Ball Of Mud:

\begin{quotation}

``A big ball of mud is a software system that lacks a perceivable
architecture. Although undesirable from a software engineering point of
view, such systems are common in practice due to business pressures,
developer turnover and code entropy.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Big_ball_of_mud}{\textemdash  Big Ball Of Mud, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{concurrency-mutability}{%
\subsection{Concurrency / Mutability}\label{concurrency-mutability}}

Although modern languages include plenty of concurrency primitives,
(such as the
\href{https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/package-summary.html}{java.util.concurrent}
libraries), concurrency is \emph{still} hard to get right.

\href{https://en.wikipedia.org/wiki/Race_condition}{Race conditions} and
\href{https://en.wikipedia.org/wiki/Deadlock}{Deadlocks} \emph{thrive}
in over-complicated concurrency designs: complexity issues are magnified
by concurrency concerns, and are also hard to test and debug.

Recently, languages such as Clojure have introduced
\href{https://en.wikipedia.org/wiki/Persistent_data_structure}{persistent
collections} to alleviate concurrency issues. The basic premise is that
any time you want to \emph{change} the contents of a collection, you get
given back a \emph{new collection}. So, any collection instance is
immutable once created. The tradeoff is again speed to mitigate
Complexity Risk.

An important lesson here is that choice of language can reduce
complexity: and we'll come back to this in Software Dependency Risk.

\hypertarget{networking-security}{%
\subsection{Networking / Security}\label{networking-security}}

There are plenty of Complexity Risk perils in \emph{anything} to do with
networked code, chief amongst them being error handling and (again)
protocol evolution.

In the case of security considerations, exploits \emph{thrive} on the
complexity of your code, and the weaknesses that occur because of it. In
particular, Schneier's Law says, never implement your own cryptographic
scheme:

\begin{quotation}

``Anyone, from the most clueless amateur to the best cryptographer, can
create an algorithm that he himself can't break. It's not even hard.
What is hard is creating an algorithm that no one else can break, even
after years of analysis.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Bruce_Schneier\#Cryptography}{Bruce Schneier, 1998} }
\end{quotation}

Luckily, most good languages include cryptographic libraries that you
can include to mitigate these Complexity Risks from your own code-base.

This is a strong argument for the use of libraries. But, when should you
use a library and when should you implement yourself? This is again
covered in the chapter on Software Dependency Risk.

\hypertarget{the-environment}{%
\subsection{The Environment}\label{the-environment}}

The complexity of software tends to reflect the complexity of the
environment it runs in, and complex software environments are more
difficult to reason about, and more susceptible to Operational Risk and
Security-Risk.

In particular, when we talk about the environment, we are talking about
the number of dependencies that the software has, and the risks we face
when relying on those dependencies. So the next stop in the tour is a
closer look at Dependency Risk.

\hypertarget{dependency-risk}{%
\chapter{Dependency Risk}\label{dependency-risk}}

Dependency Risk is the risk you take on whenever you have a dependency
on something (or someone) else.

One simple example could be that the software service you write might
depend on hardware to run on: If the server goes down, the service goes
down too. In turn, the server depends on electricity from a supplier, as
well as a network connection from a provider. If either of these
dependencies aren't met, the service is out of commission.

Dependencies can be on \emph{events}, \emph{people}, \emph{teams},
\emph{work}, \emph{processes}, \emph{software}, \emph{services},
\emph{money} and pretty much \emph{any resource}, and while every
project will need some of those, they also \emph{add risk} to any
project because the reliability of the project itself is now a function
involving the reliability of the dependency.

In order to avoid repetition, and also to break down this large topic,
we're going to look at this over 7 chapters:

\begin{itemize}
\tightlist
\item
  In this first chapter will look at dependencies \emph{in general}, and
  some of the variations of Dependency Risk.
\item
  Next, we'll look at Scarcity Risk, because time, money and staff are
  scarce resources in every project.
\item
  We'll cover Deadline Risk, and discuss the purpose of Events and
  Deadlines, and how they enable us to coordinate around dependency use.
\item
  Then, we'll move on to look specifically at Software Dependency Risk,
  covering using libraries, software services and building on top of the
  work of others.
\item
  Then, we'll take a look at Process Risk, which is still Dependency
  Risk, but we'll be considering more organisational factors and how
  bureaucracy comes into the picture.
\item
  After that, we'll take a closer look at Boundary Risk and Dead-End
  Risk. These are the risks you face in making choices about what to
  depend on.
\item
  Finally, we'll wrap up this analysis with a look at some of the
  specific problems around depending on other people or businesses in
  Agency Risk.
\end{itemize}

\hypertarget{why-have-dependencies}{%
\section{Why Have Dependencies?}\label{why-have-dependencies}}

Luckily for us, the things we depend on in life are, for the most part,
abundant: water to drink, air to breathe, light, heat and most of the
time, food for energy.

This isn't even lucky though: life has adapted to build dependencies on
things that it can \emph{rely} on.

Although life exists at the bottom of the ocean around
\href{https://en.wikipedia.org/wiki/Hydrothermal_vent}{hydrothermal
vents}, it is a very different kind of life to us, and has a different
set of dependencies given it's circumstances.

This tells us a lot about Dependency Risk right here:

\begin{itemize}
\tightlist
\item
  On the one hand, \emph{depending on something} is very often helpful,
  and quite often essential. (For example, all life seem to depend on
  water).
\item
  However, as soon as you have dependencies, you need to take into
  account of their \emph{reliability}. (Living near a river or stream
  gives you access to fresh water, for example).
\item
  Successful organisms \emph{adapt} to the dependencies available to
  them (like the thermal vent creatures).
\item
  There is likely to be \emph{competition} for a dependency when it is
  scarce (think of droughts and famine).
\end{itemize}

So, dependencies are a trade-off. They give with one hand and take with
the other. Our modern lives are full of dependency (just think of the
chains of dependency needed for putting a packet of biscuits on a
supermarket shelf, for example), but we accept this risk because it
makes life \emph{easier}.

Let's look at four types of risk that apply to every dependency: Fit,
Reliability, Invisibility and Complexity.

\hypertarget{fit-risk}{%
\section{Fit Risk}\label{fit-risk}}

In order to illustrate some of the different Dependency Risks, let's
introduce a running example: trying to get to work each day. There are
probably a few alternative ways to make your journey each day, such as
\emph{by car}, \emph{walking} or \emph{by bus}. These are all
alternative dependencies but give you the same \emph{feature}: they'll
get you there.

Normally, we'll use the same dependency each day. This speaks to the
fact that each of these approaches has different Feature Fit Risk.
Perhaps you choose going by bus over going by car because of the risk
that owning the car is expensive, or that you might not be able to find
somewhere to park it.

But the bus will take you to lots of in-between places you \emph{didn't}
want to go. This is also Feature Fit Risk and we saw this already in the
chapter on Feature Risk. There, we considered two problems:

\begin{itemize}
\tightlist
\item
  The feature (or now, dependency) doesn't provide all the functionality
  you need. This was Feature Fit Risk. An example might be your
  supermarket not stocking everything you want to buy.
\item
  The feature / dependency provides far too much, and you have to accept
  more complexity than you need. This was Conceptual Integrity Risk. An
  example of this might be the supermarket being \emph{too big}, and you
  spend a lot longer navigating it than you wanted to.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/dependency/dependency-risk-fit-400dpi.png}
\caption{Two-Dimensions of Feature Fit for the
bus-ride\label{dependency-risk-fit.png}}
\end{figure}

\hypertarget{reliability-risk}{%
\section{Reliability Risk}\label{reliability-risk}}

This points at the problem that when we use an external dependency, we
are at the mercy of its reliability.

\begin{quotation}

``\ldots{} Reliability describes the ability of a system or component to
function under stated conditions for a specified period of time.''

\sourceatright{\href{https://en.m.wikipedia.org/wiki/Reliability_engineering}{\textemdash  Reliability Engineering, \emph{Wikipedia}}}
\end{quotation}

\begin{figure}
\centering
\includegraphics{images/generated/risks/dependency/reliability-risk-400dpi.png}
\caption{Reliability Risk\label{reliability-risk.png}}
\end{figure}

Unreliability manifests itself when a dependency fails you under certain
sets of circumstances. It's easy to think about reliability for
something like a bus: sometimes, it's late due to weather, or cancelled
due to driver sickness, or the route changes unexpectedly due to road
works.

In software, it's no different: Unreliability is the flip-side of
Feature Implementation Risk. It's caused in the gap between the real
behaviour of the software and the expectations for it.

There is an upper bound on the reliability of the software you write,
and this is based on the dependencies you use and (in turn) the
reliability of those dependencies:

\begin{itemize}
\tightlist
\item
  If a component \textbf{A} depends on component \textbf{B}, unless
  there is some extra redundancy around \textbf{B}, then \textbf{A}
  \emph{can't} be more reliable than \textbf{B}.
\item
  Is \textbf{A} or \textbf{B} a
  \href{https://en.wikipedia.org/wiki/Single_point_of_failure}{Single
  Point Of Failure} in a system?
\item
  Are there bugs in \textbf{B} that are going to prevent it working
  correctly in all circumstances?
\end{itemize}

This kind of stuff is encapsulated in the science of
\href{https://en.wikipedia.org/wiki/Reliability_engineering}{Reliability
Engineering}. For example,
\href{https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis}{Failure
Mode and Effects Analysis (FEMA)}:

\begin{quotation}

``\ldots{}was one of the first highly structured, systematic techniques
for failure analysis. It was developed by reliability engineers in the
late 1950s to study problems that might arise from malfunctions of
military systems.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis}{\textemdash  FEMA, \emph{Wikipedia}}}
\end{quotation}

This was applied on NASA missions, and then in the 1970's to car design
following the
\href{https://en.wikipedia.org/wiki/Ford_Pinto\#Design_flaws_and_ensuing_lawsuits}{Ford
Pinto exploding car} affair.

\hypertarget{proxies-for-reliability}{%
\section{Proxies For Reliability}\label{proxies-for-reliability}}

Because of Trust Risk and Invisibility Risk, we cannot always establish
reliability for a dependency, and this is a huge area of concern in
software when choosing dependencies, as we will see in the chapter on
Software Dependency Risk.

In the Communication Risk chapter we looked at Marketing Communications
and talked about the levels of awareness that you could have with a
dependency.

Let's apply this to our Bus scenario:

\begin{itemize}
\tightlist
\item
  Am I aware that there is public transport in my area?
\item
  How do I find out about the different options?
\item
  How do I choose between buses, taxis, cars etc.
\item
  How do I understand the timetable, and apply it to my problem?
\item
  Is it a reliable enough solution?
\end{itemize}

\hypertarget{silo-mentality}{%
\subsection{Silo Mentality}\label{silo-mentality}}

Finding out about bus schedules is easy. But in a large company,
Communication Risk and especially Invisibility Risk are huge problems.
This tends to get called
``\href{https://en.wikipedia.org/wiki/Information_silo\#Silo_mentality}{Silo
Mentality}'', that is, ignoring what else is going on in other divisions
of the company or
\href{https://en.wikipedia.org/wiki/Not_invented_here}{``not invented
here''} syndrome:

\begin{quotation}

``In management the term silo mentality often refers to information
silos in organisations. Silo mentality is caused by divergent goals of
different organisational units.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Information_silo\#Silo_mentality}{\textemdash  Silo Mentality, \emph{Wikipedia}}}
\end{quotation}

Ironically, \emph{more communication} might not be the answer, because
even with more communication you still cannot determine reliability. If
channels are provided to discover functionality in other teams you can
still run into Trust Risk (why should I believe in the quality of this
dependency?) or Agency Risk (unwarranted self-promotion).

\hypertarget{invisibility-risk-1}{%
\section{Invisibility Risk}\label{invisibility-risk-1}}

While dependencies (like the bus, or the supermarket) make life simpler
for you, they do this by taking on complexity for you.

In our software, Dependencies are a way to manage Complexity Risk, and
we'll investigate that in much more detail in Software Dependency Risk.
The reason for this is that a dependency gives you an abstraction: you
no longer need to know \emph{how} to do something, (that's the job of
the dependency), you just need to interact with the dependency properly
to get the job done. Buses are \emph{perfect} for people who can't
drive, after all.

But this means that all of the issues of abstractions that we covered in
Communication Risk apply. For example, there is Invisibility Risk
because you probably don't have a full view of what the dependency is
doing. Nowadays, bus stops have a digital ``arrivals'' board which gives
you details of when the bus will arrive, and shops publish their opening
hours online. But, abstraction always means the loss of some detail -
the bus might be two minutes away but could already be full.

\hypertarget{dependencies-are-complex}{%
\section{Dependencies Are Complex}\label{dependencies-are-complex}}

In Rich Hickey's talk,
\href{https://www.infoq.com/presentations/Simple-Made-Easy}{Simple Made
Easy} he discusses the difference between \emph{simple} software systems
and \emph{easy} (to use) ones, heavily stressing the virtues of simple
over easy. It's an incredible talk and well worth watching.

But: living systems are not simple. Not anymore. They evolved in the
direction of increasing complexity because life was \emph{easier} that
way. In the ``simpler'' direction, life is first \emph{harder} and then
\emph{impossible}, and then an evolutionary dead-end.

Depending on things makes \emph{your job easier}. It's just
\href{https://en.wikipedia.org/wiki/Division_of_labour}{division of
labour} and dependency hierarchies, as we saw in Complexity Risk.

Our economic system and our software systems exhibit the same
tendency-towards-complexity. For example, the television in my house now
is \emph{vastly more complicated} than the one in my home when I was a
child. But, it contains much more functionality and consumes much less
power and space.

\hypertarget{managing-dependency-risk}{%
\section{Managing Dependency Risk}\label{managing-dependency-risk}}

Arguably, managing Dependency Risk is \emph{what Project Managers do}.
Their job is to meet the Goal by organising the available dependencies
into some kind of useful order.

There are \emph{some} tools for managing dependency risk:
\href{https://en.wikipedia.org/wiki/Gantt_chart}{Gantt Charts} for
example, arrange work according to the capacity of the resources
(i.e.~dependencies) available, but also the \emph{dependencies between
the tasks}. If task \textbf{B} requires the outputs of task \textbf{A},
then clearly task \textbf{A} comes first and task \textbf{B} starts
after it finishes. We'll look at this more in Process Risk.

We'll look in more detail at project management in Part 3, later. But
now let's get into the specifics with Scarcity Risk.

\hypertarget{scarcity-risk}{%
\chapter{Scarcity Risk}\label{scarcity-risk}}

While Reliability Risk (which we met in the previous chapter) considers
what happens when a \emph{single dependency} is unreliable, scarcity is
about \emph{quantities} of a dependency, and specifically, \emph{not
having enough}.

In the previous chapter, we talked about the \emph{reliability} of the
bus: it will either arrive or it wont. But what if, when it arrives,
it's already full of passengers? There is a \emph{scarcity of seats}:
you don't much care which seat you get on the bus, you just need one.
Let's term this, Scarcity Risk - Risk of not being able to access a
dependency in a timely fashion due to it's scarcity.

Any resource (such as disk space, oxygen, concert tickets, time or
pizza) that you depend on can suffer from \emph{scarcity}, and here,
we're going to look at five particular types, relevant to software.

\begin{figure}
\centering
\includegraphics{images/generated/risks/scarcity/scarcity-risks-400dpi.png}
\caption{Scarcity Risk and it's variations\label{scarcity-risks.png}}
\end{figure}

Here are a selection of mitigations:

\begin{itemize}
\tightlist
\item
  \textbf{Buffers}: Smoothing out peaks and troughs in utilisation.
\item
  \textbf{Reservation Systems}: giving clients information \emph{ahead}
  of the dependency usage about whether the resource will be available
  to them.
\item
  \textbf{Graceful degradation}: Ensuring \emph{some} service in the
  event of over-subscription. It would be no use allowing people to cram
  onto the bus until it can't move.
\item
  \textbf{Demand Management}: Having different prices during busy
  periods helps to reduce demand. Having ``first class'' seats means
  that higher-paying clients can get service even when the train is
  full. \href{https://www.uber.com}{Uber} adjust prices in real-time by
  so-called
  \href{https://www.uber.com/en-GB/drive/partner-app/how-surge-works/}{Surge
  Pricing}. This is basically turning Scarcity Risk into a Market Risk
  problem.
\item
  \textbf{Queues}: Again, these provide a ``fair'' way of dealing with
  scarcity by exposing some mechanism for prioritising use of the
  resource. Buses operate a first-come-first-served system, whereas
  emergency departments in hospitals triage according to need.
\item
  \textbf{Pools}: Reserving parts of a resource for a group of
  customers, and sharing within that group.
\item
  \textbf{Horizontal Scaling}: allowing a scarce resource to flexibly
  scale according to how much demand there is. (For example, putting on
  extra buses when the trains are on strike, or opening extra check-outs
  at the supermarket.)
\end{itemize}

Much like Reliability Risk, there is science for it:

\begin{itemize}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Queueing_theory}{Queue Theory} is
  all about building mathematical models of buffers, queues, pools and
  so forth.
\item
  \href{https://en.wikipedia.org/wiki/Logistics}{Logistics} is the
  practical organisation of the flows of materials and goods around
  things like \href{https://en.wikipedia.org/wiki/Supply_chain}{Supply
  Chains}.
\item
  And \href{https://en.wikipedia.org/wiki/Project_management}{Project
  Management} is in large part about ensuring the right resources are
  available at the right times. We'll be taking a closer look at that in
  Risk-First Part 3 chapters on Prioritisation and the Project
  Management Body Of Knowledge.
\end{itemize}

\hypertarget{funding-risk}{%
\section{Funding Risk}\label{funding-risk}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/scarcity/funding-risk-400dpi.png}
\caption{Funding Risk\label{funding-risk.png}}
\end{figure}

On a lot of software projects, you are ``handed down'' deadlines from
above, and told to deliver by a certain date or face the consequences.
But sometimes you're given a budget instead, which really just adds
another layer of abstraction to the Schedule Risk: That is, do I have
enough funds to cover the team for as long as I need them?

This grants you some leeway as now you have two variables to play with:
the \emph{size} of the team, and \emph{how long} you can run it for. The
larger the team, the shorter the time you can afford to pay for it.

In startup circles, this ``amount of time you can afford it'' is called
the \href{https://en.wiktionary.org/wiki/runway}{``Runway''}: you have
to get the product to ``take-off'' (become profitable) before the runway
ends.

Startups often spend a lot of time courting investors in order to get
funding and mitigate this type of Schedule Risk. But, as shown in Figure
\ref{funding-risk.png}, this activity usually comes at the expense of
Opportunity Risk and Feature Risk, as usually the same people are trying
to raise funds as build the project itself.

\hypertarget{staff-risk}{%
\section{Staff Risk}\label{staff-risk}}

Since the workforce is a scarce resource, it stands to reason that if a
startup has a ``Runway'', then the chances are that the founders and
staff do too, as this article
\href{https://www.entrepreneur.com/article/223135}{explores}. It
identifies the following risks:

\begin{itemize}
\tightlist
\item
  Company Cash: The \textbf{Runway} of the startup itself
\item
  Founder Cash: The \textbf{Runway} for a founder, before they run out
  of money and can't afford their rent.
\item
  Team Cash: The \textbf{Runway} for team members, who may not have the
  same appetite for risk as the founders do.
\end{itemize}

You need to consider how long your staff are going to be around,
especially if you have
\href{https://en.wikipedia.org/wiki/Key_person_insurance\#Key_person_definition}{Key
Man Risk} on some of them. People like to have new challenges, or move
on to live in new places, or simply get bored, and replacing staff can
be highly risky.

The longer your project goes on for, the more Staff Risk you will have
to endure, and you can't rely on getting the best staff for failing
projects.

\hypertarget{schedule-risk}{%
\section{Schedule Risk}\label{schedule-risk}}

Schedule Risk is very pervasive, and really underlies \emph{everything}
we do. People \emph{want} things, but they \emph{want them at a certain
time}. We need to eat and drink every day, for example. We might value
having a great meal, but not if we have to wait three weeks for it.

And let's go completely philosophical for a second: Were you to attain
immortality, you'd probably not feel the need to buy \emph{anything}.
You'd clearly have no \emph{needs}, and anything you wanted, you could
create yourself within your infinite time-budget. Rocks don't need
money, after all.

In the chapter on Feature Risk we looked at Market Risk, the idea that
the value of your product is itself at risk from the mors of the
market, share prices being the obvious example of that effect. In
Finance, we measure this using \emph{money}, and we can put together
probability models based on how much money you might make or lose.

With Schedule Risk, the underlying measure is \emph{time}:

\begin{itemize}
\tightlist
\item
  ``If I implement feature X, I'm picking up something like 5 days of
  Schedule Risk.''
\item
  ``If John goes travelling that's going to hit us with lots of Schedule
  Risk while we train up Anne.''
\end{itemize}

\ldots{} and so on. Clearly, in the same way as you don't know exactly
how much money you might lose or gain on the stock-exchange, you can't
put precise numbers on Schedule Risk either.

\hypertarget{student-syndrome}{%
\subsection{Student Syndrome}\label{student-syndrome}}

\href{https://en.wikipedia.org/wiki/Student_syndrome}{Student Syndrome}
is, according to Wikipedia:

\begin{quotation}

``Student syndrome refers to planned procrastination, when, for example,
a student will only start to apply themselves to an assignment at the
last possible moment before its deadline.'' - \emph{Wikipedia}

\end{quotation}

Arguably, there is good psychological, evolutionary and risk-based
reasoning behind procrastination: if there is apparently a lot of time
to get a job done, then Schedule Risk is low. If we're only ever
mitigating our \emph{biggest risks}, then managing Schedule Risk in the
future doesn't matter so much. Putting efforts into mitigating future
risks that \emph{might not arise} is wasted effort.

Or at least, that's the argument: If you're Discounting the Future To
Zero then you'll be pulling all-nighters in order to deliver any
assignment.

So, the problem with Student Syndrome is that the \emph{very mitigation}
for Schedule Risk (allowing more time) is an Attendant Risk that
\emph{causes} Schedule Risk: you'll work within the more generous time
allocation more slowly and you'll end up revealing Hidden Risk
\emph{later}. And, discovering these hidden risks later causes you to
end up being late because of them.

\hypertarget{opportunity-risk}{%
\section{Opportunity Risk}\label{opportunity-risk}}

Opportunity Risk is really the concern that whatever we do, we have to
do it \emph{in time}. If we wait too long, we'll miss the
\href{https://en.wikipedia.org/wiki/Window_of_opportunity}{Window Of
Opportunity} for our product or service.

Any product idea is necessarily of it's time: the Goal In Mind will be
based on observations from a particular Internal Model, reflecting a
view on reality at a specific \emph{point in time}.

How long will that remain true for? This is your \emph{opportunity}: it
exists apart from any deadlines you set yourself, or funding options.
It's purely, ``how long will this idea be worth doing?''

With any luck, decisions around \emph{funding} your project will be tied
into this, but it's not always the case. It's very easy to under-shoot
or overshoot the market completely and miss the window of opportunity.

\hypertarget{the-ipad}{%
\subsection{The iPad}\label{the-ipad}}

For example, let's look at the
\href{https://en.wikipedia.org/wiki/History_of_tablet_computers}{iPad},
which was introduced in 2010 and was hugely successful.

This was not the first tablet computer. Apple had already tried to
introduce the \href{https://en.wikipedia.org/wiki/Apple_Newton}{Newton}
in 1989, and Microsoft had released the
\href{https://en.wikipedia.org/wiki/Microsoft_Tablet_PC}{Tablet PC} in
1999. But somehow, they both missed the Window Of Opportunity. Possibly,
the window existed because Apple had changed changed the market with
their release of the iPhone, which left people open to the idea of a
tablet being ``just a bigger iPhone''.

But maybe now, the iPad's window is closing? We have more \emph{wearable
computers} like the
\href{https://en.wikipedia.org/wiki/Apple_Watch}{Apple Watch}, and
voice-controlled devices like
\href{https://en.wikipedia.org/wiki/Amazon_Alexa}{Alexa} or
\href{https://en.wikipedia.org/wiki/Siri}{Siri}. Peak iPad was in 2014,
according to
\href{https://www.statista.com/statistics/269915/global-apple-ipad-sales-since-q3-2010/}{this
graph}. tbd add graph.

So, it seems Apple timed the iPad to hit the peak of the Window of
Opportunity.

But, even if you time the Window Of Opportunity correctly, you might
still have the rug pulled from under your feet due to a different kind
of Scarcity Risk, such as\ldots{}

\hypertarget{red-queen-risk}{%
\section{Red-Queen Risk}\label{red-queen-risk}}

A more specific formulation of Schedule Risk is Red Queen Risk, which is
that whatever you build at the start of the project will go slowly
more-and-more out of date as the project goes on.

This is named after the Red Queen quote from Alice in Wonderland:

\begin{quotation}

``My dear, here we must run as fast as we can, just to stay in place.
And if you wish to go anywhere you must run twice as fast as that.''

\sourceatright{\href{https://www.goodreads.com/quotes/458856-my-dear-here-we-must-run-as-fast-as-we}{\textemdash  Lewis Carroll, \emph{Alice in Wonderland}}}
\end{quotation}

The problem with software projects is that tools and techniques change
\emph{really fast}. In 2011, 3DRealms released Duke Nukem Forever after
\href{https://en.wikipedia.org/wiki/Duke_Nukem_Forever}{15 years in
development}, to negative reviews:

\begin{quotation}

``\ldots{} most of the criticism directed towards the game's long
loading times, clunky controls, offensive humor, and overall aging and
dated design.'' - \emph{Duke Nukem Forever, Wikipedia}

\end{quotation}

Now, they didn't \emph{deliberately} take 15 years to build this game
(lots of things went wrong). But, the longer it took, the more their
existing design and code-base were a liability rather than an asset.

Personally, I have suffered the pain on project teams where we've had to
cope with legacy code and databases because the cost of changing them
was too high. And any team who is stuck using
\href{https://en.wikipedia.org/wiki/Visual_Basic}{Visual Basic 6.0} is
here. It's possible to ignore Red Queen Risk for a time, but this is
just another form of Technical Debt which eventually comes due.

\begin{figure}
\centering
\includegraphics{images/generated/risks/scarcity/red-queen-risk-400dpi.png}
\caption{Red Queen Risk\label{red-queen-risk.png}}
\end{figure}

In this chapter, we've looked at various risks to do with scarcity of
time, as a quantity we can spend like money. But frequently, we have a
dependency on a specific \emph{event}. On to Deadline Risk.

\hypertarget{deadline-risk}{%
\chapter{Deadline Risk}\label{deadline-risk}}

Let's examine dependencies on \emph{events}.

We rely on events occuring all the time in our lives, and event
dependencies are simple to express: usually, a \emph{time} and a
\emph{place}. For example:

\begin{itemize}
\tightlist
\item
  ``The bus to work leaves at 7:30am'' or
\item
  ``I can't start shopping until the supermarket opens at 9am''.
\end{itemize}

In the first example, you can't \emph{start} something until a
particular event happens. In the latter example, you must \emph{be
ready} for an event at a particular time.

\hypertarget{events-mitigate-risk}{%
\section{Events Mitigate Risk\ldots{}}\label{events-mitigate-risk}}

Having an event occur in a fixed time and place is mitigating risk:

\begin{itemize}
\tightlist
\item
  By taking the bus, we are mitigating our own Schedule Risk: we're
  (hopefully) reducing the amount of time we're going to spend on the
  activity of getting to work. It's not entirely necessary to even take
  the bus: you could walk, or go by another form of transport. But,
  effectively, this just swaps one dependency for another: if you walk,
  this might well take longer and use more energy, so you're just
  picking up Schedule Risk in another way.
\item
  Events are a mitigation for Coordination Risk: A bus needn't
  necessarily \emph{have} a fixed timetable: it could wait for each
  passenger until they turned up, and then go. (A bit like ride-sharing
  works). This would be a total disaster from a Coordination Risk
  perspective, as one person could cause everyone else to be really
  really late. Having a fixed time for doing something mitigates
  Coordination Risk by turning it into Schedule Risk. Agreeing a date
  for a product launch, for example, allows lots of teams to coordinate
  their activities.
\item
  If you drive, you have a dependency on your car instead. So, there is
  often an \emph{opportunity cost} with dependencies. Using the bus
  might be a cheap way to travel. You're therefore imposing less
  Dependency Risk on a different scarce resource - your money.
\end{itemize}

\hypertarget{but-events-lead-to-attendant-risk}{%
\section{But, Events Lead To Attendant
Risk}\label{but-events-lead-to-attendant-risk}}

By \emph{deciding to use the bus} we've Taken Action. By agreeing a
\emph{time} and \emph{place} for something to happen, you're introducing
Deadline Risk. Miss the deadline, and you miss the bus.

As discussed above, \emph{schedules} (such as bus timetables) exist so
that \emph{two or more parties can coordinate}, and Deadline Risk is on
\emph{all} of the parties. While there's a risk I am late, there's also
a risk the bus is late. I might miss the start of a concert, or the band
might keep everyone waiting.

In software development, deadlines are set in order to \emph{coordinate
work between teams}. For example, having a product ready in production
at the same time as the marketing campaign starts. Fixing on an agreed
deadline mitigates inter-team Coordination Risk.

\begin{figure}
\centering
\includegraphics{images/generated/risks/deadline/dependency-risk-event-400dpi.png}
\caption{Action Diagram showing risks mitigated by having an
\emph{event}\label{dependency-risk-event.png}}
\end{figure}

\hypertarget{slack}{%
\section{Slack}\label{slack}}

Each party can mitigate Deadline Risk with \emph{slack}. That is,
ensuring that the exact time of the event isn't critical to your plans:

\begin{itemize}
\tightlist
\item
  Don't build into your plans a \emph{need} to start shopping at 9am.
\item
  Arrive at the bus-stop \emph{early}.
\end{itemize}

The amount of slack you build into the schedule is likely dependent on
the level of risk you face: I tend to arrive a few minutes early for a
bus, because the risk is \emph{low} (there'll be another bus along
soon), however I try to arrive over an hour early for a flight, because
I can't simply get on the next flight straight away, and I've already
paid for it, so the risk is \emph{high}.

Deadline Risk becomes very hard to manage when you have to coordinate
actions with lots of tightly-constrained events. So what else can give?
We can reduce the number of \emph{parties} involved in the event, which
reduces risk, or, we can make sure all the parties are in the same
\emph{place} to begin with.

\hypertarget{deadlines}{%
\section{Deadlines}\label{deadlines}}

Often when running a software project, you're given a team of people and
told to get something delivered by a certain date. i.e.~you have an
artificially-imposed deadline on delivery.

What happens if you miss the deadline? It could be:

\begin{itemize}
\tightlist
\item
  The funding on the project runs out, and it gets cancelled.
\item
  You have to go back to a budgeting committee, and get more money.
\item
  The team gets replaced, because of lack of faith.
\end{itemize}

.. or something else.

Deadline Risk can be introduced by an authority in order to
\emph{sharpen focus} and reduce Coordination Risk. This is how we arrive
at tools like \href{https://en.wikipedia.org/wiki/SMART_criteria}{SMART
Objectives} and
\href{https://en.wikipedia.org/wiki/Performance_indicator}{KPI's (Key
Performance Indicators)}.

Deadlines change the way we evaluate goals, and the solutions we choose
because they force us to reckon with Deadline Risk. For example, in
JFK's quote:

\begin{quotation}

``First, I believe that this nation should commit itself to achieving
the goal, before this decade is out, of landing a man on the moon and
returning him safely to the Earth.'' - John F. Kennedy, 1961

\end{quotation}

The 9-year timespan came from an authority figure (the president) and
helped a huge team of people coordinate their efforts and arrive at a
solution that would work within a given time-frame. The Deadline Risk
allowed the team to focus on mitigating the risk of missing that
deadline.

Compare with this quote:

\begin{quotation}

``I love deadlines. I love the whooshing noise they make as they go
by.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Douglas_Adams}{Douglas Adams}}
\end{quotation}

As a successful author, Douglas Adams \emph{didn't really care} about
the deadlines his publisher's gave him. The Deadline Risk was minimal
for him, because the publisher wouldn't be able to give his project to
someone else to complete.

\hypertarget{deadline-risk-and-schedule-risk}{%
\section{Deadline Risk and Schedule
Risk}\label{deadline-risk-and-schedule-risk}}

Schedule Risk and Deadline Risk are clearly related: they both refer to
the risk of running out of time. However, the \emph{risk profile} of
each is very different:

\begin{itemize}
\tightlist
\item
  Schedule Risk is \emph{continuous}, like money. i.e.~You want to waste
  as little of it as possible. Every extra day you take compounds
  Schedule Risk additively, and a day wasted at the start of the project
  is much the same as a day wasted at the end.
\item
  Deadline Risk is \emph{binary}. The impact of Deadline Risk is either
  zero (you make it in time) or one (you are late and miss the flight).
  You don't particularly get a reward for being early.
\end{itemize}

So, these are two separate concepts, and both are useful.

\hypertarget{software-dependency-risk}{%
\chapter{Software Dependency Risk}\label{software-dependency-risk}}

In this chapter, we're going to look specifically at \emph{Software}
dependencies, although many of the concerns we'll raise here apply
equally to all the other types of dependency we outlined in Dependency
Risk.

\hypertarget{kolmogorov-complexity-cheating}{%
\section{Kolmogorov Complexity:
Cheating}\label{kolmogorov-complexity-cheating}}

In the earlier chapter on Complexity Risk we tackled Kolmogorov
Complexity, and the idea that your codebase had some kind of minimal
level of complexity based on the output it was trying to create. This is
a neat idea, but in a way, we cheated. Let's look at how.

We were trying to figure out the shortest (Javascript) program to
generate this output:

\begin{verbatim}
abcdabcdabcdabcdabcdabcdabcdabcdabcdabcd
\end{verbatim}

And we came up with this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{const}\NormalTok{ ABCD}\OperatorTok{=}\StringTok{"ABCD"}\OperatorTok{;}\NormalTok{                         (}\DecValTok{11}\NormalTok{ symbols)}

\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                           (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return} \VariableTok{ABCD}\NormalTok{.}\AttributeTok{repeat}\NormalTok{(}\DecValTok{10}\NormalTok{)                 (}\DecValTok{7}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

Which had \textbf{26} symbols in it.

Now, here's the cheat: The \texttt{repeat()} function was built into
Javascript in 2015 in
\href{http://www.ecma-international.org/ecma-262/6.0/}{ECMAScript 6.0}.
If we'd had to program it ourselves, we might have added this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{repeat}\NormalTok{(s}\OperatorTok{,}\NormalTok{n) }\OperatorTok{\{}\NormalTok{                     (}\DecValTok{10}\NormalTok{ symbols)}
    \KeywordTok{var}\NormalTok{ a}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{                              (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{while}\NormalTok{(}\VariableTok{a}\NormalTok{.}\AttributeTok{length}\OperatorTok{<}\NormalTok{n)}\OperatorTok{\{}\NormalTok{                     (}\DecValTok{9}\NormalTok{ symbols)}
        \VariableTok{a}\NormalTok{.}\AttributeTok{push}\NormalTok{(s)                          (}\DecValTok{6}\NormalTok{ symbols)}
    \OperatorTok{\}}\NormalTok{                                      (}\DecValTok{1}\NormalTok{ symbol)}
    \ControlFlowTok{return} \VariableTok{a}\NormalTok{.}\AttributeTok{join}\NormalTok{(}\StringTok{''}\NormalTok{)}\OperatorTok{;}\NormalTok{                     (}\DecValTok{10}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

\ldots{} which would be an extra \textbf{44} symbols (in total
\textbf{70}), and push us completely over the original string encoding
of \textbf{53} symbols. So, \emph{encoding language is important}.

Conversely, if ECMAScript 6.0 had introduced a function called
\texttt{abcdRepeater(n)} we'd have been able to do this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \AttributeTok{out}\NormalTok{() }\OperatorTok{\{}\NormalTok{                           (}\DecValTok{7}\NormalTok{ symbols)}
    \ControlFlowTok{return} \AttributeTok{abcdRepeater}\NormalTok{(}\DecValTok{10}\NormalTok{)                (}\DecValTok{6}\NormalTok{ symbols)}
\OperatorTok{\}}\NormalTok{                                          (}\DecValTok{1}\NormalTok{ symbol)}
\end{Highlighting}
\end{Shaded}

.. and re-encode to \textbf{14} symbols. Now, clearly there are some
problems with all this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Language Matters:} the Kolmogorov complexity is dependent on
  the language, and the features the language has built in. 
\item
  \textbf{Exact Kolmogorov complexity is uncomputable anyway:} Since
  it's the \emph{theoretical} minimum program length, it's a fairly
  abstract idea, so we shouldn't get too hung up on this. There is no
  function to be able to say, ``what's the Kolmogorov complexity of
  string X''
\item
  \textbf{What is this new library function we've created?} Is
  \texttt{abcdRepeater} going to be part of \emph{every} Javascript? If
  so, then we've shifted Codebase Risk away from ourselves, but we've
  pushed Communication Risk and Dependency Risk onto every \emph{other}
  user of Javascript. (Why these? Because \texttt{abcdRepeater} will be
  clogging up the documentation and other people will rely on it to
  function correctly.)
\item
  \textbf{Are there equivalent functions for every single other string?}
  If so, then compilation is no longer a tractable problem because now
  we have a massive library of different \texttt{XXXRepeater} functions
  to compile against to see if it is\ldots{} So, what we \emph{lose} in
  Codebase Risk we gain in Dependency Risk.
\item
  \textbf{Language design, then, is about \emph{ergonomics}:} After you
  have passed the relatively low bar of providing
  \href{https://en.wikipedia.org/wiki/Turing_completeness}{Turing
  Completeness}, the key is to provide \emph{useful} features that
  enable problems to be solved, without over-burdening the user with
  features they \emph{don't} need. And in fact, all software is about
  this.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/ergonomics-400dpi.png}
\caption{Software Dependency Ergonomics: finding the sweet spot between
too many features and too few\label{ergonomics.png}}
\end{figure}

\hypertarget{ergonomics-examined}{%
\section{Ergonomics Examined}\label{ergonomics-examined}}

Have a look at some physical tools, like a hammer, or spanner. To look
at them, they are probably \emph{simple} objects, obvious, strong and
dependable. Their entire behaviour is encapsulated in their form. Now,
if you have a drill or sander to hand, look at the design of this too.
If it's well-designed, then from the outside it is simple, perhaps with
only one or two controls. Inside, it is complex and contains a motor,
perhaps a transformer, and is maybe made of a hundred different
components.

But outside, the form is simple, and designed for humans to use. This is
\emph{\href{https://en.wikipedia.org/wiki/Human_factors_and_ergonomics}{ergonomics}}:

\begin{quotation}

``Human factors and ergonomics (commonly referred to as Human Factors),
is the application of psychological and physiological principles to the
(engineering and) design of products, processes, and systems. The goal
of human factors is to reduce human error, increase productivity, and
enhance safety and comfort with a specific focus on the interaction
between the human and the thing of interest.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Human_factors_and_ergonomics}{\textemdash  Human Factors and Ergonomics, \emph{Wikipedia}}}
\end{quotation}

\hypertarget{protocols-and-ergonomics}{%
\subsection{Protocols and Ergonomics}\label{protocols-and-ergonomics}}

The \emph{interface} of a tool is the part we touch and interact with,
via it's protocol. By striving for an ergonomic sweet spot, the protocol
reduces Communication Risk.

The interface of a system expands when you ask it to do a wide variety
of things. An easy-to-use drill does one thing well: it turns drill-bits
at useful levels of torque for drilling holes and sinking screws. But if
you wanted it to also operate as a lathe, a sander or a strimmer (all
basically mechanical things going round) you would have to sacrifice the
conceptual integrity for a more complex protocol, probably including
adapters, extensions, handles and so on.

So, we now have split complexity into two:

\begin{itemize}
\tightlist
\item
  The inner complexity of the tool (how it works internally, it's own
  internal complexity).
\item
  The complexity of the instructions that we need to write to make the
  tool work, the protocol complexity, which will be a function of the
  complexity of the tool itself..
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/protocol-complexity-400dpi.png}
\caption{Types of Complexity For a Software
Dependency\label{protocol-complexity.png}}
\end{figure}

\hypertarget{software-tools}{%
\subsection{Software Tools}\label{software-tools}}

In the same way as with a hand-tool, the bulk of the complexity of a
software tool is hidden behind it's interface. But, the more complex the
\emph{purpose} of the tool, the more complex the interface will be.

Software is not constrained by \emph{physical} ergonomics in the same
way as a tool is. But ideally, it should have conceptual ergonomics:
ideally, complexity is hidden away from the user behind the \emph{User
Interface}. This is the familiar concept of Abstraction we've already
looked at. As we saw in Communication Risk, when we use a new protocol,
we face Learning Curve Risk. To minimise this, we should apply the
Principal Of Least Astonishment when designing protocols:

\begin{itemize}
\tightlist
\item
  \textbf{The abstractions should map easily to how the user expects the
  tool to work.} For example, I \emph{expect} the trigger on a drill to
  start the drill turning.
\item
  \textbf{The abstractions should leverage existing idioms and
  knowledge.} In a new car, I \emph{expect} to know what the symbols on
  the dashboard mean, because I've driven other cars.
\item
  \textbf{The abstractions provide me with only the functions I need.}
  Because everything else is confusing and gets in the way.
\end{itemize}

\hypertarget{types-of-software-dependencies}{%
\section{Types Of Software
Dependencies}\label{types-of-software-dependencies}}

There are lots of ways you can depend on software. Here though, we're
going to focus on just three main types:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Code Your Own}: write some code ourselves to meet the
  dependency.
\item
  \textbf{Software Libraries}: importing code from the Internet, and
  using it in our project. Often, libraries are Open Source (this is
  what we'll consider here).
\item
  \textbf{Software as a Service}: calling a service on the Internet,
  (probably via \texttt{http}) This is often known as
  \href{https://en.wikipedia.org/wiki/Software_as_a_service}{SaaS, or
  Software as a Service}.
\end{enumerate}

All 3 approaches involve a different risk-profile. Let's look at each in
turn, from the perspective of which risks get mitigated, and which risks
are accentuated.

\hypertarget{code-your-own}{%
\subsection{1. Code Your Own}\label{code-your-own}}

Way before the Internet, this was the only game in town. Tool support
was very thin-on-the-ground. Algorithms could be distributed as code
snippets \emph{in magazines} which could be transcribed and run, and
added to your program. This spirit lives on somewhat in StackOverflow
and JSFiddle, where you are expected to ``adopt'' others' code into your
own project. Code-your-own is still the best option if you have highly
bespoke requirements, or are dealing with unusual environmental
contexts.

One of the hidden risks of embarking on a code-your-own approach is that
the features you need are \emph{not} apparent from the outset. What
might appear to be a trivial implementation of some piece of
functionality can often turn into it's own industry as more and more
hidden Feature Risk is uncovered. For example, as we discussed in our
earlier treatment of Dead-End Risk, building log-in screens \emph{seemed
like a good idea}. However, this gets out-of-hand fast when you need:

\begin{itemize}
\tightlist
\item
  A password reset screen
\item
  To email the reset links to the user
\item
  An email verification screen
\item
  A lost account screen
\item
  Reminders to complete the sign up process
\item
  \ldots{} and so on.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/code-your-own-400dpi.png}
\caption{Code-Your-Own mitigates immediate feature risk, but at the
expense of schedule risk, complexity risk and communication risk. There
is also a hidden risk of features you don't yet know you
need.\label{code-your-own.png}}
\end{figure}

\hypertarget{unwritten-software}{%
\subsection{Unwritten Software}\label{unwritten-software}}

Sometimes, you will pick up Dependency Risk from \emph{unwritten
software}. This commonly happens when work is divided amongst team
members, or teams.

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/unwritten-400dpi.png}
\caption{Sometimes, a module you're writing will depend on unwritten
code\label{unwritten.png}}
\end{figure}

If a component \textbf{A} of our project \emph{depends} on \textbf{B}
for some kind of processing, you might not be able to complete
\textbf{A} before writing \textbf{B}. This makes \emph{scheduling} the
project harder, and if component \textbf{A} is a risky part of the
project, then the chances are you'll want to mitigate risk there first.

But it also hugely increases Communication Risk because now you're being
asked to communicate with a dependency that doesn't really exist yet,
\emph{let alone} have any documentation.

There are a couple of ways to do this:

\begin{itemize}
\item
  \textbf{Standards}: If component \textbf{B} is a database, a queue,
  mail gateway or something else with a standard interface, then you're
  in luck. Write \textbf{A} to those standards, and find a cheap, simple
  implementation to test with. This gives you time to sort out exactly
  what implementation of \textbf{B} you're going for. This is not a
  great long-term solution, because obviously, you're not using the
  \emph{real} dependency- you might get surprised when the behaviour of
  the real component is subtly different. But it can reduce Schedule
  Risk in the short-term.
\item
  \textbf{Coding To Interfaces}: If standards aren't an option, but the
  surface area of \textbf{B} that \textbf{A} uses is quite small and
  obvious, you can write a small interface for it, and work behind that,
  using a \href{https://en.wikipedia.org/wiki/Mock_object}{Mock} for
  \textbf{B} while you're waiting for finished component. Write the
  interface to cover only what \textbf{A} \emph{needs}, rather than
  everything that \textbf{B} \emph{does} in order to minimise the risk
  of \href{https://en.wikipedia.org/wiki/Leaky_abstraction}{Leaky
  Abstractions}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/unwritten-mitigation-400dpi.png}
\caption{Coding to a standard on an interface breaks the dependency on
unwritten software\label{unwritten-mitigation.png}}
\end{figure}

\hypertarget{conways-law}{%
\subsection{Conway's Law}\label{conways-law}}

Due to channel bandwidth limitations, if the dependency is being written
by another person, another team or in another country, Communication
Risk piles up. When this happens, you will want to minimise the
interface complexity \emph{as much as possible}, since the more complex
the interface, the worse the Communication Risk will be. The tendency
then is to make the interfaces between teams or people \emph{as simple
as possible}, modularising along these organisational boundaries.

In essence, this is
\href{https://en.wikipedia.org/wiki/Conways_law}{Conway's Law}:

\begin{quotation}

``organisations which design systems \ldots{} are constrained to produce
designs which are copies of the communication structures of these
organisations.'' ---M. Conway, \emph{Conway's Law}

\end{quotation}

\hypertarget{software-libraries}{%
\subsection{2. Software Libraries}\label{software-libraries}}

By choosing a particular software library, we are making a move on the
Risk Landscape in the hope of moving to place with more favourable
risks. Typically, using library code offers a Schedule Risk and
Complexity Risk Silver Bullet - a high-speed route over the risk
landscape to somewhere nearer where we want to be. But, in return we
expect to pick up:

\begin{itemize}
\tightlist
\item
  \textbf{Communication Risk:} because we now have to learn how to
  communicate with this new dependency.
\item
  \textbf{Boundary Risk:} - because now are limited to using the
  functionality provided by this dependency. We have chosen it over
  alternatives and changing to something else would be more work and
  therefore costly.
\end{itemize}

But, it's quite possible that we could wind up in a worse place than we
started out, by using a library that's out-of-date, riddled with bugs or
badly supported. i.e.~Full of new, hidden Feature Risk.

It's \emph{really easy} to make bad decisions about which tools to use
because the tools don't (generally) advertise their deficiencies. After
all, they don't generally know how \emph{you} will want to use them.

\hypertarget{software-libraries---attendant-risks}{%
\subsection{Software Libraries - Attendant
Risks}\label{software-libraries---attendant-risks}}

Currently, choosing software dependencies looks like a ``bounded
rationality''-type process:

\begin{quotation}

``Bounded rationality is the idea that when individuals make decisions,
their rationality is limited by the tractability of the decision
problem, the cognitive limitations of their minds, and the time
available to make the decision.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Bounded_rationality}{\textemdash  Bounded Rationality, \emph{Wikipedia}}}
\end{quotation}

Unfortunately, we know that most decisions \emph{don't} really get made
this way. We have things like
\href{https://en.wikipedia.org/wiki/Confirmation_bias}{Confirmation
Bias} (looking for evidence to support a decision you've already made)
and \href{https://en.wikipedia.org/wiki/Cognitive_inertia}{Cognitive
Inertia} (ignoring evidence that would require you to change your mind)
to contend with.

But, leaving that aside, let's try to build a model of what this
decision making process \emph{should} involve. Luckily, other authors
have already considered the problem of choosing good software libraries,
so let's start there.

In the table below, I am summarising three different sources (linked at
the end of the chapter), which give descriptions of which factors to
look for when choosing open-source libraries.

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/software_dependency_table_1_large-400dpi.png}
\caption{Software Library Dependencies, Attendant
Risks\label{software_dependency_table_1_large.png}}
\end{figure}

Figure \ref{software_dependency_table_1_large.png} summarises the risks
raised in some of the literature. Here are some take-aways:

\begin{itemize}
\tightlist
\item
  \textbf{Feature Risk is a big concern:} How can you be sure that the
  project will do what you want it to do ahead of schedule? Will it
  contain bugs or missing features? By looking at factors like
  \emph{release frequency} and \emph{size of the community} you get a
  good feel for this which is difficult to fake.
\item
  \textbf{Boundary Risk is also very important:} You are going to have
  to \emph{live} with your choices for the duration of the project, so
  it's worth spending the effort to either ensure that you're not going
  to regret the decision, or that you can change direction later.
\item
  \textbf{Third is Communication Risk:} how well does the project deal
  with it's users? If a project is ``famous'', then it has communicated
  its usefulness to a wide, appreciative audience. Avoiding
  Communication Risk is also a good reason to pick \emph{tools you are
  already familiar with}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/library-400dpi.png}
\caption{Software Libraries Risk Tradeoff\label{library.png}}
\end{figure}

\hypertarget{complexity-risk-1}{%
\subsection{Complexity Risk?}\label{complexity-risk-1}}

One thing that none of the sources in the table consider (at least from
the outset) is the Complexity Risk of using a solution:

\begin{itemize}
\tightlist
\item
  Does it drag in lots of extra dependencies that seem unnecessary for
  the job in hand? If so, you could end up in
  \href{https://en.wikipedia.org/wiki/Dependency_hell}{Dependency Hell},
  with multiple, conflicting versions of libraries in the project.
\item
  Do you already have a dependency providing this functionality? So many
  times, I've worked on projects that import a \emph{new} dependency
  when some existing (perhaps transitive) dependency has \emph{already
  brought in the functionality}. For example, there are plenty of
  libraries for \href{https://en.wikipedia.org/wiki/JSON}{JSON}
  marshaling, but if I'm also using a web framework the chances are it
  already has a dependency on one already.
\item
  Does it contain lots of functionality that isn't relevant to the task
  you want it to accomplish? e.g.~Using Java when a shell script would
  do (on a non-Java project)
\end{itemize}

Sometimes, the amount of complexity \emph{goes up} when you use a
dependency for \emph{good reason}. For example, in Java, you can use
\href{https://en.wikipedia.org/wiki/Java_Database_Connectivity}{Java
Database Connectivity (JDBC)} to interface with various types of
database. \href{https://en.wikipedia.org/wiki/Spring_Framework}{Spring
Framework} (a popular Java library) provides a thing called a
\texttt{JDBCTemplate}. This actually makes your code \emph{more}
complex, and can prove very difficult to debug. However, it prevents
some security issues, handles resource disposal and makes database
access more efficient. None of those are essential to interfacing with
the database, but not using them is Technical Debt that can bite you
later on.

To give an extreme example of this, I once worked on an application
which used \href{https://en.wikipedia.org/wiki/Hazelcast}{Hazlecast}, an
in-memory distributed database, to cache log-in session tokens for a 3rd
party data-source. But, the app is only used once every month, and
session IDs can be obtained in milliseconds. So\ldots{} why cache them?
Although Hazlecast is an excellent choice for in-memory caching across
multiple JVMs, it is a complex piece of software (after all, it does
lots of stuff). Using it introduced extra dependency risk, cache
invalidation risks, networking risks, synchronisation risks and so on,
for actually no benefit at all\ldots{} Unless, it's about CV Building.
(See Agency Risk.)

\hypertarget{software-as-a-service}{%
\subsection{3. Software as a Service}\label{software-as-a-service}}

Businesses opt for Software as a Service (SaaS) because:

\begin{itemize}
\tightlist
\item
  It promises to vastly reduce the Complexity Risk they face in their
  organisations. e.g.~managing the software or making changes to it.
\item
  Payment is usually based on \emph{usage}, mitigating Funding Risk.
  e.g.~Instead of having to pay up-front for a license, and hire
  in-house software administrators, they can leave this function to the
  experts.
\item
  Potentially, you out-source the Operational Risk to a third party.
  e.g.~ensuring availability, making sure data is secure and so on.
\end{itemize}

SaaS is now a very convenient way to provide \emph{commercial} software.
Popular examples of SaaS might be
\href{https://en.wikipedia.org/wiki/Salesforce.com}{SalesForce}, or
\href{https://en.wikipedia.org/wiki/Gmail}{GMail}. Both of which follow
the commonly-used
\href{https://en.wikipedia.org/wiki/Freemium}{Freemium} model, where the
basic service is provided free, but upgrading to a paid account gives
extra benefits.

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/software_dependency_table_2_large-400dpi.png}
\caption{Software As A Service
Dependencies\label{software_dependency_table_2_large.png}}
\end{figure}

Figure \ref{software_dependency_table_2_large.png} summarises the risks
raised in some of the available literature. Some take-aways:

\begin{itemize}
\tightlist
\item
  Clearly, Operational Risk is now a big concern. By depending on a
  third-party organisation you are tying yourself to its success or
  failure in a much bigger way than just by using a piece of open-source
  software. What happens to data security, both in the data centre and
  over the Internet? Although you might choose a SaaS solution to
  mitigate \emph{internal} Operational Risk, you might just be
  ``throwing it over the wall'' to a third party, who might do a worse
  job.
\item
  With Feature Risk you now have to contend with the fact that the
  software will be upgraded \emph{outside your control}, and you may
  have limited control over which features get added or changed.
\item
  Boundary Risk is a also a different proposition: you are tied to the
  software provider by \emph{a contract}. If the service changes in the
  future, or isn't to your liking, you can't simply fork the code (like
  you could with an open source project).
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/saas-400dpi.png}
\caption{Risk Tradeoff From Using Software as a Service
(SaaS)\label{saas.png}}
\end{figure}

\hypertarget{a-matrix-of-options}{%
\section{A Matrix of Options}\label{a-matrix-of-options}}

We've looked at just 3 different ways of providing a software
dependency: Code-Your-Own, Libaries and SaaS.

But these are not the only ways to do it, and there's clearly no one
\emph{right} way. Although here we have looked just at ``Commercial
SaaS'' and ``Free Open Source'', in reality, these are just points in a
two-dimensional space involving \emph{Pricing} and \emph{Hosting}.

Let's expand this view slightly and look at where different pieces of
software sit on these axes:

\begin{sidewaysfigure}
\centering
\includegraphics{images/generated/risks/software-dependency/software_dependency_table_3_sideways-400dpi.png}
\caption{Software Dependencies, Pricing, Delivery Matrix Risk Profiles}
\end{sidewaysfigure}

\begin{itemize}
\tightlist
\item
  Where there is value in \textbf{the
  \href{https://en.wikipedia.org/wiki/Network_effect}{Network Effect}:},
  it's often a sign that the software will be free, or open source:
  programming languages and Linux are the obvious examples of this. Bugs
  are easier to find when there are lots of eyes looking, and learning
  the skill to use the software has less Boundary Risk if you know
  you'll be able to use it at any point in the future.
\item
  At the other end of the spectrum, clients will happily pay for
  software if it clearly \textbf{reduces Operational Risk}. Take
  \href{https://en.wikipedia.org/wiki/Amazon_Web_Services}{Amazon Web
  Services (AWS)}. The essential trade here is that you substitute the
  complexity of hosting and maintaining various pieces of hardware, in
  exchange for metered payments (Funding Risk for you). Since the AWS
  \emph{interfaces} are specific to Amazon, there is significant
  Boundary Risk in choosing this option.
\item
  In the middle there are lots of \textbf{substitute options} and
  therefore high competition. Because of this, prices are pushed towards
  zero, and and therefore often advertising is used to monetarise the
  product. \href{https://en.wikipedia.org/wiki/Angry_Birds}{Angry Birds}
  is a classic example: initially, it had demo and paid versions,
  however
  \href{https://en.wikipedia.org/wiki/Rovio_Entertainment}{Rovio}
  discovered there was much more money to be made through advertising
  than from the
  \href{https://www.deconstructoroffun.com/blog/2017/6/11/how-angry-birds-2-multiplied-quadrupled-revenue-in-a-year}{paid-for
  app}.
\end{itemize}

\hypertarget{software-dependencies-as-features}{%
\section{Software Dependencies as
Features}\label{software-dependencies-as-features}}

So far, we've looked at different \emph{approaches} to software
dependencies, and the risk profiles they present. But the category is
less important than the specifics: we are choosing specific tools for
specific tasks. Software Dependencies allows us to construct dependency
networks to give us all kinds of features and mitigate all kinds of
risk. That is, the features we are looking for in a dependency \emph{are
to mitigate some kind of risk}.

For example, I might start using
\href{https://en.wikipedia.org/wiki/WhatsApp}{WhatsApp} because I want
to be able to send my friends photos and text messages. However, it's
likely that those same features allow us to mitigate Coordination Risk
when we're next trying to meet up.

Let's look at some:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.40\columnwidth}\raggedright
Risk\strut
\end{minipage} & \begin{minipage}[b]{0.55\columnwidth}\raggedright
Examples of Software Mitigating That Risk\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Calendar tools, Bug Tracking, Distributed Databases\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Map-And-Territory-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
The Internet, generally. Excel, Google, ``Big Data'', Reporting
tools\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Schedule-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Planning Software, Project Management Software\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Communication-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Email, Chat tools, CRM tools like SalesForce, Forums, Twitter,
Protocols\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Process-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Reporting tools, online forms, process tracking tools\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Agency-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Auditing tools, transaction logs, Time-Sheet software, HR Software\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Operational-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Support tools like ZenDesk, Grafana, InfluxDB, Geneos, Security
Tools\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.40\columnwidth}\raggedright
Feature-Risk\strut
\end{minipage} & \begin{minipage}[t]{0.55\columnwidth}\raggedright
Every piece of software you use!\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{choice}{%
\section{Choice}\label{choice}}

\emph{Choosing} dependencies can be extremely difficult. As we discussed
above, the usefulness of any tool depends on its fit for purpose, it's
\emph{ergonomics within a given context}. It's all too easy to pick a
good tool for the wrong job:

\begin{quotation}

``I suppose it is tempting, if the only tool you have is a hammer, to
treat everything as if it were a nail.''

\sourceatright{\href{https://en.wiktionary.org/wiki/if_all_you_have_is_a_hammer,_everything_looks_like_a_nail}{\textemdash  Abraham Maslow, \emph{Toward a Psychology of Being}}}
\end{quotation}

Having chosen a dependency, whether or not you end up in a more
favourable position risk-wise is going to depend heavily on the quality
of the execution and the skill of the implementor. With software
dependencies, we often have to live with the decisions we make for a
long time. In my experience, given the Boundary Risks associated with
getting this wrong, not enough time is spent really thinking about this
in advance.

Let's take a closer look at this problem in the next chapter, Boundary
Risk.

\hypertarget{sources}{%
\section{Sources}\label{sources}}

\begin{itemize}
\item
  \texttt{sd1}: Defending your code against dependency problems.
  https://www.software.ac.uk/resources/guides/defending-your-code-against-dependency-problems
\item
  \texttt{sd2}: How to choose an open source library.
  https://stackoverflow.com/questions/2960371/how-to-choose-an-open-source-library
\item
  \texttt{sd3}: Open Source - To use or not to use.
  https://www.forbes.com/sites/forbestechcouncil/2017/07/20/open-source-to-use-or-not-to-use-and-how-to-choose/2/\#39e67e445a8c
\item
  \texttt{sd4}: SaaS Checklist - Nine Factors to Consider.
  https://www.zdnet.com/article/saas-checklist-nine-factors-to-consider-when-selecting-a-vendor/
\item
  \texttt{sd5}: How to Evaluate SaaS Vendors.
  http://sandhill.com/article/how-to-evaluate-saas-vendors-five-key-considerations/
\end{itemize}

\hypertarget{process-risk}{%
\chapter{Process Risk}\label{process-risk}}

Process Risk, as we will see, is the risk you take on whenever you
embark on completing a \emph{process}.

\begin{quotation}

``\textbf{Process:} A process is a set of activities that interact to
achieve a result.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Process}{\textemdash  Process, \emph{Wikipedia}}}
\end{quotation}

Processes commonly involve \emph{forms}: If you're filling out a form
(whether on paper or on a computer) then you're involved in a process of
some sort, whether an ``Account Registration'' process, ``Loan
Application'' process or ``Consumer Satisfaction Survey'' process.
Sometimes, they involve events occurring: a
\href{https://en.wikipedia.org/wiki/Software_build}{build process} might
start after you commit some code, for example. And, the \emph{code we
write} is usually describing some kind of process we want performed.

\hypertarget{the-purpose-of-process}{%
\section{The Purpose Of Process}\label{the-purpose-of-process}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/process/process-risk-introduction-400dpi.png}
\caption{Introducing process can mitigate many
risks\label{process-risk-introduction.png}}
\end{figure}

As Figure \ref{process-risk-introduction.png} shows, process exists to
mitigate other kinds of risk. For example:

\begin{itemize}
\tightlist
\item
  \textbf{Coordination Risk:} You can often use process to help people
  coordinate. For example, a
  \href{https://en.wikipedia.org/wiki/Production_line}{Production Line}
  is a process where work being done by one person is pushed to the next
  person when it's done. A meeting booking process is designed to
  efficiently allocate meeting rooms.
\item
  \textbf{Operational Risk:} This encompasses the risk of people
  \emph{not doing their job properly}. But, by having a process, (and
  asking, did this person follow the process?) you can draw a
  distinction between a process failure and a personnel failure. For
  example, making a loan to a money launderer \emph{could} be a failure
  of the loan agent. But, if they followed the \emph{process}, it's a
  failure of the Process itself.
\item
  \textbf{Complexity Risk:} Working \emph{within a process} can reduce
  the amount of Complexity you have to think about. We accept that
  processes are going to slow us down, but we appreciate the reduction
  in risk this brings. Clearly, the complexity hasn't gone away, but
  it's hidden within design of the process. For example,
  \href{https://en.wikipedia.org/wiki/McDonald's}{McDonalds} tries to
  design its operation so that preparing each food item is a simple
  process to follow, reducing complexity (and training time) for the
  staff.
\end{itemize}

These are all examples of Risk Mitigation for the \emph{owners} of the
process. But often the \emph{consumers} of the process end up picking up
Process Risks as a result:

\begin{itemize}
\tightlist
\item
  \textbf{Invisibility Risk:} It's often not possible to see how far
  along a process is to completion. Sometimes, you can do this to an
  extent. For example, when I send a package for delivery, I can see
  roughly how far it's got on the tracking website. But, this is still
  less-than-complete information, and is a representation of reality.
\item
  \textbf{Dead-End Risk:} Even if you have the right process, initiating
  a process has no guarantee that your efforts won't be wasted and
  you'll be back where you started from. The chances of this happening
  increase as you get further from the standard use-case for the
  process, and the sunk cost increases with the length of time the
  process takes to complete.
\item
  \textbf{Feature Access Risk:} Processes generally handle the common
  stuff, but ignore the edge cases. For example, a form on a website
  might not be designed to be accessible to disabled people, or might
  only cater to some common subset of use-cases.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/process/process-risk-400dpi.png}
\caption{Process Risk, and it's consequences, compared with Agency
Risk\label{process-risk.png}}
\end{figure}

When we talk about ``Process Risk'' we are really referring to these
types of risks, arising from ``following a set of instructions.''
Compare this with Agency Risk (which we will review in a forthcoming
chapter), which is risks due to \emph{not} following the instructions,
as shown in Figure \ref{process-risk.png} . Let's look at two examples,
how Process Risk can lead to Invisibility Risks and Agency Risk.

\hypertarget{processes-and-invisibility-risk}{%
\subsection{Processes And Invisibility
Risk}\label{processes-and-invisibility-risk}}

Processes tend to work well for the common cases, because \emph{practice
makes perfect}. but they are really tested when unusual situations
occur. Expanding processes to deal with edge-cases incurs Complexity
Risk, so often it's better to try and have clear boundaries of what is
``in'' and ``out'' of the process' domain.

Sometimes, processes are \emph{not} used commonly. How can we rely on
them anyway? Usually, the answer is to build in extra feedback loops
anyway:

\begin{itemize}
\tightlist
\item
  Testing that backups work, even when no backup is needed.
\item
  Running through a disaster recovery scenario at the weekend.
\item
  Increasing the release cadence, so that we practice the release
  process more.
\end{itemize}

The feedback loops allow us to perform Retrospectives and Reviews to
improve our processes.

\hypertarget{processes-sign-offs-and-agency-risk}{%
\subsection{Processes, Sign-Offs and Agency
Risk}\label{processes-sign-offs-and-agency-risk}}

Often, Processes will include sign-off steps. The Sign-Off is an
interesting mechanism:

\begin{itemize}
\tightlist
\item
  By signing off on something for the business, people are usually in
  some part staking their reputation on something being right.
\item
  Therefore, you would expect that sign-off involves a lot of Agency
  Risk: people don't want to expose themselves in career-limiting ways.
\item
  Therefore, the bigger the risk they are being asked to swallow, the
  more cumbersome and protracted the sign off process.
\end{itemize}

Often, Sign Offs boil down to a balance of risk for the signer: on the
one hand, \emph{personal, career risk} from signing off, on the other,
the risk of upsetting the rest of the staff waiting for the sign-off,
and the Dead End Risk of all the effort gone into getting the sign off
if they don't.

This is a nasty situation, but there are a couple of ways to de-risk
this:

\begin{itemize}
\tightlist
\item
  Break Sign Offs down into bite-size chunks of risk that are acceptable
  to those doing the sign-off.
\item
  Agree far-in-advance the sign-off criteria. As discussed in Risk
  Theory, people have a habit of heavily discounting future risk, and
  it's much easier to get agreement on the \emph{criteria} than it is to
  get the sign-off.
\end{itemize}

\hypertarget{evolution-of-process}{%
\section{Evolution Of Process}\label{evolution-of-process}}

Writing software and designing processes are often overlapping
activities. Often, we build processes when we are writing software.
Since designing a process is an activity like any other on a project,
you can expect that the Risk-First explanation for why we do this is
\emph{risk management}.

Processes arise because of a desire to mitigate risk. When whole
organisations follow that desire independently, we end up in an
evolutionary or gradient-descent style scenario of risk reduction (as we
will see below).

Here, we are going to look at how a
\href{https://en.wikipedia.org/wiki/Business_process}{Business Process}
might mature within an organisation.

\begin{quotation}

``\textbf{Business Process} or \textbf{Business Method} is a collection
of related, structured activities or tasks that in a specific sequence
produces a service or product (serves a particular business goal) for a
particular customer or customers.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Business_process}{\textemdash  Business Process, \emph{Wikipedia}}}
\end{quotation}

Let's look at an example of how that can happen in a step-wise way.

\begin{figure}
\centering
\includegraphics{images/generated/risks/process/step1-400dpi.png}
\caption{Step 1: Clients \texttt{C} need \texttt{A} to do their
jobs\label{step1.png}}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  As Figure \ref{step1.png} shows, there exists a group of people inside
  a company \texttt{C}, which need a certain something \texttt{A} in
  order to get their jobs done. Because they are organising, providing
  and creating \texttt{A} to do their jobs, they are responsible for all
  the Complexity Risk of \texttt{A}. The harder it is for them to secure
  \texttt{A}, the higher the risk.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/generated/risks/process/step2-400dpi.png}
\caption{Step 2: Team \texttt{B} doing \texttt{A} for clients
\texttt{C}\label{step2.png}}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Because \texttt{A} is so complex, a new team (\texttt{B}) is spun up
  to deal with the Complexity Risk, which lets \texttt{C} get on with
  their ``proper'' jobs. As shown in Figure \ref{step2.png}, this is
  really useful: It makes \texttt{C}'s job much easier (reduced
  Complexity Risk) as they have an easier path to \texttt{A} than
  before. But the risk for \texttt{A} hasn't really gone - they're now
  just dependent on \texttt{B} instead. When members of \texttt{B} fail
  to deliver, this is Staff Risk for \texttt{C}.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{images/generated/risks/process/step3-400dpi.png}
\caption{Step 3: Team \texttt{B} formalises the arrangement with a
Process\label{step3.png}}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Problems are likely to occur eventually in the \texttt{B}/\texttt{C}
  relationship. Perhaps some members of the \texttt{B} team give better
  service than others, or deal with more variety in requests. In order
  to standardise the response from \texttt{B}, and also to reduce
  scope-creep in requests from \texttt{C}, \texttt{B} organises
  bureaucratically, so that there is a controlled process (\texttt{P})
  by which \texttt{A} can be accessed. Members of teams \texttt{B} and
  \texttt{C} now interact via some request mechanism like forms (or
  another protocol).
\end{enumerate}

\begin{itemize}
\tightlist
\item
  As shown in Figure \ref{step3.png}, because of \texttt{P}, \texttt{B}
  can now deal with requests on a first-come-first-served basis and deal
  with them all in the same way: the more unusual requests from
  \texttt{C} might not fit the model. These Complexity Risks are now the
  problem of the form-filler in \texttt{C}.
\item
  Since this is Abstraction, \texttt{C} now has Invisibility Risk since
  it can't access team \texttt{B} and see how it works.
\item
  Team \texttt{B} may also use \texttt{P} to introduce other bureaucracy
  like authorisation and sign-off steps or payment barriers. All of this
  increases complexity for team C.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/process/step4-400dpi.png}
\caption{Person D acts as a middleman for customers needing some variant
of \texttt{A}\label{step4.png}}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Teams like \texttt{B} can sometimes end up in ``Monopoly'' positions
  within a business. This means that clients like \texttt{C} are forced
  to deal with whatever process \texttt{B} wishes to enforce. Although
  they are unable to affect process \texttt{P}, \texttt{C} still have
  risks they want to transfer.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  In Figure \ref{step4.png}, Person \texttt{D}, who has experience
  working with team \texttt{B} acts as a middleman for some of
  \texttt{C}, requiring some variant of \texttt{A} . They are able to
  help navigate the bureaucratic process (handle with Process Risk).
\item
  The cycle potentially starts again: will \texttt{D} end up becoming a
  new team, with a new process?
\end{itemize}

In this example, you can see how the organisation evolves process to
mitigate risk around the use (and misuse) of \texttt{A}. This is an
example of \emph{Process following Strategy}:

\begin{quotation}

In this conception, you can see how the structure of an organisation
(the teams and processes within it, the hierarchy of control) will
`evolve' from the resources of the organisation and the strategy it
pursues. Processes evolve to meet the needs of the organisation."

\sourceatright{\href{http://www.mintzberg.org/books/strategy-safari}{\textemdash  Minzberg, \emph{Strategy Safari}}}
\end{quotation}

Two key take-aways from this:

\begin{itemize}
\tightlist
\item
  \textbf{The Process Gets More Complex:} With different teams working
  to mitigate different risks in different ways, we end up with a more
  complex situation than we started in. Although we've \emph{evolved} in
  this direction by mitigating risks, it's not necessarily the case that
  the end result is \emph{more efficient}. In fact, as we will see in
  Map-And-Territory Risk, this evolution can lead to some very
  inadequate (but nonetheless stable) systems.
\item
  \textbf{Organisational process evolves to mitigate risk:} Just as
  we've shown that actions are about mitigating risk, we've now seen
  that these actions get taken in an evolutionary way. That is, there is
  ``pressure'' on our internal processes to reduce risk. The people
  maintaining these processes feel the risk, and modify their processes
  in response. Let's look at a real-life example:
\end{itemize}

\hypertarget{an-example---release-processes}{%
\section{An Example - Release
Processes}\label{an-example---release-processes}}

For many years I have worked in the Finance Industry, and it's given me
time to observe how, across an entire industry, process can evolve, both
in response to regulatory pressure but also because of organisational
maturity, and mitigating risks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initially, I could release software by logging onto the production
  accounts with a shared password that everyone knew, and deploy
  software or change data in the database.
\item
  The first issue with this is Agency Risk from bad actors: How could
  you know that the numbers weren't being altered in the databases?
  \emph{Production Auditing} was introduced so that at least you could
  tell what was being changed and when, in order to point the blame
  later.
\item
  But, there was still plenty of scope for deliberate or accidental
  Dead-End Risk damage. Next, passwords were taken out of the hands of
  developers and you needed approval to ``break glass'' to get onto
  production.
\item
  The increasing complexity (and therefore Complexity Risk) in
  production environments meant that sometimes, changes collided with
  each other, or were performed at inopportune times. Change Requests
  were introduced. This is an approval process which asks you to
  describe what you want to change in production, and why you want to
  change it.
\item
  The change request software is generally awful, making the job of
  raising change requests tedious and time-consuming. Therefore,
  developers would \emph{automate} the processes for release, sometimes
  including the process to write the change request. This allowed them
  to improve release cadence, at the expense of owning more code.
\item
  Auditors didn't like the fact that this automation existed, because
  effectively, that meant that developers could get access to production
  with the press of a button, effectively taking you back to step
  1\ldots{}
\end{enumerate}

\hypertarget{bureaucracy-risk}{%
\section{Bureaucracy Risk}\label{bureaucracy-risk}}

Where we've talked about process evolution above, the actors involved
have been acting in good faith: they are working to mitigate risk in the
organisation. The Process Risk that accretes along the way is an
\emph{unintended consequence}: There is no guarantee that the process
that arises will be humane and intuitive. Many organisational processes
end up being baroque or Kafka-esque, forcing unintuitive behaviour on
their users. This is partly because process design is \emph{hard}, and
it's difficult to anticipate all the various ways a process will be used
ahead-of-time.

But \href{https://en.wikipedia.org/wiki/Parkinsons_law}{Parkinson's Law}
takes this one step further: the human actors shaping the organisation
will abuse their positions of power in order to further their own
careers (this is Agency Risk, which we will come to in a future
chapter):

\begin{quotation}

``Parkinson's law is the adage that''work expands so as to fill the time
available for its completion``. It is sometimes applied to the growth of
bureaucracy in an organisation\ldots{} He explains this growth by two
forces: (1) `An official wants to multiply subordinates, not rivals' and
(2) `Officials make work for each other.'\,''

\sourceatright{\href{https://en.wikipedia.org/wiki/Parkinsons_law}{\textemdash  Parkinson's Law, \emph{Wikipedia}}  }
\end{quotation}

This implies that there is a tendency for organisations to end up with
\emph{needless levels of Process Risk}.

To fix this, design needs to happen at a higher level. In our code, we
would Refactor these processes to remove the unwanted complexity. In an
business, it requires re-organisation at a higher level to redefine the
boundaries and responsibilities between the teams.

Next in the tour of Dependency Risks, it's time to look at Boundary
Risk.

\hypertarget{boundary-risk}{%
\chapter{Boundary Risk}\label{boundary-risk}}

In the previous chapters on Dependency Risk we've touched on Boundary
Risk several times, but now it's time to tackle it head-on and discuss
this important type of risk.

In terms of the Risk Landscape, Boundary Risk is exactly as it says: a
\emph{boundary}, \emph{wall} or other kind of obstacle in your way to
making a move you want to make. This changes the nature of the Risk
Landscape, and introduces a maze-like component to it. It also means
that we have to make \emph{decisions} about which way to go, knowing
that our future paths are constrained by the decisions we make.

As we discussed in Complexity Risk, there is always the chance we end up
at a Dead End, and we've done work that we need to throw away. In this
case, we'll have to head back and make a different decision.

\hypertarget{emergence-through-choice}{%
\section{Emergence Through Choice}\label{emergence-through-choice}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/boundary/boundary-risk-400dpi.png}
\caption{Boundary Risk is due to Complexity Risk, Dependency Risk and
Communication Risk\label{boundary-risk.png}}
\end{figure}

Boundary Risk is an emergent risk, which exists at the intersection of
Complexity Risk, Dependency Risk and Communication Risk. Because of
that, it's going to take a bit of time to pick it apart and understand
it, so we're going to build up to this in stages.

Let's start with an obvious example: Say you want to learn to play some
music. There are a \emph{multitude} of options available to you, and you
might choose an \emph{uncommon} instrument like a
\href{https://en.wikipedia.org/wiki/Balalaika}{Balalaika}, or you might
choose a \emph{common} one like a piano or guitar. In any case, once you
start learning this instrument, you have picked up the three risks from
Figure \ref{boundary-risk.png}:

\begin{itemize}
\tightlist
\item
  \textbf{Dependency Risk:} You have a \emph{physical} Dependency on it
  in order to play music, so get to the music shop and buy one.
\item
  \textbf{Communication Risk:} You have to \emph{communicate} with the
  instrument in order to get it to make the sounds you want. And you
  have Learning Curve Risk in order to be able to do that.
\item
  \textbf{Complexity Risk:} As \emph{a music playing system}, you now
  have an extra component (the instrument), with all the attendant
  complexity of looking after that instrument, tuning it, and so on.
\end{itemize}

Those risks are true for \emph{any} instrument you choose. However, if
you choose the \emph{uncommon} instrument you have \emph{worse} Boundary
Risk, because the \emph{ecosystem} is smaller. It might be hard to find
a tutor, or a band needing a balalaika, and you're unlikely to find one
in a friend's house (compared to the guitar, say).

If you spend time learning to play the piano, you're mitigating
Communication Risk issues, but \emph{mostly}, your skills won't be
transferable to playing the guitar. Your decision to choose one
instrument over another cements the Boundary Risk: you're following a
path on the Risk Landscape and changing to a different path is
\emph{expensive}.

Also, it stands to reason that making \emph{any} choice is better than
making \emph{no} choice, because you can't try and learn \emph{all} the
instruments. Doing that, you'd make no meaningful progress on any of
them.

\hypertarget{boundary-risk-for-software-dependencies}{%
\section{Boundary Risk For Software
Dependencies}\label{boundary-risk-for-software-dependencies}}

Let's look at a software example now.

As discussed in Software Dependency Risk, if we are going to use a
software tool as a dependency, we have to accept the complexity of it's
protocols. You have to use it's protocol: it won't come to you.

\begin{figure}
\centering
\includegraphics{images/generated/risks/boundary/choices-400dpi.png}
\caption{Our System receives data from the \texttt{input}, translates it
and sends it to the \texttt{output}. But which dependency should we use
for the translation, if any?\label{choices.png}}
\end{figure}

Let's take a look at a hypothetical system structure, in Figure
\ref{choices.png}. In this design, we have are transforming data from
the \texttt{input} to the \texttt{output}. But how should we do it?

\begin{itemize}
\tightlist
\item
  We could use library `a', using the Protocols of `a', and having a
  dependency on `a'.
\item
  We could use library `b', using the Protocols of `b', and having a
  dependency on `b'.
\item
  We could use neither, and avoid the dependency, but potentially pick
  up lots more Codebase Risk and Schedule Risk because we have to code
  our own alternative to `a' and `b'.
\end{itemize}

The choice of approach presents us with Boundary Risk, because we don't
know that we'll necessarily be successful with any of these options
until we \emph{go down the path} of choosing one to see:

\begin{itemize}
\tightlist
\item
  Maybe `a' has some undocumented drawbacks that are going to hold us
  up.
\item
  Maybe `b' works on some streaming API basis, that is incompatible with
  the input protocol.
\item
  Maybe `a' runs on Windows, whereas our code runs on Linux.
\end{itemize}

\ldots{} and so on.

\hypertarget{boundary-risk-pinned-down}{%
\section{Boundary Risk Pinned Down}\label{boundary-risk-pinned-down}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/software-dependency/library-400dpi.png}
\caption{The tradeoff for using a library\label{library.png}}
\end{figure}

Wherever we integrate dependencies with complex protocols, we
potentially have Boundary Risk. The more complex the dependencies being
integrated, the higher the risk. As shown in Figure \ref{library.png},
when we choose software tools, languages or libraries to help us build
our systems, we are trading Complexity Risk for Boundary Risk. It could
include:

\begin{itemize}
\tightlist
\item
  The \emph{sunk cost} of the Learning Curve we've overcome to integrate
  the dependency, when it fails to live up to expectations.
\item
  The likelihood of, and costs of changing to something else in the
  future.
\item
  The risk of Lock In.
\end{itemize}

As we saw in Software Dependency Risk, Boundary Risk is a big factor in
choosing libraries and services. However, it can apply to any kind of
dependency:

\begin{itemize}
\tightlist
\item
  If you're depending on a Process or Organisation, they might change
  their products or quality, making the effort you put into the
  relationship worthless.
\item
  If you're depending on Staff, they might leave, meaning your efforts
  on training them don't pay back as well as you hoped.
\item
  If you're depending on an Event occurring at a particular time, you
  might have a lot of work to reorganise your life if it changes time or
  place.
\item
  If you are tied into a contract, you might have to pay for something
  despite no longer using it.
\end{itemize}

\hypertarget{boundary-risk-and-sunk-costs}{%
\section{Boundary Risk and Sunk
Costs}\label{boundary-risk-and-sunk-costs}}

Because of Boundary Risk's relationship to Learning Curve Risk, we can
avoid accreting it by choose the \emph{simplest} and \emph{fewest}
dependencies for any job. Let's look at some examples:

\begin{itemize}
\tightlist
\item
  \texttt{mkdirp} is an \href{https://www.npmjs.com}{npm} module
  defining a single function. This function takes a single string
  parameter and recursively creating directories. Because the protocol
  is so simple, there is almost no Boundary Risk.
\item
  Using a particular brand of database with a JDBC driver comes with
  \emph{some} Boundary Risk: but the boundary is specified by a
  standard. Although the standard doesn't cover every aspect of the
  behaviour of the database, it does minimise risk, because if you are
  familiar with one JDBC driver, you'll be familiar with them all, and
  swapping one for another is relatively easy.
\item
  Choosing a language or framework comes with higher Boundary Risk: you
  are expected to yield to the framework's way of behaving throughout
  your application. You cannot separate the concern easily, and swapping
  out the framework for another is likely to leave you with a whole new
  set of assumptions and interfaces to deal with.
\end{itemize}

\hypertarget{lock-in}{%
\section{Lock-In}\label{lock-in}}

Sometimes, one choice leads to another, and you're forced to ``double
down'' on your original choice, and head further down the path of
commitment.

On the face of it,
\href{https://en.wikipedia.org/wiki/WordPress}{WordPress} and
\href{https://en.wikipedia.org/wiki/Drupal}{Drupal} \emph{should} be
very similar:

\begin{itemize}
\tightlist
\item
  They are both
  \href{https://en.wikipedia.org/wiki/Content_management_system}{Content
  Management Systems}
\item
  They both use a
  \href{https://en.wikipedia.org/wiki/LAMP_(software_bundle)}{LAMP
  (Linux, Apache, MySql, PHP) Stack}
\item
  They were both started around the same time (2001 for Drupal, 2003 for
  WordPress)
\item
  They are both Open-Source, and have a wide variety of
  \href{https://en.wikipedia.org/wiki/Plug-in_(computing)}{Plugins}.
  That is, ways for other programmers to extend the functionality in new
  directions.
\end{itemize}

In practice, they are very different, as we will see. The quality, and
choice of plugins for a given platform, along with factors such as
community and online documentation is often called its
\href{https://en.wikipedia.org/wiki/Software_ecosystem}{ecosystem}:

\begin{quotation}

``Software Ecosystem is a book written by David G. Messerschmitt and
Clemens Szyperski that explains the essence and effects of a''software
ecosystem``, defined as a set of businesses functioning as a unit and
interacting with a shared market for software and services, together
with relationships among them. These relationships are frequently
underpinned by a common technological platform and operate through the
exchange of information, resources, and artifacts.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Software_ecosystem}{\textemdash  Software Ecosystem, \emph{Wikipedia}}}
\end{quotation}

You can think of the ecosystem as being like the footprint of a town or
a city, consisting of the buildings, transport network and the people
that live there. Within the city, and because of the transport network
and the amenities available, it's easy to make rapid, useful moves on
the Risk Landscape. In a software ecosystem it's the same: the ecosystem
has gathered together to provide a way to mitigate various different
Feature Risks in a common way.

Ecosystem size is one key determinant of Boundary Risk: a \emph{large}
ecosystem has a large boundary circumference. Boundary Risk is lower in
a large ecosystem because your moves on the Risk Landscape are unlikely
to collide with it. The boundary \emph{got large} because other
developers before you hit the boundary and did the work building the
software equivalents of bridges and roads and pushing it back so that
the boundary didn't get in their way.

In a small ecosystem, you are much more likely to come into contact with
the edges of the boundary. \emph{You} will have to be the developer that
pushes back the frontier and builds the roads for the others. This is
hard work.

\hypertarget{big-ecosystems-get-bigger}{%
\subsection{Big Ecosystems Get Bigger}\label{big-ecosystems-get-bigger}}

In the real world, there is a tendency for \emph{big cities to get
bigger}. The more people that live there, the more services they
provide, and therefore, the more immigrants they attract. And, it's the
same in the software world. In both cases, this is due to the Network
Effect:

\begin{quotation}

``A network effect (also called network externality or demand-side
economies of scale) is the positive effect described in economics and
business that an additional user of a good or service has on the value
of that product to others. When a network effect is present, the value
of a product or service increases according to the number of others
using it.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Network_effect}{\textemdash  Network Effect, \emph{Wikipedia}}}
\end{quotation}

\begin{figure}
\centering
\includegraphics{images/numbers/wordpress-drupal-chart.png}
\caption{WordPress vs Drupal adoption over 8 years, according to
\href{https://w3techs.com/technologies/history_overview/content_management/all/y}{w3techs.com}}
\end{figure}

You can see the same effect in the software ecosystems with the adoption
rates of WordPress and Drupal, shown in Figure \ref{library.png}. Note:
this is over \emph{all sites on the internet}, so Drupal accounts for
hundreds of thousands of sites. In 2018, WordPress is approximately 32\%
of all web-sites. For Drupal it's 2\%.

Did WordPress gain this march because it was always \emph{better} than
Drupal? That's arguable. Certainly, they're not different enough that
WordPress is 16x better. That it's this way round could be
\emph{entirely accidental}, and a result of Network Effect.

But, by now, if they \emph{are} to be compared side-by-side, WordPress
\emph{should be better} due to the sheer number of people in this
ecosystem who are\ldots{}

\begin{itemize}
\tightlist
\item
  Creating web sites.
\item
  Using those sites.
\item
  Submitting bug requests.
\item
  Fixing bugs.
\item
  Writing documentation.
\item
  Building plugins.
\item
  Creating features.
\item
  Improving the core platform.
\end{itemize}

Is bigger always better? There are five further factors to
consider\ldots{}

\hypertarget{the-peter-principle}{%
\subsubsection{1. The Peter Principle}\label{the-peter-principle}}

When a tool or platform is popular, it is under pressure to increase in
complexity. This is because people are attracted to something useful,
and want to extend it to new purposes. This is known as \emph{The Peter
Principle}:

\begin{quotation}

``The Peter principle is a concept in management developed by Laurence
J. Peter, which observes that people in a hierarchy tend to rise to
their `level of incompetence'.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Peter_principle}{\textemdash  The Peter Principle, \emph{Wikipedia}}}
\end{quotation}

Although designed for \emph{people}, it can just as easily be applied to
any other dependency you can think of. This means when things get
popular, there is a tendency towards Conceptual Integrity Risk and
Complexity Risk.

\begin{figure}
\centering
\includegraphics{images/numbers/java_classes_by_version.png}
\caption{Java Public Classes By Version
(3-9)\label{java_classes_by_version.png}}
\end{figure}

The above chart is an example of this: look at how the number of public
classes (a good proxy for the boundary) has increased with each release.

\hypertarget{backward-compatibility-1}{%
\subsubsection{2. Backward
Compatibility}\label{backward-compatibility-1}}

As we saw in Software Dependency Risk, The art of good design is to
afford the greatest increase in functionality with the smallest increase
in complexity possible, and this usually means
\href{https://en.wikipedia.org/wiki/Refactoring}{Refactoring}. But, this
is at odds with Backward Compatibility.

Each new version has a greater functional scope than the one before
(pushing back Boundary Risk), making the platform more attractive to
build solutions in. But this increases the Complexity Risk as there is
more functionality to deal with.

\hypertarget{focus-vs-over-reach}{%
\subsubsection{3. Focus vs Over-Reach}\label{focus-vs-over-reach}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/boundary/boundary-risk2-400dpi.png}
\caption{The Peter Principle: Backward Compatibility + Extension leads
to complexity and learning curve risk\label{boundary-risk2.png}}
\end{figure}

You can see in Figure \ref{boundary-risk2.png} the Peter Principle at
play: as more responsibility is given to a dependency, the more complex
it gets, and the greater the learning curve to work with it. Large
ecosystems like Java react to Learning Curve Risk by having copious
amounts of literature to read or buy to help, but it is still
off-putting.

Because Complexity is Mass, large ecosystems can't respond quickly to
Feature Drift. This means that when the world changes, \emph{new}
systems will come along to plug the gaps.

This implies a trade-off: - Sometimes it's better to accept the Boundary
Risk innate in a smaller system than try to work within the bigger, more
complex system.

\hypertarget{ecosystem-bridges}{%
\subsubsection{4. Ecosystem Bridges}\label{ecosystem-bridges}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/boundary/boundary-risk3-400dpi.png}
\caption{Boundary Risk is mitigated when a bridge is built between
ecosystems\label{boundary-risk3.png}}
\end{figure}

Sometimes, technology comes along that allows us to cross boundaries,
like a \emph{bridge} or a \emph{road}. This has the effect of making it
easy to to go from one self-contained ecosystem to another. Going back
to WordPress, a simple example might be the
\href{https://en-gb.wordpress.org/plugins/google-analytics-dashboard-for-wp/}{Analytics
Dashboard} which provides
\href{https://en.wikipedia.org/wiki/Google_Marketing_Platform}{Google
Analytics} functionality inside WordPress.

I find, a lot of code I write is of this nature: trying to write the
\emph{glue code} to join together two different \emph{ecosystems}.

\begin{sidewaystable} 

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.18\columnwidth}\raggedright
Protocol Risk From A\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Protocol Risk From B\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright
Resulting Bridge Complexity\strut
\end{minipage} & \begin{minipage}[b]{0.35\columnwidth}\raggedright
Example\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Simple\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Changing from one date format to another.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Moderate\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Status Dashboard.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Object-Relational Mapping (ORM) Tools.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
High + Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Moderate, Versioned\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Simple Phone App, e.g.~note-taker or calculator\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
High\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Modern browser (see below)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Evolving\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
Very Complex\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
Google Search, Scala\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\end{sidewaystable} 

As shown in Figure \ref{boundary-risk3.png}, mitigating Boundary Risk
involves taking on complexity. The more Protocol Complexity there is to
bridge the two ecosystems, the more Complex the bridge will necessarily
be. The above table shows some examples of this.

From examining the {[}Protocol
Risk{]}{[}Communication-Risk\#protocol-risk{]} at each end of the bridge
you are creating, you can get a rough idea of how complex the endeavour
will be:

\begin{itemize}
\tightlist
\item
  If it's low-risk at both ends, you're probably going to be able to
  knock it out easily. Like translating a date, or converting one file
  format to another.
\item
  Where one of the protocols is \emph{evolving}, you're definitely going
  to need to keep releasing new versions. The functionality of a
  \texttt{Calculator} app on my phone remains the same, but new versions
  have to be released as the phone APIs change, screens change
  resolution and so on.
\end{itemize}

\hypertarget{standards}{%
\subsubsection{5. Standards}\label{standards}}

Standards allow us to achieve the same thing, in one of two ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Abstract over the ecosystems.} Provide a \emph{standard}
  protocol (a \emph{lingua franca}) which can be converted down into the
  protocol of any of a number of competing ecosystems.
\end{enumerate}

\begin{itemize}
\item
  \href{https://en.wikipedia.org/wiki/C_(programming_language)}{C}: The
  C programming language provided a way to get the same programs
  compiled against different CPU instruction sets, therefore providing
  some \emph{portability} to code. The problem was, each different
  operating system would still have it's own libraries, and so to
  support multiple operating systems, you'd have to write code against
  multiple different libraries.
\item
  \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}
  took what C did and went one step further, providing interoperability
  at the library level. Java code could run anywhere where Java was
  installed.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Force adoption.} All of the ecosystems start using the
  standard for fear of being left out in the cold. Sometimes, a
  standards body is involved, but other times a ``de facto'' standard
  emerges that everyone adopts.
\end{enumerate}

\begin{itemize}
\item
  \href{https://en.wikipedia.org/wiki/ASCII}{ASCII}: fixed the
  different-character-sets boundary risk by being a standard that others
  could adopt. Before everyone agreed on ASCII, copying data from one
  computer system to another was a massive pain, and would involve some
  kind of translation.
  \href{https://en.wikipedia.org/wiki/Unicode}{Unicode} continues this
  work.
\item
  Internet Protocol: As we saw in Communication Risk, the Internet
  Protocol (IP) is the \emph{lingua franca} of the modern Internet.
  However, at one period of time, there were many competing standards.
  and IP was the ecosystem that ``won'', and was subsequently
  standardised by the
  \href{https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force}{IETF}.
  This is actually an example of \emph{both} approaches: as we saw in
  Communication Risk, Internet Protocol is also an abstraction over
  lower-level protocols.
\end{itemize}

\hypertarget{boundary-risk-cycle}{%
\section{Boundary Risk Cycle}\label{boundary-risk-cycle}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/boundary/cycle-400dpi.png}
\caption{Boundary Risk Decreases With Bridges and
Standards\label{cycle.png}}
\end{figure}

Boundary Risk seems to progress in cycles. As a piece of technology
becomes more mature, there are more standards and bridges, and boundary
risk is lower. Once Boundary Risk is low and a particular approach is
proven, there will be innovation upon this, giving rise to new
opportunities for Boundary Risk. Here are some examples:

\begin{itemize}
\tightlist
\item
  Processor Chip manufacturers had done something similar in the 1970's
  and 1980's: by providing features (instructions) on their processors
  that other vendors didn't have, they made their processors more
  attractive to system integrators. However, since the instructions were
  different on different chips, this created Boundary Risk for the
  integrators. Intel and Microsoft were able to use this fact to build a
  big ecosystem around Windows running on Intel chips (so called,
  WinTel). The Intel instruction set is nowadays a \emph{de-facto}
  standard for PCs.
\item
  In the late 1990s, faced with the emergence of the nascent World Wide
  Web, and the
  \href{https://en.wikipedia.org/wiki/Netscape_Navigator}{Netscape
  Navigator} browser,
  \href{https://en.wikipedia.org/wiki/Microsoft}{Microsoft} adoped a
  strategy known as
  \href{https://en.wikipedia.org/wiki/Embrace_and_extend}{Embrace and
  Extend}. The idea of this was to subvert the HTML standard to their
  own ends by \emph{embracing} the standard and creating their own
  browser Internet Explorer and then \emph{extending} it with as much
  functionality as possible, which would then \emph{not work} in
  Netscape Navigator. They then embarked on a campaign to try and get
  everyone to ``upgrade'' to Internet Explorer. In this way, they hoped
  to ``own'' the Internet, or at least, the software of the browser,
  which they saw as analogous to being the ``operating system'' of the
  Internet, and therefore a threat to their own operating system,
  \href{https://en.wikipedia.org/wiki/Microsoft_Windows}{Windows}.
\item
  We currently have just two main \emph{mobile} ecosystems (although
  there used to be many more):
  \href{https://en.wikipedia.org/wiki/IOS}{Apple's iOS} and
  \href{https://en.wikipedia.org/wiki/Android_(operating_system)}{Google's
  Android}, which are both \emph{very} different and complex ecosystems
  with large, complex boundaries. They are both innovating as fast as
  possible to keep users happy with their features. Bridging Tools like
  \href{https://en.wikipedia.org/wiki/Xamarin}{Xamarin} exist which
  allow you to build applications sharing code over both platforms.
\item
  Currently, Amazon Web Services (AWS) are competing with
  \href{https://en.wikipedia.org/wiki/Microsoft_Azure}{Microsoft Azure}
  and \href{https://en.wikipedia.org/wiki/Google_Cloud_Platform}{Google
  Cloud Platform} over building tools for
  \href{https://en.wikipedia.org/wiki/Platform_as_a_service}{Platform as
  a Service (PaaS)} (running software in the cloud). They are both
  racing to build new functionality, but at the same time it's hard to
  move from one vendor to another as there is no standardisation on the
  tools.
\end{itemize}

\hypertarget{everyday-boundary-risks}{%
\section{Everyday Boundary Risks}\label{everyday-boundary-risks}}

Although ecosystems are one very pernicious type of boundary in software
development, it's worth pointing out that Boundary Risk occurs all the
time. Let's look at some ways:

\begin{itemize}
\tightlist
\item
  \textbf{Configuration}: When software has to be deployed onto a
  server, there has to be configuration (usually on the command line, or
  via configuration property files) in order to bridge the boundary
  between the \emph{environment it's running in} and the \emph{software
  being run}. Often, this is setting up file locations, security keys
  and passwords, and telling it where to find other files and services.
\item
  \textbf{Integration Testing}: Building a unit test is easy. You are
  generally testing some code you have written, aided with a testing
  framework. Your code and the framework are both written in the same
  language, which means low boundary risk. But, to \emph{integration
  test} you need to step outside this boundary and so it becomes much
  harder. This is true whether you are integrating with other systems
  (providing or supplying them with data) or parts of your own system
  (say testing the client-side and server parts together).
\item
  \textbf{User Interface Testing}: If you are supplying a
  user-interface, then the interface with the user is already a complex,
  under-specified risky protocol. Although tools exist to automate UI
  testing (such as
  \href{https://en.wikipedia.org/wiki/Selenium_(software)}{Selenium},
  these rarely satisfactorily mitigate this protocol risk: can you be
  sure that the screen hasn't got strange glitches, that the mouse moves
  correctly, that the proportions on the screen are correct on all
  browsers?
\item
  \textbf{Jobs}: When you pick a new technology to learn and add to your
  CV, it's worth keeping in mind how useful this will be to you in the
  future. It's career-limiting to be stuck in a dying ecosystem and need
  to retrain.
\item
  \textbf{Teams}: if you're asked to build a new tool for an existing
  team, are you creating Boundary Risk by using tools that the team
  aren't familiar with?
\item
  \textbf{Organisations}: Getting teams or departments to work with each
  other often involves breaking down Boundary Risk. Often the
  departments use different tool-sets or processes, and have different
  goals making the translation harder.
\end{itemize}

\hypertarget{likelihood-of-change}{%
\section{Likelihood of Change}\label{likelihood-of-change}}

Unless your project \emph{ends}, you can never be completely sure that
Boundary Risk \emph{isn't} going to stop you making a move you want. For
example:

\begin{itemize}
\tightlist
\item
  \texttt{mkdirp} might not work on a new device's Operating System,
  forcing you to swap it out.
\item
  You might discover that the database you chose satisfied all the
  features you needed at the start of the project, but came up short
  when the requirements changed later on.
\item
  The front-end framework you chose might go out-of-fashion, and it
  might be hard to find developers interested in working on the project
  because of it.
\end{itemize}

This third point is perhaps the most interesting aspect of Boundary
Risk: how can we ensure that the decisions we make now are future-proof?
You can't always be sure that a dependency now will always have the same
guarantees in the future:

\begin{itemize}
\tightlist
\item
  \textbf{Ownership changes} Microsoft buys
  \href{https://en.wikipedia.org/wiki/GitHub}{GitHub}. What will happen
  to the ecosystem around GitHub now?
\item
  \textbf{Licensing changes}. (e.g. \href{http://oracle.com}{Oracle}
  buys \textbf{Tangosol} who make
  \href{https://en.wikipedia.org/wiki/Oracle_Coherence}{Coherence} for
  example). Having done this, they increase the licensing costs of
  Tangosol to huge levels, milking the
  \href{https://en.wikipedia.org/wiki/Cash_cow}{Cash Cow} of the
  installed user-base, but ensuring no-one else is likely to use it.
\item
  \textbf{Better alternatives become available}: As a real example of
  this, I began a project in 2016 using
  \href{https://en.wikipedia.org/wiki/Apache_Solr}{Apache Solr}.
  However, in 2018, I would probably use
  \href{https://en.wikipedia.org/wiki/Elasticsearch}{ElasticSearch}. In
  the past, I've built web-sites using Drupal and then later converted
  them to use WordPress.
\end{itemize}

\hypertarget{patterns-in-boundary-risk}{%
\section{Patterns In Boundary Risk}\label{patterns-in-boundary-risk}}

In Feature Risk, we saw that the features people need change over time.
Let's get more specific about this:

\begin{itemize}
\tightlist
\item
  \textbf{Human need is
  \href{https://en.wikipedia.org/wiki/Fractal}{Fractal}:} This means
  that over time, software products have evolved to more closely map to
  human needs. Software that would have delighted us ten years ago lacks
  the sophistication we expect today.
\item
  \textbf{Software and hardware are both improving with time:} due to
  evolution and the ability to support greater and greater levels of
  complexity.
\item
  \textbf{Abstractions accrete too:} As we saw in Process Risk, we
  \emph{encapsulate} earlier abstractions in order to build later ones.
\end{itemize}

The only thing we can expect in the future is that the lifespan of any
ecosystem will follow the arc shown in Figure \ref{cycle.png}, through
creation, adoption, growth, use and finally either be abstracted over or
abandoned.

Although our discipline is a young one, we should probably expect to see
``Software Archaeology'' in the same way as we see it for biological
organisms. Already we can see the dead-ends in the software evolutionary
tree: COBOL and BASIC languages, CASE systems. Languages like FORTH live
on in PostScript, SQL is still embedded in everything

Let's move on now to the last Dependency Risk chapter, and look at
Agency Risk.

\hypertarget{agency-risk}{%
\chapter{Agency Risk}\label{agency-risk}}

Coordinating a team is difficult enough when everyone on the team has a
single Goal. But, people have their own goals, too. Sometimes, their
goals harmlessly co-exist with the team's goal, but other times they
don't.

This is Agency Risk. This term comes from finance and refers to the
situation where you (the ``principal'') entrust your money to someone
(the ``agent'') in order to invest it, but they don't necessarily have
your best interests at heart. They may instead elect to invest the money
in ways that help them, or outright steal it.

\begin{quotation}

``This dilemma exists in circumstances where agents are motivated to act
in their own best interests, which are contrary to those of their
principals, and is an example of moral hazard.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Principalagent_problem}{\textemdash  Principal-Agent Problem, \emph{Wikipedia}}}
\end{quotation}

The less visibility you have of the agent's activities, the bigger the
risk. However, the whole point of giving the money to the agent was that
you would have to spend less time and effort managing it.

\begin{figure}
\centering
\includegraphics{images/generated/risks/agency/agency-risk-400dpi.png}
\caption{Mitigating Agency Risk Through
Monitoring\label{agency-risk.png}}
\end{figure}

Agency Risk clearly includes the behaviour of
\href{https://en.wiktionary.org/wiki/bad_actor}{Bad Actors}. But, that's
too strict a definition: In software development, we're not lending each
other money, but we are being paid by the project sponsor, so they are
assuming Agency Risk by employing us.

As we saw in the previous chapter on Process Risk, Agency Risk doesn't
just apply to people: it can apply to \emph{running software} or
\emph{whole teams} - anything which has agency over it's actions.

\begin{quotation}

``Agency is the capacity of an actor to act in a given
environment\ldots{} Agency may either be classified as unconscious,
involuntary behaviour, or purposeful, goal directed activity
(intentional action).''

\sourceatright{\href{https://en.wikipedia.org/wiki/Agency_(philosophy}{\textemdash  Agency, \emph{Wikipedia}}) }
\end{quotation}

Let's look at some examples of borderline Agency Risk situations, in
order to sketch out where the domain of this risk lies.

\hypertarget{personal-lives}{%
\section{Personal Lives}\label{personal-lives}}

We can't (shouldn't) expect people on a project to sacrifice their
personal lives for the success of the project, right? Except that
\href{https://en.wikipedia.org/wiki/Video_game_developer\#\%22Crunch_time\%22}{``Crunch
Time''} is exactly how some software companies work:

\begin{quotation}

``Game development\ldots{} requires long working hours and dedication
from their employees. Some video game developers (such as Electronic
Arts) have been accused of the excessive invocation of''crunch
time``.''Crunch time" is the point at which the team is thought to be
failing to achieve milestones needed to launch a game on schedule. "

\sourceatright{\href{https://en.wikipedia.org/wiki/Video_game_developer\#"Crunch_time"}{\textemdash  Crunch Time, \emph{Wikipedia}}}
\end{quotation}

People taking time off, going to funerals, looking after sick relatives
and so on are all acceptable forms of Agency Risk. They are the
Attendant Risk of having \emph{staff} rather than \emph{slaves}.

\hypertarget{the-hero}{%
\section{The Hero}\label{the-hero}}

\begin{quotation}

``The one who stays later than the others is a hero.''

\sourceatright{\href{http://wiki.c2.com/?HeroCulture}{\textemdash  Hero Culture, \emph{Ward's Wiki}} <!-- tweet-end -->}
\end{quotation}

Heroes put in more hours and try to rescue projects single-handedly,
often cutting corners like team communication and process in order to
get there.

Sometimes, projects don't get done without heroes. But other times, the
hero has an alternative agenda than just getting the project done:

\begin{itemize}
\tightlist
\item
  A need for control, and for their own vision.
\item
  A preference to work alone.
\item
  A desire for recognition and acclaim from colleagues.
\item
  For the job security of being a
  \href{https://en.wikipedia.org/wiki/Key_person_insurance}{Key Man}.
\end{itemize}

A team \emph{can} make use of heroism, but it's a double-edged sword.
The hero can becomes a bottleneck to work getting done, and because want
to solve all the problems themselves, they under-communicate.

\hypertarget{consultancies}{%
\section{Consultancies}\label{consultancies}}

When you work with an external consultancy, there is \emph{always} more
Agency Risk than with a direct employee. This is because as well as your
goals and the employee's goals, there is also the consultancy's goals.

This is a good argument for avoiding consultancies, but sometimes the
technical expertise they bring can outweigh this risk.

\hypertarget{cv-building}{%
\section{CV Building}\label{cv-building}}

CV Building is when someone decides that the project needs a dose of
``Some Technology X'', but in actual fact, this is either completely
unhelpful to the project (incurring large amounts of Complexity Risk),
or merely a poor alternative to something else.

It's very easy to spot CV building: look for choices of technology that
are incongruently complex compared to the problem they solve, and then
challenge by suggesting a simpler alternative.

\hypertarget{devil-makes-work}{%
\section{Devil Makes Work}\label{devil-makes-work}}

Heroes can be useful, but \emph{underused} project members are a
nightmare. The problem is, people who are not fully occupied begin to
worry that actually, the team would be better off without them, and then
wonder if their jobs are at risk.

Even if they don't worry about their jobs, sometimes they need ways to
stave off \emph{boredom}. The solution to this is ``busy-work'': finding
tasks that, at first sight, look useful, and then delivering them in an
over-elaborate way (Gold Plating)) that'll keep them occupied. This will
leave you with more Complexity Risk than you had in the first place.

\hypertarget{pet-projects}{%
\section{Pet Projects}\label{pet-projects}}

\begin{quotation}

A project, activity or goal pursued as a personal favourite, rather than
because it is generally accepted as necessary or important.

\sourceatright{\href{https://en.wiktionary.org/wiki/pet_project}{\textemdash  Pet Project, \emph{Wiktionary}}}
\end{quotation}

Sometimes, budget-holders have projects they value more than others
without reference to the value placed on them by the business. Perhaps
the project has a goal that aligns closely with the budget holder's
passions, or its related to work they were previously responsible for.

Working on a pet project usually means you get lots of attention (and
more than enough budget), but it can fall apart very quickly under
scrutiny.

\hypertarget{morale-risk}{%
\section{Morale Risk}\label{morale-risk}}

\begin{quotation}

Morale, also known as Esprit de Corps is the capacity of a group's
members to retain belief in an institution or goal, particularly in the
face of opposition or hardship

\sourceatright{\href{https://en.wikipedia.org/wiki/Morale}{\textemdash  Morale, \emph{Wikipedia}} }
\end{quotation}

Sometimes, the morale of the team or individuals within it dips, leading
to lack of motivation. Morale Risk is a kind of Agency Risk because it
really means that a team member or the whole team isn't committed to the
Goal, may decide their efforts are best spent elsewhere. Morale Risk
might be caused by:

\begin{itemize}
\tightlist
\item
  \textbf{External Factors:} Perhaps the employees' dog has died, or
  they're simply tired of the industry, or are not feeling challenged.
\item
  \textbf{The goal feels unachievable:} in this case, people won't
  commit their full effort to it. This might be due to to a difference
  in the evaluation of the risks on the project between the team members
  and the leader. In military science, a second meaning of morale is how
  well supplied and equipped a unit is. This would also seem like a
  useful reference point for IT projects. If teams are under-staffed or
  under-equipped, this will impact on motivation too.
\item
  \textbf{The goal isn't sufficiently worthy}, or the team doesn't feel
  sufficiently valued.
\end{itemize}

\hypertarget{software-processes-and-teams}{%
\section{Software Processes And
Teams}\label{software-processes-and-teams}}

There is significant Agency Risk in running software \emph{at all}.
Since computer systems follow rules we set for them, we shouldn't be
surprised when those rules have exceptions that lead to disaster. For
example:

\begin{itemize}
\tightlist
\item
  A process continually writing log files until the disks fill up,
  crashing the system.
\item
  Bugs causing data to get corrupted, causing financial loss.
\item
  Malware infecting a system, and sending your passwords and data to
  undesirables.
\end{itemize}

Agency Risk applies to \emph{whole teams} too. It's perfectly possible
that a team within an organisation develops Goals that don't align with
those of the overall organisation. For example:

\begin{itemize}
\tightlist
\item
  A team introduces excessive Bureaucracy in order to avoid work it
  doesn't like.
\item
  A team gets obsessed with a particular technology, or their own
  internal process improvement, at the expense of delivering business
  value.
\item
  A marginalised team forces their services on other teams in the name
  of ``consistency''. (This can happen a lot with ``Architecture'',
  ``Branding'' and ``Testing'' teams, sometimes for the better,
  sometimes for the worse.)
\end{itemize}

\hypertarget{security-risk}{%
\section{Security Risk}\label{security-risk}}

As shown in Figure \ref{agency-risk.png}, to mitigate Agency Risk
\emph{within} a system, we can apply monitoring and goal-alignment.
Where the Agency Risk is from an unwanted actors \emph{outside} the
system, we can apply security. That is, ensuring that the environment we
work in is \emph{safe} for the good actors to operate in, by keeping out
the bad actors.

Interestingly, security is handled in very similar ways in all kinds of
systems, whether biological, human or organisational.

\begin{itemize}
\tightlist
\item
  \textbf{Walls}: defences \emph{around} the complex system, to protect
  it's parts from the external environment.
\item
  \textbf{Doors}: ways to get \emph{in} and \emph{out} of the complex
  system, possibly with \emph{locks}.
\item
  \textbf{Guards}: to make sure only the right things go in and out.
  (i.e.~to try and keep out \emph{Bad Actors}).
\item
  \textbf{Police}: to defend from \emph{within} the system, against
  internal Agency Risk.
\item
  \textbf{Subterfuge}: Hiding, camouflage, disguises, pretending to be
  something else.
\end{itemize}

These work various levels in our own bodies: our \emph{cells} have
\emph{cell walls} around them, and \emph{cell membranes} that act as the
guards to allow things in and out. Our \emph{bodies} have \emph{skin} to
keep the world out, and we have \emph{mouths}, \emph{eyes}, \emph{pores}
and so on to allow things in and out. We have an \emph{immune system} to
act as the police.

Our societies work in similar ways: in medieval times, a city would have
walls, guards and doors to keep out intruders. Nowadays, we have customs
control, borders and passports.

We're waking up to the realisation that our software systems need to
work the same way: we have
\href{https://en.wikipedia.org/wiki/Firewall_(computing)}{Firewalls} to
protect our organisations, we lock down \emph{ports} on servers to
ensure there are the minimum number of doors to guard and we
\emph{police} the servers ourselves with monitoring tools and anti-virus
software and we \emph{guard} access using passwords and other
identification approaches.

Both Security Risk and Agency Risk thrive on complexity. The more
complex the systems we create, the more opportunities there are for bad
actors to insert themselves and extract their own value. Security Risk
is also a major determinant of Operational Risk, which we will review in
a couple of chapters time.

\hypertarget{its-about-goals}{%
\section{It's About Goals}\label{its-about-goals}}

We've looked here at some illustrative examples of Agency Risk. But as
we stated at the beginning, Agency Risk at any level comes down to
differences of Goals between the different agents, whether they are
\emph{people}, \emph{teams} or \emph{software}.

So, having looked at agents \emph{individually}, it's time to look more
closely at Goals, and the Attendant Risks when aligning them amongst
multiple agents.

On to Coordination Risk\ldots{}

\hypertarget{coordination-risk}{%
\chapter{Coordination Risk}\label{coordination-risk}}

As in Agency Risk, we are going to use the term \emph{agent}, which
refers to anything with
\href{https://github.com/risk-first/website/wiki/Agency-Risk\#software-processes-and-teams}{agency}
in a system to decide it's own fate. That is, an agent has an Internal
Model, and can take actions based on it. Here, we leave aside Agency
Risk and work on the assumption that the agents \emph{are} working
towards a common Goal, even though in reality it's not always the case,
as we saw in the chapter on Agency Risk.

Coordination Risk is the risk that, a group of people or processes,
maybe with a common Goal In Mind, can fail to coordinate to meet this
goal and end up making things worse. Coordination Risk is embodied in
the phrase ``Too Many Cooks Spoil The Broth'': more people, opinions or
\emph{agents} often make results worse.

In this chapter, we'll first build up a model of Coordination Risk and
what exactly coordination means and why we do it. Then, we'll look at
some classic problems of coordination. Then, we're going to consider
agency at several different levels (because of Scale Invariance) . We'll
look at:

\begin{itemize}
\tightlist
\item
  Team Decision Making,
\item
  Living Organisms,
\item
  Larger Organisations and the staff within them,
\item
  and Software Processes.
\end{itemize}

\ldots{} and we'll consider how Coordination Risk is a problem at each
scale.

But for now, let's crack on and examine where Coordination Risk comes
from.

\hypertarget{a-model-of-coordination-risk}{%
\section{A Model Of Coordination
Risk}\label{a-model-of-coordination-risk}}

Earlier, in Dependency Risk, we looked at various resources (time,
money, people, events etc) and showed how we could depend on them,
taking on risk. Here, however, we're looking at the situation where
there is \emph{competition for those dependencies}, that is, Scarcity
Risk: other parties want to use them in a different way.

\hypertarget{law-of-diminishing-returns}{%
\subsection{Law Of Diminishing
Returns}\label{law-of-diminishing-returns}}

\begin{figure}
\centering
\includegraphics{images/numbers/sharing.png}
\caption{Sharing Resources. 5 units are available, and the X axis shows
A's consumption of the resource. B gets whatever remains. Total benefit
is maximised somewhere in the middle\label{sharing.png}}
\end{figure}

One argument could come from
\href{https://en.wikipedia.org/wiki/Diminishing_returns}{Diminishing
Returns}, which says that the earlier units of a resource (say,
chocolate bars) give you more benefit than later ones.

We can see this in Figure \ref{sharing.png}. Let's say A and B compete
over a resource, of which there are 5 units available. For every extra A
takes, B loses one. The X axis shows A's consumption of the resource, so
the biggest benefit to A is in the consumption of the first unit.

As you can see, by \emph{sharing}, it's possible that the \emph{total
benefit} is greater than it can be for either individual. But sharing
requires coordination. Further, the more competitors involved, the
\emph{worse} a winner-take-all outcome is for total benefit.

Just two things are needed for competition to occur:

\begin{itemize}
\tightlist
\item
  Multiple, Individual agents, trying to achieve Goals.
\item
  Scarce Resources, which the agents want to use as Dependencies.
\end{itemize}

\hypertarget{coordination-via-communication}{%
\subsection{Coordination via
Communication}\label{coordination-via-communication}}

The only way that the agents can move away from competition towards
coordination is via Communication, and this is where their coordination
problems begin.

Coordination Risk commonly occurs where people have different ideas
about how to achieve a goal, and they have different ideas because they
have different Internal Models. As we saw in the chapter on
Communication Risk, we can only hope to synchronise Internal Models if
there are high-bandwidth Channels available for communication.

You might think, therefore, that this is just another type of
Communication Risk problem, and that's often a part of it, but even with
synchronized Internal Models, coordination risk can occur. Imagine the
example of people all trying to madly leave a burning building. They all
have the same information (the building is on fire). If they coordinate,
and leave in an orderly fashion, they might all get out. If they don't,
and there's a scramble for the door, more people might die.

\begin{figure}
\centering
\includegraphics{images/generated/risks/coordination/coordination-risk-400dpi.png}
\caption{Coordination Risk - Mitigated by
Communication\label{coordination-risk.png}}
\end{figure}

\hypertarget{problems-of-coordination}{%
\section{Problems Of Coordination}\label{problems-of-coordination}}

Let's unpack this idea, and review some classic problems of
coordination, none of which can be addressed without good communication.
Here are some examples:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Merging Data:} If you are familiar with the source code
  control system, Git, you will know that this is a \emph{distributed}
  version control system. That means that two or more people can propose
  changes to the same files without knowing about each other. This means
  that at some later time, Git then has to merge (or reconcile) these
  changes together. Git is very good at doing this automatically, but
  sometimes, different people can independently change the same lines of
  code and these will have to be merged manually. In this case, a human
  arbitrator ``resolves'' the difference, either by combining the two
  changes or picking a winner.
\item
  \textbf{Consensus:} Making group decisions (as in elections) is often
  decided by votes. But having a vote is a coordination issue, and
  requires that everyone has been told the rules:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Where will the vote be held?
\item
  How long do you provide for the vote?
\item
  What do you do about absentees?
\item
  What if people change their minds in the light of new information?
\item
  How do you ensure everyone has enough information to make a good
  decision?
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  \textbf{Factions:} Sometimes, it's hard to coordinate large groups at
  the same time, and ``factions'' can occur. That the world isn't a
  single big country is probably partly a testament to this: countries
  are frequently separated by geographic features that prevent the easy
  flow of communication (and force). We can also see this in distributed
  systems, with the ``split brain'') problem. This is where a network of
  processes becomes disconnected (usually due to a network failure
  between data centers), and you end up with two, smaller networks with
  different knowledge. We'll address in more depth later.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Resource_allocation}{Resource
  Allocation}:} Ensuring that the right people are doing the right work,
  or the right resources are given to the right people is a coordination
  issue. On a grand scale, we have Logistics, and
  \href{https://en.wikipedia.org/wiki/Economic_system}{Economic
  Systems}. On a small scale, the office's \emph{room booking system}
  solves the coordination issue of who gets a meeting room using a
  first-come-first-served booking algorithm.
\item
  \textbf{Deadlock:} Deadlock refers to a situation where, in an
  environment where multiple parallel processes are running, the
  processing stops and no-one can make progress because the resources
  each process needs are being reserved by another process. This is a
  specific issue in Resource Allocation, but it's one we're familiar
  with in the computer science industry. Compare with
  \href{https://en.wikipedia.org/wiki/Gridlock}{Gridlock}, where traffic
  can't move because other traffic is occupying the space it wants to
  move to already.
\item
  \textbf{Race Conditions:} A race condition is where we can't be sure
  of the result of a calculation, because it is dependent on the
  ordering of events within a system. For example, two separate threads
  writing the same memory at the same time (one ignoring and
  over-writing the work of the other) is a race.
\item
  \textbf{Contention}: Where there is Scarcity Risk for a dependency, we
  might want to make sure that everyone gets fair use of it, by taking
  turns, booking, queueing and so on. As we saw in Scarcity Risk,
  sometimes, this is handled for us by the Dependency itself. However if
  it isn't, it's the \emph{users} of the dependency who'll need to
  coordinate to use the resource fairly, again, by communicating with
  each other.
\end{enumerate}

\hypertarget{decision-making}{%
\section{Decision Making}\label{decision-making}}

Within a team, Coordination Risk is at it's core about resolving
Internal Model conflicts in order that everyone can agree on a Goal In
Mind and cooperate on getting it done. Therefore, Coordination Risk is
worse on projects with more members, and worse in organizations with
more staff.

As an individual, do you suffer from Coordination Risk at all? Maybe:
sometimes, you can feel ``conflicted'' about the best way to solve a
problem. And weirdly, usually \emph{not thinking about it} helps.
Sleeping too. (Rich Hickey calls this
``\href{https://www.youtube.com/watch?v=f84n5oFoZBc}{Hammock Driven
Development}''). This is probably because, unbeknownst to you, your
subconscious is furiously communicating internally, trying to resolve
these conflicts itself, and will let you know when it's come to a
resolution.

\begin{figure}
\centering
\includegraphics{images/generated/risks/coordination/vroom-yetton-400dpi.png}
\caption{Vroom And Yetton Decision Making Styles. ``d'' indicates
authority in making a decision, circles are subordinates. Thin lines
with arrow-heads show information flow, whilst thick lines show
\emph{opinions} being passed around.\label{vroom-yetton.png}}
\end{figure}

\href{https://en.wikipedia.org/wiki/Vroom-Yetton_decision_model}{Vroom
and Yetton} introduced a model of group decision making which delineated
five different styles of decision making within a team. These are
summarised in the table below (\textbf{AI, AII, CI, CII, GII}). To this,
I have added a sixth (\textbf{UI}), which is the \emph{uncoordinated}
option, where everyone competes. Figure \ref{vroom-yetton.png}
illustrates these, with the following conventions:

\begin{itemize}
\tightlist
\item
  Thin lines with arrow-heads show a flow of \emph{information}, either
  one-way or two-way.
\item
  Thick lines show a flow of \emph{opinion}.
\item
  Boxes with corners are \emph{decision makers}, whereas curved corners
  don't have a part in the decision.
\end{itemize}

\begin{sidewaystable} 

\begin{longtable}[]{@{}llllll@{}}
\toprule
\begin{minipage}[b]{0.06\columnwidth}\raggedright
Type\strut
\end{minipage} & \begin{minipage}[b]{0.27\columnwidth}\raggedright
Description\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
Decision Makers\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedright
Opinions\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedright
Channels\strut
\end{minipage} & \begin{minipage}[b]{0.27\columnwidth}\raggedright
Coordination Risk\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.06\columnwidth}\raggedright
\textbf{UI}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Uncoordinated\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
0\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Competition\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.06\columnwidth}\raggedright
\textbf{AI}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Autocratic\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Maximum Coordination Risk\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.06\columnwidth}\raggedright
\textbf{AII}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Autocratic (with upward information flow)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.06\columnwidth}\raggedright
\textbf{CI}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Consultative (Individual)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
2\textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.06\columnwidth}\raggedright
\textbf{CII}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Consultative (Group)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
\(\mathbf{s}^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.06\columnwidth}\raggedright
\textbf{GII}\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Group Consultation and Voting\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
1 + \textbf{s}\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
\(\mathbf{s}^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
Maximum Communication Risk, Schedule Risk\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\textbf{s} = subordinate

\end{sidewaystable} 

At the top, you have the \emph{least} consultative styles, and at the
bottom, the \emph{most}. At the top, decisions are made with just the
leader's Internal Model but moving down, the Internal Models of the
\emph{subordinates} are increasingly brought into play.

The decisions at the top are faster, but don't do much for mitigating
\textbf{Coordination Risk}. The ones below take longer, (incurring
Schedule Risk) but mitigate more \textbf{Coordination Risk}. Group
decision-making inevitably involves everyone \emph{learning}, and
improving their Internal Models.

The trick is to be able to tell which approach is suitable at which
time. Everyone is expected to make decisions \emph{within their realm of
expertise}: you can't have developers continually calling meetings to
discuss whether they should be using an
\href{https://en.wikipedia.org/wiki/Abstract_factory_pattern}{Abstract
Factory} or a
\href{https://en.wikipedia.org/wiki/Factory_method_pattern}{Factory
Method}, this would waste time. The critical question is therefore,
``what's the biggest risk?''

\begin{itemize}
\tightlist
\item
  Is the Coordination Risk greater? Are we going to suffer Dead End Risk
  if the decision is made wrongly? What if people don't agree with it?
  Poor leadership has an impact on Morale too.
\item
  Is the Schedule Risk greater? If you have a 1-hour meeting with eight
  people to decide a decision, that's \emph{one man day} gone right
  there: group decision making is \emph{expensive}.
\end{itemize}

Hopefully, this model shows how \emph{organisation} can reduce
Coordination Risk. But, to make this work, we need more
\emph{communication}, and this has attendant complexity and time costs.
So, we can draw diagram above of our move on the Risk Landscape:

\hypertarget{staff-as-agents}{%
\subsection{Staff As Agents}\label{staff-as-agents}}

Staff in a team have a dual nature: they are \textbf{Agents} and
\textbf{Resources} at the same time. The team depends on staff for their
resource of \emph{labour}, but they're also part of the decision making
process of the team, because they have \emph{agency} over their own
actions.

Part of Coordination Risk is about trying to mitigate differences in
Internal Models. So it's worth considering how varied people's models
can be:

\begin{itemize}
\tightlist
\item
  Different skill levels
\item
  Different experiences
\item
  Expertise in different areas
\item
  Preferences
\item
  Personalities
\end{itemize}

The job of harmonising this on a project would seem to fall to the team
leader, but actually people are self-organising to some extent. This
process is called
\href{https://en.wikipedia.org/wiki/Tuckmans_stages_of_group_development}{Team
Development}:

\begin{quotation}

``The forming--storming--norming--performing model of group development
was first proposed by Bruce Tuckman in 1965, who said that these phases
are all necessary and inevitable in order for the team to grow, face up
to challenges, tackle problems, find solutions, plan work, and deliver
results.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Tuckmans_stages_of_group_development}{\textemdash  Tuckman's Stages Of Group Development, \emph{Wikipedia}}}
\end{quotation}

Specifically, this describes a process whereby a new group will form and
then be required to work together. In the process, they will have many
\emph{disputes}. Ideally, the group will resolve these disputes
internally and emerge as a team, with a common Goal In Mind.

They can be encouraged with orthogonal practices such as
\href{https://en.wikipedia.org/wiki/Team_building}{team-building
exercises} (generally, submitting everyone to extreme experiences in
order to bond them together). With enough communication bandwidth and
detente, a motivated team will self-organise code reviews, information
exchange and improve their practices.

As described above, the job of Coordination is Resource Allocation, and
so the skills of staff can potentially be looked at as resources to
allocate. This means handling Coordination Risk issues like:

\begin{itemize}
\tightlist
\item
  People leaving, taking their Internal Models and expertise with them
  Key Man Risk.
\item
  People requiring external training, to understand new tools and
  techniques Learning-Curve Risk.
\item
  People being protective about their knowledge in order to protect
  their jobs Agency Risk.
\item
  Where there are mixed ability levels, senior developers not helping
  juniors as it ``slows them down''.
\item
  People not getting on and not helping each other.
\end{itemize}

\begin{quotation}

``As a rough rule, three programmers organised into a team can do only
twice the work of a single programmer of the same ability - because of
time spent on coordination problems.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Gerald_Weinberg}{\textemdash  Gerald Wienberg, \emph{The Psychology of Computer Programming}} }
\end{quotation}

\hypertarget{in-living-organisms}{%
\section{In Living Organisms}\label{in-living-organisms}}

Vroom and Yetton's organisational style isn't relevant to just teams of
people. We can see it in the natural world too. Although \emph{the
majority} of cellular life on earth (by weight) is
\href{http://www.stephenjaygould.org/library/gould_bacteria.html}{single
celled organisms}, the existence of \emph{humans} (to pick a single
example) demonstrates that sometimes it's better to try to mitigate
Coordination Risk and work as a team, accepting the Complexity Risk and
Communication Risk this entails. As soon as cells start working
together, they either need to pass \emph{resources} between them, or
\emph{control} and \emph{feedback}.

For example, in the human body, we have:

\begin{itemize}
\tightlist
\item
  \textbf{Various
  \href{https://en.wikipedia.org/wiki/List_of_systems_of_the_human_body}{systems}:}
  such as the
  \href{https://en.wikipedia.org/wiki/Respiratory_system}{Respiratory
  System} or the
  \href{https://en.wikipedia.org/wiki/Human_digestive_system}{Digestive
  System}. Each of these systems contains\ldots{}
\item
  \textbf{Organs}, such as the heart or lungs, which contain..
\item
  \textbf{Tissues}, which contain\ldots{}
\item
  \textbf{Cells} of different types. (Even cells are complex systems
  containing multiple different, communicating sub-systems.)
\end{itemize}

There is huge attendant Communication Risk to running the human body,
but, given the success of humanity as a species, you must conclude that
these steps on the \emph{evolutionary} Risk Landscape have benefited us
in our ecological niche.

\hypertarget{decision-making-1}{%
\subsection{Decision Making}\label{decision-making-1}}

The key observation from looking at biology is this: most of the cells
in the human body \emph{don't get a vote}. Muscles in the motor system
have an \textbf{AI} or \textbf{AII} relationship with the brain - they
do what they are told, but there are often nerves to report pain back.
The only place where \textbf{CII} or \textbf{GII} \emph{could} occur is
in our brains, when we try to make a decision and weigh up the pros and
cons.

This means that there is a deal: \emph{most} of the cells in our body
accede control of their destiny to ``the system''. Living within the
system of the human body is a better option than going it alone as a
single-celled organism. Occasionally, due to mutation, we can end up
with \href{https://en.wikipedia.org/wiki/Cancer}{Cancer}, which is where
one cell genetically ``forgets'' its purpose in the whole system and
goes back to selfish individual self-replication (\textbf{UI}). We have
\href{https://en.wikipedia.org/wiki/White_blood_cell}{White Blood Cells}
in the body to shut down this kind of behaviour and try to kill the
rogue cells. In the same way, societies have police forces to stop
undesirable behaviour amongst their citizens.

\hypertarget{large-organisations}{%
\section{Large Organisations}\label{large-organisations}}

Working in a large organisation often feels like being a cell in a
larger organism. Cells live and die and the organism goes on. Workers
come and go from a large company but the organisation goes on. By
working in an organisation, we give up self-control and competition and
accept \textbf{AI} and \textbf{AII} power structures above us, but we
trust that there is symbiotic value creation on both sides of the
employment deal.

\emph{Less} consultative decision making styles are more appropriate
then when we don't have the luxury of high-bandwidth channels for
discussion. When the number of parties rises above a room-full of people
it's not possible to hear everyone's voice. As you can see from the
table above, for \textbf{CII} and \textbf{GII} decision-making styles,
the amount of communication increases non-linearly with the number of
participants, so we need something simpler.

As we saw in the Complexity Risk chapter, hierarchies are an excellent
way of economising on number of different communication channels, and we
use these frequently when there are lots of parties to coordinate.

In large organisations, teams are created and leaders chosen for those
teams precisely to mitigate this Communication Risk. We're all familiar
with this: control of the team is ceded to the leader, who takes on the
role of `handing down' direction from above, but also `reporting up'
issues that cannot be resolved within the team. In Vroom and Yetton's
model, this is moving from a \textbf{GII} or \textbf{CII} to an
\textbf{AI} or \textbf{AII} style of leadership.

Clearly, this is just a \emph{model}, it's not set in stone and decision
making styles usually change from day-to-day and decision to decision.
The same is not true in our software - \emph{rules are rules}.

\hypertarget{in-software-processes}{%
\section{In Software Processes}\label{in-software-processes}}

It should be pretty clear that we are applying our Scale Invariance rule
to Coordination Risk: all of the problems we've described as affecting
teams and organisations also affect software, although the scale and
terrain are different. Software processes have limited \emph{agency} -
in most cases they follow fixed rules set down by the programmers,
rather than self-organising like people can (so far).

As before, in order to face Coordination Risk in software, we need
multiple agents all working together. Coordination Risks (such as race
conditions or deadlock) only really occur where \emph{more than one
agent working at the same time}. This means we are considering \emph{at
least} multi-threaded software, and anything above that (multiple CPUs,
servers, data-centres and so on).

\hypertarget{cap-theorem}{%
\subsection{CAP Theorem}\label{cap-theorem}}

Imagine talking to a distributed database, where your request
(\emph{read} or \emph{write}) can be handled by one of many agents.

\begin{figure}
\centering
\includegraphics{images/generated/risks/coordination/cap1-400dpi.png}
\caption{User A and User B are both using a distributed database,
managed by Agents 1 and 2, whom each have their own Internal
Model\label{cap1.png}}
\end{figure}

In Figure \ref{cap1.png}, we have just two agents \texttt{1} and
\texttt{2}, in order to keep things simple. \texttt{User\ A}
\emph{writes something} to the database, then \texttt{User\ B}
\emph{reads it back} afterwards.

According to the \href{https://en.wikipedia.org/wiki/CAP_theorem}{CAP
Theorem}, there are three properties we could desire in such a system:

\begin{itemize}
\tightlist
\item
  \textbf{Consistency (C)}: Every read receives the most recent value
  from the last write.
\item
  \textbf{Availability (A)}: Every request receives a response.
\item
  \textbf{Partition tolerance (P)}: The system can operate despite the
  isolation (lack of communication with) some of it's agents.
\end{itemize}

The CAP Theorem states that this is a
\href{https://en.wikipedia.org/wiki/Trilemma}{Trilemma}. That is, you
can only have two out of the three properties.

There are plenty of resources on the Internet that discuss this in
depth, but let's just illustrate with some diagrams to show how this
plays out. In Figure \ref{cap1.png}, we can see a 2-agent distributed
database. Either agent can receive a read or write. So this might be a
\textbf{GII} decision making system, because all the agents are going to
need to coordinate to figure out what the right value is to return for a
read, and what the last value written was.

In Figure \ref{cap1.png}, you can already see that there is a \emph{race
condition}: if A and B both make their requests at the same time, what
will B get back? The original value of X, or the new value?

\hypertarget{with-an-ap-system}{%
\subsubsection{With an AP System}\label{with-an-ap-system}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/coordination/cap-ap-400dpi.png}
\caption{In an AP system, the User B may get back a \emph{stale value}
for X\label{cap-ap.png}}
\end{figure}

Here, we are going to consider what happens when communication breaks
down between Agents 1 and 2. That is, they are \emph{isolated} from
communicating with each other. As shown in Figure \ref{cap-ap.png}, in
an \texttt{AP} system, we have a database that is able to survive
partitioning, and always returns a response, but may not be consistent.
The value \texttt{B} will get back will depend on whether they talk with
Agent 1 or Agent 2.

\hypertarget{with-an-cp-system}{%
\subsubsection{With an CP System}\label{with-an-cp-system}}

\includegraphics{images/generated/risks/coordination/cap-cp-400dpi.png}
.

To be consistent, Agent 2 needs to check with Agent 1 to make sure it
has the latest value for X. Where Agent 2 is left waiting for Agent 1 to
re-appear, we are \emph{blocked}. So CP systems will block when
partitioned.

\hypertarget{with-an-ca-system}{%
\subsubsection{With an CA System}\label{with-an-ca-system}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/coordination/cap-ca-400dpi.png}
\caption{In an CA system, we can't have partition tolerance, so in order
to be consistent a single Agent has to do all the
work\label{cap-ca.png}}
\end{figure}

Finally, if we have a CA system, we are essentially saying that
\emph{only one agent is doing the work}. (You can't partition a single
agent, after all). But this leads to Resource Allocation and
\textbf{Contention} around use of the scarce resource of
\texttt{Agent\ 2}'s attention. (Both Coordination Risk issues we met
earlier.)

\hypertarget{some-real-life-examples}{%
\subsection{Some Real-Life Examples}\label{some-real-life-examples}}

This sets an upper bound on Coordination Risk: we \emph{can't} get rid
of it completely in a software system, -or- a system on any other scale.
Fundamentally, coordination problems are inescapable at some level. The
best we can do is mitigate it by agreeing on protocols and doing lots of
communication.

Let's look at some real-life examples of how this manifests in software.

\hypertarget{zookeeper}{%
\subsubsection{ZooKeeper}\label{zookeeper}}

First, \href{https://zookeeper.apache.org}{ZooKeeper} is an Open-Source
datastore, which is used in building distributed systems (like the one
above) and ensuring things like configuration information are consistent
across all agents.

This \emph{seems} trivial, but it quickly gets out-of-hand: what happens
if only some of the agents receive the new information? What happens if
a datacentre gets disconnected while the update is happening? There are
lots of edge-cases.

ZooKeeper handles this by communicating inter-agent with it's own
protocol. It elects a \textbf{master agent} (via \textbf{GII}-style
voting), turning it into an \textbf{AI}-style team. If the master is
lost for some reason, a new leader is elected. \emph{Writes} are then
coordinated via the \textbf{master agent} who makes sure that a
\emph{majority of agents} have received and stored the configuration
change before telling the user that the transaction is complete.
Therefore, ZooKeeper is a \texttt{CP} system.

\hypertarget{git}{%
\subsubsection{Git}\label{git}}

Second, git is a (mainly) write-only ledger of source changes. However,
as we already discussed above, where different agents make incompatible
changes, someone has to decide how to resolve the conflicts so that we
have a single source of truth.

The Coordination Risk just \emph{doesn't go away}.

Since multiple users can make all the changes they like locally, and
merge them later, Git is an \texttt{AP} system where everyone's opinion
counts (\textbf{GII}): individual users may have \emph{wildly} different
ideas about what the source looks like until the merge is complete.

\hypertarget{bitcoin}{%
\subsubsection{Bitcoin}\label{bitcoin}}

Finally, \href{https://en.wikipedia.org/wiki/Bitcoin}{Bitcoin (BTC)} is
a write-only
\href{https://en.wikipedia.org/wiki/Distributed_ledger}{distributed
ledger}, where agents \emph{compete} to mine BTC (a \textbf{UI} style
organisation), but also at the same time record transactions on the
ledger. BTC is also \texttt{AP}, in a similar way to Git. But new
changes can only be appended if you have the latest version of the
ledger. If you append to an out-of-date ledger, your work will be lost.

Because it's based on outright competition, if someone beats you to
completing a mining task, then your work is wasted. So, there is
\emph{huge} Coordination Risk.

For this reason, BTC agents coordinate into
\href{https://en.bitcoin.it/wiki/Comparison_of_mining_pools}{mining
consortia}, so they can avoid working on the same tasks at the same
time, turning it into a \textbf{CI}-type organisation.

This in itself is a problem, because the whole \emph{point} of BTC is
that it's competitive, and no one entity has control. So, mining pools
tend to stop growing before they reach 50\% of the BTC network's
processing power. Taking control would be
\href{https://www.reddit.com/r/Bitcoin/comments/5fe9vz/in_the_last_24hrs_three_mining_pools_have_control/}{politically
disastrous} and confidence in the currency (such as there is) would
likely be lost.

\hypertarget{communication-is-for-coordination}{%
\section{Communication Is For
Coordination}\label{communication-is-for-coordination}}

CAP theory gives us a fundamental limit on how much Coordination Risk we
can mitigate. We've looked at different organisational structures used
to manage Coordination Risk within teams of people, organisations or
living organisms, so it's the case in software.

At the start of this chapter, we questioned whether Coordination Risk
was just another type of Communication Risk. However, it should be clear
after looking at the examples of competition, cellular life and Vroom
and Yetton's Model that this is exactly \emph{backwards}:

\begin{itemize}
\tightlist
\item
  Most single-celled life has no need for communication: it simply
  competes for the available resources. If it lacks anything it needs,
  it dies.
\item
  There are \emph{no} lines of communication on the \textbf{UI}
  decision-type. It's only when we want to avoid competition, by sharing
  resources and working towards common goals that we need to
  communicate.
\item
  Therefore, the whole point of communication \emph{is for
  coordination}.
\end{itemize}

In the next chapter, Map And Territory Risk, we're going to look at some
new ways in which systems can fail, despite their attempts to
coordinate.

\hypertarget{map-and-territory-risk}{%
\chapter{Map And Territory Risk}\label{map-and-territory-risk}}

As we discussed in the Communication Risk chapter, our understanding of
the world is informed by the names we give things and the abstractions
we create.

In the same way, Risk-First is about naming risks within software
development and calling them out.

Our Internal Models of the world based on these abstractions, and their
relationships.

So there is a translation going on here: observations about the
arrangement of \emph{atoms} in the world get turned into patterns of
\emph{information} (measured in bits and bytes).

\begin{figure}
\centering
\includegraphics{images/generated/risks/map-and-territory/communication-400dpi.png}
\caption{Maps and Territories, and Communication happening between
them\label{communication.png}}
\end{figure}

Like Trust \& Belief Risk and Learning-Curve Risk, Map And Territory
Risk is an Internal Model Risk, and is the risk we face because we base
our behaviour on our Internal Models rather than reality itself. It
comes from the expression ``Confusing the Map for the Territory'',
attributed to Alfred Korzybski:

\begin{quotation}

``Polish-American scientist and philosopher Alfred Korzybski remarked
that''the map is not the territory" and that ``the word is not the
thing'', encapsulating his view that an abstraction derived from
something, or a reaction to it, is not the thing itself. Korzybski held
that many people \emph{do} confuse maps with territories, that is,
confuse models of reality with reality itself."

\sourceatright{\href{https://en.wikipedia.org/wiki/Mapterritory_relation}{\textemdash  Map-Territory Relation, \emph{Wikipedia}}}
\end{quotation}

In this chapter, we're going to make a case for analysing Map and
Territory Risk along the same axes we introduced for Feature Risk, that
is \textbf{Fitness}, \textbf{Audience} and \textbf{Evolution}. After
that, we are going to widen the scope by looking at Map and Territory
Risk within the context of \textbf{machines}, \textbf{people},
\textbf{hierarchies} and \textbf{markets}.

\hypertarget{fitness}{%
\section{Fitness}\label{fitness}}

\begin{figure}
\centering
\includegraphics{images/sat_nav.png}
\caption{Sat Nav Blunder Sends Asda Van Crashing Narrow Footpath -
Telegraph Newspaper\label{sat_nav.png}}
\end{figure}

In the headline above, taken from
\href{https://www.telegraph.co.uk/news/newstopics/howaboutthat/6413887/Asda-van-crashes-after-sat-nav-sends-driver-to-narrow-footpath.html}{the
Telegraph newspaper}, the driver \emph{trusted} the SatNav to such an
extent that he didn't pay attention to the road-signs around him, and
ended up getting stuck.

This wasn't borne of stupidity, but experience: SatNavs are pretty
reliable. \emph{So many times} the SatNav had been right, that the
driver stopped \emph{questioning its fallibility}.

So, there are two Map and Territory Risks here:

\begin{itemize}
\tightlist
\item
  The Internal Model of the \emph{SatNav} contained information that was
  wrong: the track had been marked up as a road, rather than a path.
\item
  The Internal Model of the \emph{driver} was wrong: his abstraction of
  ``the SatNav is always right'' turned out to be only \emph{mostly}
  accurate.
\end{itemize}

We've already looked in detail at the Dependency Risks involved in
relying on something like a SatNav, in the Software Dependency Risk
chapter. But here, we are really looking at the \emph{Internal Models
themselves} as a source of Dependency Risk too.

You could argue that the SatNav and the Driver's Internal Model had bugs
in them. That is, they both suffer the Feature Implementation Risk we
saw in the Feature Risk chapter. If a SatNav has too much of this, you'd
end up not trusting it, and getting a new one. With your \emph{personal}
Internal Model, you can't buy a new one, but you may learn to
\emph{trust your assumptions less}.

In the Feature Risk chapter, we broke down Feature Risk on three axes:
\textbf{Fitness}, \textbf{Evolution} and \textbf{Audience}.

\begin{figure}
\centering
\includegraphics{images/generated/risks/map-and-territory/map_and_territory_table_1-400dpi.png}
\caption{Feature Risk, as manifested in the Internal
Model\label{map_and_territory_table_1.png}}
\end{figure}

Figure \ref{map_and_territory_table_1.png} does this again, showing how
type of Feature Fit Risk can manifest in the Internal Model.

\hypertarget{audience}{%
\section{Audience}\label{audience}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/map-and-territory/map_and_territory_table_2-400dpi.png}
\caption{Audience Feature Risks, as manifested in the Internal
Model\label{map_and_territory_table_2.png}}
\end{figure}

We already know a lot about Internal Models and Audience, as these have
been the subject of previous chapters:

\begin{itemize}
\tightlist
\item
  We know from looking at Communication Risk that communication allows
  us to \emph{share} information between Internal Models.
\item
  We know from Coordination Risk the difficulties inherent in aligning
  Internal Models so that they cooperate.
\item
  Job markets show us that there is demand for people with certain
  \emph{skills}. This demonstrates to us that Market Risk is as
  applicable to Internal Models containing certain information as it is
  to products containing Features. This was the focus of the Ecosystem
  discussion in Boundary Risk.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/google-trends.png}
\caption{Relative popularity of ``Machine Learning'' and ``Big Data'' as
search terms on \href{https://trends.google.com}{Google Trends},
2011-2018}
\end{figure}

Therefore, we should be able to track the rise-and-fall of \emph{ideas}
much as we can track stock prices. And in effect, this is what Google
Trends does. In Figure \ref{map_and_territory_table_2.png}, we can see
the relative popularity of two search terms over time. This is probably
as good an indicator as any of the audience for an abstraction at any
point in time.

\hypertarget{example-hype-cycles}{%
\subsection{Example: Hype Cycles}\label{example-hype-cycles}}

Most ideas (and most products) have a slow, hard climb to wide-scale
adoption. But some ideas seem to disperse much more rapidly and are
picked up quickly because they are exciting and promising, having
greater ``memetic potential'' within society. One way this evolution
manifests itself in the world is though the
\href{https://en.wikipedia.org/wiki/Hype_cycle}{Hype Cycle}:

\begin{quotation}

``The hype cycle is a branded graphical presentation developed and used
by the American research, advisory and information technology firm
Gartner, for representing the maturity, adoption and social application
of specific technologies. The hype cycle provides a graphical and
conceptual presentation of the maturity of emerging technologies through
five phases.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Hype_cycle}{\textemdash  Hype Cycle, \emph{Wikipedia}}}
\end{quotation}

\begin{figure}
\centering
\includegraphics{images/numbers/hype1.png}
\caption{Hype Cycle, along with Map \& Territory Risk\label{hype1.png}}
\end{figure}

The five phases (and the ``Hype'' itself as the thick black line) are
shown in Figure \ref{hype1.png}. We start off at the ``Technology
Trigger'', moving to the ``Peak of Inflated Expectations'', then to the
``Trough of Disillusionment'' and finally to the ``Plateau of
Productivity''.

The concept of Map and Territory Risk actually helps explain why this
curve has the shape it does. Figure \ref{hype1.png} also shows where the
hype originates:

\begin{itemize}
\tightlist
\item
  The \textbf{awareness} of the idea within the audience as a dotted
  line.
\item
  The \textbf{knowledge} of the idea by the audience (a Learning Curve,
  if you will) as a dashed line.
\end{itemize}

Both of these are modelled with
\href{https://en.wikipedia.org/wiki/Cumulative_distribution_function\#Use_in_statistical_analysis}{Cumulative
Distribution} curves, which are often used for modelling the spread of a
phenomena (disease, product uptake, idea) within a population. From
these two things, we can figure out where our maximum Map and Territory
Risk lies: it's the point where awareness of an idea is farthest from
the understanding of it.

This Map and Territory Risk acts as a ``brake'' on the \textbf{hype}
around the idea. In the diagram, our ``hype'' curve is calculated as
being the same as the ``saturation'' line, with a subtraction due to Map
and Territory Risk. As you can see, ``hype'' drops fastest at the point
where Map and Territory Risk is at it's greatest, and we end up in the
``Trough of Disillusionment''.

\begin{figure}
\centering
\includegraphics{images/numbers/hype2.png}
\caption{Hype Cycle 2: More even growth of means no ``Trough of
Disillusionment''\label{hype2.png}}
\end{figure}

As you might expect, the ``Trough of Disillusionment'' exists because
the ``saturation'' of the idea and the ``amount known'' about it
increase at different rates.

Where the \textbf{saturation} and \textbf{knowledge} grow more evenly
together, there is no spike in Map and Territory Risk and we don't see
the corresponding ``Trough of Disillusionment'' at all, as shown in the
above chart.

\hypertarget{evolution}{%
\section{Evolution}\label{evolution}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/communication/communication_marketing-400dpi.png}
\caption{Spread of information between Internal
Models\label{communication_marketing.png}}
\end{figure}

The chapter on Communication Risk introduced Figure
\ref{communication_marketing.png} for the spread of ideas. But what
happens next? As we saw in Boundary Risk, the \textbf{Peter Principle}
applies, people will use dependencies up to the point when they start
breaking down.

\hypertarget{example-metrics}{%
\subsection{Example: Metrics}\label{example-metrics}}

Let's dive into a specific example now: someone finds a useful new
metric that helps in evaluating performance.

It might be:

\begin{itemize}
\tightlist
\item
  \textbf{Source Lines Of Code (SLOC)}: i.e.~the number of lines of code
  each developer writes per day/week whatever.
\item
  \textbf{Function Points}: the number of function points a person on
  the team completes, each sprint.
\item
  \textbf{Code Coverage}: the number of lines of code exercised by unit
  tests.
\item
  \textbf{Response Time}: the time it takes to respond to an emergency
  call, say, or to go from a feature request to production.
\item
  \textbf{Release cadence}: number of releases a team performs, per
  month, say.
\end{itemize}

With some skill, they may be able to \emph{correlate} this metric
against some other more abstract measure of success. For example:

\begin{itemize}
\tightlist
\item
  ``quality is correlated with more releases''
\item
  ``user-satisfaction is correlated with SLOC''
\item
  ``revenue is correlated with response time''
\end{itemize}

Because the \emph{thing on the right} is easier to measure than
\emph{the thing on the left}, it becomes used as a proxy (or, Map) for
the thing they are really interested in (the Territory). At this point,
it's \emph{easy} to communicate this idea with the rest of the team, and
\emph{the market value of the idea is high}: it is a useful
representation of reality, which is shown to be accurate at a particular
point in time.

But \emph{correlation} doesn't imply \emph{causation}. The \emph{cause}
might be different:

\begin{itemize}
\tightlist
\item
  Quality and number of releases might both be down to the simplicity of
  the product.
\item
  User satisfaction and SLOC might both be down to the calibre of the
  developers.
\item
  Response time and revenue might both be down to clever team planning.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/risks/map-and-territory/map_and_territory_table_3-400dpi.png}
\caption{Evolution Feature Risks, as manifested in the Internal
Model\label{map_and_territory_table_3.png}}
\end{figure}

Metrics are seductive because they simplify reality and are easily
communicated. But they \emph{inherently} contain Map and Territory Risk:
By relying \emph{only} on the metrics, you're not really \emph{seeing}
the reality.

The devil is in the detail.

\hypertarget{reality-evolves}{%
\subsection{Reality Evolves}\label{reality-evolves}}

In the same way that markets evolve to demand more features, our
behaviour evolves to incorporate new ideas. The more popular an idea is,
the more people will modify their behaviour as a result of it, and the
more the world will change.

In the case of metrics, this is where they start being used for more
than just indicators, but as measures of performance or targets:

\begin{itemize}
\tightlist
\item
  If a team is \emph{told} to do lots of releases, they will perform
  lots of releases \emph{at the expense of something else}.
\item
  If team members are promoted according to SLOC, they will make sure
  their code takes up as many lines as possible.
\item
  In the UK, ambulances were asked to wait before admitting patients to
  Emergency wards, in order that hospitals could
  \href{https://en.wikipedia.org/wiki/NHS_targets}{meet their targets}.
\end{itemize}

\begin{quotation}

``Any observed statistical regularity will tend to collapse once
pressure is placed upon it for control purposes.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Goodharts_law}{\textemdash  Goodhart's Law, \emph{Wikipedia}}}
\end{quotation}

Some of this seems obvious: \emph{Of course} SLOC is a terrible measure
performance! We're not that stupid anymore. The problem is, it's not so
much the \emph{choice} of metric, but the fact that \emph{all} metrics
merely approximate reality with a few numbers. The map is \emph{always}
simpler than the territory, therefore there can be no perfect metrics.

Will the idea still be useful as the world adapts? Although the Hype
Cycle model doesn't cover it, ideas and products all eventually have
their day and decline in usefulness.

\hypertarget{bad-ideas}{%
\subsection{Bad Ideas}\label{bad-ideas}}

There are plenty of ideas which \emph{seem a really good idea at the
time} but then end up being terrible. It's only as we \emph{improve our
internal model} and realize the hidden risks that we stop using them.
While SLOC is a minor offender,
\href{https://en.wikipedia.org/wiki/Chlorofluorocarbon}{CFCs} or
\href{https://en.wikipedia.org/wiki/Tetraethyllead}{Leaded Petrol} are
more significant examples.

\begin{figure}
\centering
\includegraphics{images/numbers/hype3.png}
\caption{Hype Cycle for something that turns out to be a \emph{bad}
idea\label{hype3.png}}
\end{figure}

The above chart shows an initially promising idea that turns out to be
terrible, and there is a ``Period of Inoculation'' where the population
realise their mistake. There is ``negative hype'' as they work to phase
out the offending idea.

SLOC is not on it's own a \emph{bad idea}, but using it as a metric for
developer productivity \emph{is}:

\begin{quotation}

``Measuring programming progress by lines of code is like measuring
aircraft building progress by weight.''

\sourceatright{\href{https://www.goodreads.com/quotes/536587}{Bill Gates}}
\end{quotation}

\hypertarget{humans-and-machines}{%
\section{Humans and Machines}\label{humans-and-machines}}

In the example of the SatNav, we saw how the \emph{quality} of Map and
Territory Risk is different for \emph{people} and \emph{machines}.
Whereas people \emph{should} be expected show skepticism to new
(unlikely) information, our databases accept it unquestioningly.
\emph{Forgetting} is an everyday, usually benign part of our human
Internal Model, but for software systems it is a production crisis
involving 3am calls and backups.

For Humans, Map and Territory Risk is exacerbated by
\href{https://en.wikipedia.org/wiki/List_of_cognitive_biases}{cognitive
biases}:

\begin{quotation}

``Cognitive biases are systematic patterns of deviation from norm or
rationality in judgement, and are often studied in psychology and
behavioural economics.''

\sourceatright{\href{https://en.wikipedia.org/wiki/List_of_cognitive_biases}{\textemdash  Cognitive Bias, \emph{Wikipedia}}}
\end{quotation}

There are \emph{lots} of cognitive biases. But let's just look at a
couple that are relevant to Map and Territory Risk:

\begin{itemize}
\tightlist
\item
  \textbf{Availability Heuristic}: People overestimate the importance of
  knowledge they have been exposed to.
\item
  \textbf{The Ostrich Effect}: Which is where dangerous information is
  ignored or avoided because of the emotions it will evoke.
\item
  \textbf{Bandwagon Effect}: People like to believe things that other
  people believe. (Could this be a factor in the existence of the Hype
  Cycle?)
\end{itemize}

\hypertarget{hierarchical-organisations}{%
\section{Hierarchical Organisations}\label{hierarchical-organisations}}

Map And Territory Risk ``trickles down'' through an organisation. The
higher levels have an out-sized ability to pervert the incentives at
lower levels because once an organisation begins to pursue a ``bullshit
objective'', the whole company can align to this.

\href{https://www.huffingtonpost.com/otto-scharmer/the-fish-rots-from-the-he_b_8208652.html}{The
Huffington Post} paints a brilliant picture of how Volkswagen managed to
get caught faking their emissions tests. As they point out:

\begin{quotation}

``The leadership culture of VW probably amplified the problem by
disconnecting itself from the values and trajectory of society, by
entrenching in what another executive in the auto industry once called a
``bullshit-castle''\ldots{} No engineer wakes up in the morning and
thinks: OK, today I want to build devices that deceive our customers and
destroy our planet. Yet it happened. Why? Because of hubris at the
top.''

\sourceatright{\href{https://www.huffingtonpost.com/otto-scharmer/the-fish-rots-from-the-he_b_8208652.html}{\textemdash  Otto Scharmer, \emph{Huffington Post}}.}
\end{quotation}

This article identifies the following process:

\begin{itemize}
\tightlist
\item
  \textbf{De-sensing}: VW Executives ignored \emph{The Territory}
  society around them (such as the green movement), ensuring their maps
  were out of date. The top-down culture made it hard for reality to
  propagate back up the hierarchy.
\item
  \textbf{Hubris/Absencing}: They pursued their own metrics of
  \emph{volume} and \emph{cost}, rather than seeking out others (a la
  the Availability Heuristic Bias). That is, focusing on their own
  \emph{Map}, which is \emph{easier} than checking the \emph{Territory}.
\item
  \textbf{Deception}: Backed into a corner, engineers had no choice but
  to find ``creative'' ways to meet the metrics.
\item
  \textbf{Destruction}: Eventually, the truth comes out, to the
  detriment of the company, the environment and the shareholders. As the
  article's title summarizes ``A fish rots from the head down''.
\end{itemize}

\hypertarget{markets}{%
\section{Markets}\label{markets}}

So far, we've considered Map and Territory Risk for individuals, teams
and organisations. \href{https://equilibriabook.com}{Inadequate
Equilibria} by Eleizer Yudkovsky, looks at how perverse incentive
mechanisms break not just departments, but entire societal systems. He
highlights one example involving \emph{academics} and \emph{grantmakers}
in academia:

\begin{itemize}
\tightlist
\item
  It's not very apparent which academics are more worthy of funding.
\item
  One proxy is what they've published (scientific papers) and where
  they've published (journals).
\item
  Universities want to attract research grants, and the best way to do
  this is to have the best academics.
\item
  Because ``best'' isn't measurable, they use the publications proxy.
\item
  Therefore, immense power rests in the hands of the journals, since
  they can control this metric.
\item
  Therefore, journals are able to charge large amounts of money to
  universities for subscriptions.
\end{itemize}

\begin{quotation}

``Now consider the system of scientific journals\ldots{} Some journals
are prestigious. So university hiring committees pay the most attention
to publications in that journal. So people with the best, most
interesting-looking publications try to send them to that journal. So if
a university hiring committee paid an equal amount of attention to
publications in lower-prestige journals, they'd end up granting tenure
to less prestigious people. Thus, the whole system is a stable
equilibrium that nobody can unilaterally defy except at cost to
themselves.''

\sourceatright{\href{https://equilibriabook.com/molochs-toolbox/}{\textemdash  Inadequate Equilibria, \emph{Eleizer Yudkovsky}}}
\end{quotation}

As the book points out, while everyone \emph{persists} in using an
inadequate abstraction, the system is broken. However, Coordination
would be required for everyone to \emph{stop} doing it this way, which
is hard work. (At least within a top-down hierarchy, Maps can get
fixed.)

This is a \emph{small example} from a larger, closely argued book
investigating lots of examples of this kind. It's worth taking the time
to read a couple of the chapters on this interesting topic. (Like
Risk-First, it is available to read online).

As usual, this chapter forms a grab-bag of examples in a complex topic.
But it's time to move on as there is one last stop we have to make on
the Risk Landscape, and that is to look at Operational Risk.

The Hype Cycle model is available in \textbf{Numbers} format
{[}here{]}(https://github.com/risk-first/website/blob/master/RiskMatrix.numbers.

Now, on to the last risk in our tour, Operational Risk.

\hypertarget{operational-risk}{%
\chapter{Operational Risk}\label{operational-risk}}

\begin{quotation}

``The risk of loss resulting from inadequate or failed internal
processes, people and systems or from external events.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Operational_risk\#Definition}{\textemdash  Operational Risk, \emph{Wikipedia}}}
\end{quotation}

In this chapter we're going to start considering the realities of
running software systems in the real world.

Here, we're going to set the scene by looking at what constitutes an
Operational Risk, and then look at the related discipline of Operations
Management. Following this background, we'll apply the Risk-First model
and dive into the various mitigations for Operational Risk.

\hypertarget{operational-risks}{%
\section{Operational Risks}\label{operational-risks}}

When building software, it's tempting to take a very narrow view of the
dependencies of a system, but Operational Risks are often caused by
dependencies we \emph{don't} consider - i.e.~the \textbf{Operational
Context} within which the system is operating. Here are some examples:

\begin{itemize}
\tightlist
\item
  \textbf{Staff Risks:}

  \begin{itemize}
  \tightlist
  \item
    Freak weather conditions affecting ability of staff to get to work,
    interrupting the development and support teams.
  \item
    Reputational damage caused when staff are rude to the customers.
  \end{itemize}
\item
  \textbf{Reliability Risks:}

  \begin{itemize}
  \tightlist
  \item
    A data-centre going off-line, causing your customers to lose access.
  \item
    A power cut causing backups to fail.
  \item
    Not having enough desks for everyone to sit at.
  \end{itemize}
\item
  \textbf{Process Risks:}

  \begin{itemize}
  \tightlist
  \item
    Regulatory change, which means you have to adapt your business
    model.
  \item
    Insufficient controls which means you don't notice when some
    transactions are failing, leaving you out-of-pocket.
  \item
    Data loss because of bugs introduced during an untested release.
  \end{itemize}
\item
  \textbf{Software Dependency Risk:}

  \begin{itemize}
  \tightlist
  \item
    Hackers exploit weaknesses in a piece of 3rd party software,
    bringing your service down.
  \end{itemize}
\item
  \textbf{Agency Risk:}

  \begin{itemize}
  \tightlist
  \item
    Suppliers deciding to stop supplying you with something you need.
  \item
    Workers going on strike.
  \item
    Employees trying to steal from the company (bad actors).
  \item
    Other crime, such as hackers stealing data.
  \end{itemize}
\end{itemize}

.. basically, a long laundry-list of everything that can go wrong due to
operating in ``The Real World''. Although we've spent a lot of time
looking at the varieties of Dependency Risk on a software project, with
Operational Risk we have to consider that these dependencies will fail
in any number of unusual ways, and we can't be ready for all of them.
Nevertheless, preparing for this comes under the umbrella of Operations
Management.

\hypertarget{operations-management}{%
\section{Operations Management}\label{operations-management}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/slack-400dpi.png}
\caption{A Risk-First Model of Operations Management, inspired by the
work of Slack \emph{et al.}\label{slack.png}}
\end{figure}

If we are designing a software system to ``live'' in the real world, we
have to be mindful of the Operational Context we're working in, and
craft our software and processes accordingly. This view of the ``wider''
system is the discipline of Operations Management.

Figure \ref{slack.png} is a Risk-First interpretation of
\href{http://amzn.eu/d/b6ZjuMu}{Slack \emph{et al}'s model of Operations
Management}. This model breaks down some of the key abstractions of the
discipline: a \textbf{Transform Process} (the \textbf{Operation} itself)
is embedded in the wider \textbf{Operational Context}, which supplies it
with three key dependencies:

\begin{itemize}
\tightlist
\item
  \textbf{Resources}: Whether \emph{transformed} resources (like
  electricity or information, say) or \emph{transforming} resources
  (like staff or equipment).
\item
  \textbf{Customers}: Which supply it with money in return for goods and
  services.
\item
  \textbf{Operational Strategy}: The goals and objectives of the
  operation, informed by the reality of the environment it operates in.
\end{itemize}

We have looked at processes like the \textbf{Transform Process} in the
chapter on Process Risk. The healthy functioning of this process is the
domain of Operations Management, and (as per Slack \emph{et al.}) this
involves the following types of actions:

\begin{itemize}
\tightlist
\item
  \textbf{Control}: Ensuring that the Operation is working according to
  it's targets. This includes day-to-day quality control and monitoring
  of the Transform Process.
\item
  \textbf{Planning}: This covers aspects such as capacity planning,
  forecasting and project planning. This is about making sure the
  transform process has targets to meet and the resources to meet them.
\item
  \textbf{Design}: Ensuring that the design of the product and the
  transform process itself fulfils an \textbf{Operational Strategy}.
\item
  \textbf{Improvement}: Improving the operation in response to changes
  in the \textbf{Environment} and the \textbf{Operational Strategy},
  detecting failure and recovering from it.
\end{itemize}

Let's look at each of these actions in turn.

\hypertarget{control}{%
\section{Control}\label{control}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/monitoring-detection-400dpi.png}
\caption{Control, Monitoring And
Detection\label{monitoring-detection.png}}
\end{figure}

Since humans and machines have different areas of expertise, and because
Operational Risks are often novel, it's often not optimal to try and
automate everything. A good operation will consist of a mix of human and
machine actors, each playing to their strengths (see the table below).

\begin{longtable}[]{@{}ll@{}}
\toprule
Humans Are\ldots{} & Machines Are\ldots{}\tabularnewline
\midrule
\endhead
Good at novel situations & Good at repetitive situations\tabularnewline
Good at adaptation & Good at consistency\tabularnewline
Expensive at scale & Cheap at scale\tabularnewline
Reacting and Anticipating & Recording\tabularnewline
\bottomrule
\end{longtable}

The aim is to build a human-machine operational system that is
\href{https://en.wikipedia.org/wiki/Homeostasis}{\emph{Homeostatic}}.
This is the property of living things to try and maintain an equilibrium
(for example, body temperature or blood glucose levels), but also
applies to systems at any scale. The key to homeostasis is to build
systems with feedback loops, even though this leads to more complex
systems overall. Figure \ref{monitoring-detection.png} shows some of the
actions involved in these kind of feedback loops.

As we saw in Map and Territory Risk, it's very easy to fool yourself,
especially around Key Performance Indicators (KPIs) and metrics. Large
organisations have \href{https://en.wikipedia.org/wiki/Audit}{Audit}
functions precisely to guard against their own internal failing
processes and Agency Risk. Audits could be around software tools,
processes, practices, quality and so on. Practices such as
\href{https://en.wikipedia.org/wiki/Continual_improvement_process}{Continuous
Improvement} and
\href{https://en.wikipedia.org/wiki/Total_quality_management}{Total
Quality Management} also figure here.

\hypertarget{the-operational-context}{%
\subsection{The Operational Context}\label{the-operational-context}}

There are plenty of Hidden Risks within the environment the operation
exists within, and these change all the time in response to economic or
political change. In order to manage a risk, you have to uncover it, so
part of Operations Management is to look for trouble:

\begin{itemize}
\tightlist
\item
  \textbf{Environmental Scanning} is all about trying to determine which
  changes in the environment are going to impact your operation. Here,
  we are trying to determine the level of Dependency Risk we face for
  external dependencies, such as \emph{suppliers}, \emph{customers} and
  \emph{markets}. Tools like
  \href{https://en.wikipedia.org/wiki/PEST_analysis}{PEST} are relevant
  here, as is
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Penetration_test}{Penetration
  Testing}} is looking for security weaknesses within the operation. See
  \href{https://en.wikipedia.org/wiki/OWASP}{OWASP} for examples.
\item
  \textbf{\href{https://en.wikipedia.org/wiki/Vulnerability_management}{Vulnerability
  Management}} is keeping up-to-date with vulnerabilities in Software
  Dependencies.
\end{itemize}

\hypertarget{planning}{%
\section{Planning}\label{planning}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/forecasting-planning-400dpi.png}
\caption{Forecasting and Planning
Actions\label{forecasting-planning.png}}
\end{figure}

In order to \emph{control} an operation, we need targets and plans to
\emph{control against}. For a system to run well, it needs to carefully
manage unreliable dependencies, and ensure their safety and
availability. In the example of the humans, say, it's the difference
between
\href{https://en.wikipedia.org/wiki/Hunter-gatherer}{Hunter-Gathering}
(picking up food where we find it) and
\href{https://en.wikipedia.org/wiki/Agriculture}{Agriculture}
(controlling the environment and the resources to grown crops).

As Figure \ref{forecasting-planning.png} shows, we can bring Planning to
bear on dependency management, and this usually falls to the more human
end of the operation.

\hypertarget{design}{%
\section{Design}\label{design}}

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/design-change-400dpi.png}
\caption{Design and Change Activities\label{design-change.png}}
\end{figure}

Since our operation exists in a world of risks like Red Queen Risk and
Feature Drift Risk, we would expect that the output of our Planning
actions would result in changes to our operation.

While \emph{planning} is a day-to-day operational feedback loop,
\emph{design} is a longer feedback loop changing not just the parameters
of the operation, but the operation itself.

You might think that for an IT operation, tasks like Design belong
within the Development function within an organisation. Often, this is
the case. However separating Development from Operation implies Boundary
Risk between these two functions. For example, the developers might
employ different tools, equipment and processes to the operations team,
resulting in a mismatch when software is delivered.

In recent years, the ``DevOps'' movement has brought this Boundary Risk
into sharper focus. This specifically means:

\begin{itemize}
\tightlist
\item
  Using code to automate previously manual Operations functions, like
  monitoring and releasing.
\item
  Involving Operations in the planning and design, so that the delivered
  software is optimised for the environment it runs in.
\end{itemize}

DevOps heavily borrows from the Agile movement, both of which will be
covered in more detail in Part 4.

\begin{figure}
\centering
\includegraphics{images/devops.png}
\caption{DevOps Activities: Development and Operations activities
overlap one-another (Credit: Kharnagy, Wikipedia)\label{devops.png}}
\end{figure}

\hypertarget{improvement}{%
\section{Improvement}\label{improvement}}

Once exposed to the real world, no system is perfect: we will want to
improve it over time. However, conversely, Operational Risk includes an
element of Trust \& Belief Risk: our \emph{reputation} and the good will
of our customers. This gives us pause: we don't want to destroy good
will created for our software, this is very hard to rebuild.

So there is a tension between ``you only get one chance to make a first
impression'' and ``gilding the lily'' (perfectionism). In the past I've
seen this stated as:

\begin{quotation}

``Pressure to ship vs pressure to improve''

\end{quotation}

\begin{figure}
\centering
\includegraphics{images/generated/risks/operational/ship-it-400dpi.png}
\caption{Balance of Risks from Delivering Software\label{ship-it.png}}
\end{figure}

A Risk-First re-framing of this might be the balance between:

\begin{itemize}
\tightlist
\item
  The perceived Trust \& Belief Risk, Feature Risk and Operational Risk
  of going to production (pressure to improve).
\item
  The perceived Scarcity Risks (such as funding, time available, etc) of
  staying in development (pressure to ship).
\end{itemize}

The ``should we ship?'' decision is therefore a complex one. In Meeting
Reality, we discussed that it's better to do this ``sooner, more
frequently, in smaller chunks and with feedback''. We can meet
Operational Risk \emph{on our own terms} by doing so:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
Meet Reality\ldots{}\strut
\end{minipage} & \begin{minipage}[b]{0.58\columnwidth}\raggedright
Techniques\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{Sooner}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Quality Control Processes, Limited Early-Access Programs, Beta Programs,
Soft Launches, Business Continuity Testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{More Frequently}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Continuous Delivery, Sprints\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{In Smaller Chunks}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Modular Releases, Microservices, Feature Toggles, Trial
Populations\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
\textbf{With Feedback}\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
User Communities, Support Groups, Monitoring, Logging, Analytics\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{end-of-the-road}{%
\section{End Of The Road}\label{end-of-the-road}}

In a way, actions like \textbf{Design} and \textbf{Improvement} bring us
right back to where we started from: identifying Dependency Risks,
Feature Risks and Complexity Risks that hinder our operation, and
mitigating them through actions like \emph{software development}.

Our safari of risk is finally complete, it's time to look back and what
we've seen in Staging and Classifying.

\hypertarget{staging-and-classifying}{%
\chapter{Staging And Classifying}\label{staging-and-classifying}}

Our tour is complete.

On this journey around the Risk Landscape we've collected a (hopefully)
good, representative sample of Risks and where to find them. But if we
are good collectors, then before we're done we should
\emph{\href{https://en.wikipedia.org/wiki/Entomological_equipment_for_mounting_and_storage}{Stage}}
our specimens and do some work in classifying what we've seen.

\begin{figure}
\centering
\includegraphics{images/Beetle_collection.jpg}
\caption{Staged and Classified Beetle Collection, (Credit: Fir0002,
Wikipedia)\label{Beetle_collection.jpg}}
\end{figure}

If you've been reading closely, you'll notice that a number of themes
come up again and again within the different chapters. Concepts like
\textbf{Abstraction}, \textbf{Evolution} and \textbf{Fit}. Although
we've been looking at patterns of risk across software projects, it's
time to look at the \emph{patterns within the patterns}.

\hypertarget{the-power-of-abstractions}{%
\section{The Power Of Abstractions}\label{the-power-of-abstractions}}

Abstraction appears as a concept continually: in Communication Risk,
Complexity Metrics, Map and Territory Risk or how it causes Boundary
Risk. We've looked at some complicated examples of abstractions, such as
network protocols, dependencies on technology or Business Processes.

Let's now \emph{generalize} what is happening with abstraction. To do
this, we'll consider the simplest example of abstraction: \emph{naming a
pattern} of behaviour we see in the real world, such as ``Binge
Watching'' or ``Remote Working'', or naming a category of insects as
``Beetles''.

\hypertarget{using-an-existing-abstraction-means}{%
\subsection{Using An Existing Abstraction
means:}\label{using-an-existing-abstraction-means}}

\begin{itemize}
\tightlist
\item
  \textbf{Mitigating Feature Risk:} Because the abstraction is providing
  you with something \emph{useful}. For example, using the word
  ``London'' allows you to refer to a whole existing (but slightly
  non-specific) geographic area.
\item
  \textbf{Accepting Communication Risk.} : Because if you are using the
  abstraction in conversation, the people you are using it with
  \emph{need to understand it too}.
\item
  \textbf{Accepting Map and Territory Risk}: Because the abstraction is
  a simplification, and not the actual thing itself.
\item
  \textbf{Living with Dependency Risk:} We depend on a word in our
  language (or a function in our library, or a service on the Internet).
  But words are \emph{unreliable}. They might not communicate what you
  want them to, or be understood by the audience. Language
  \emph{changes} and \emph{evolves}, and the words you are using now
  might not always mean what you want them to mean. (Software too
  changes and evolves: We've seen this in Red Queen Risk and Feature
  Drift Risk.)
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/depending-abstraction-400dpi.png}
\caption{Depending on an Abstraction\label{depending-abstraction.png}}
\end{figure}

\hypertarget{inventing-a-new-abstraction-means}{%
\subsection{Inventing A New Abstraction
means:}\label{inventing-a-new-abstraction-means}}

\begin{itemize}
\tightlist
\item
  \textbf{Mitigating Feature Risk.} By \emph{giving a name to something}
  (perhaps a new product, or a way of working) you are offering up
  something that someone else can use in conversation. This should
  mitigate Features in the sense that other people can choose to use
  your name, if it fits their requirements.
\item
  \textbf{Creating a Protocol.} At the very simplest level (again), this
  is just introducing \emph{new words to a language}. Therefore, we
  create Protocol Risk: what if the person we are communicating with
  \emph{doesn't} know this word?
\item
  \textbf{Increasing Complexity Risk.} Because, the more words we have,
  the more complex the language is.
\item
  \textbf{Creating Boundary Risk.} By naming something, you
  \emph{implicitly} create a boundary, because the world is now divided
  into ``things which \emph{are} X'' and ``things which \emph{are not}
  X''. Sometimes, this abstraction may literally end up having a
  physical boundary to enforce this division (such as the fence
  separating ``My Property'' from ``Not My Property''). \emph{Boundary
  Risk is a result of abstractions.}
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/inventing-abstraction-400dpi.png}
\caption{Inventing an Abstraction\label{inventing-abstraction.png}}
\end{figure}

\hypertarget{choosing-between-abstractions-means}{%
\subsection{Choosing Between Abstractions
means:}\label{choosing-between-abstractions-means}}

\begin{itemize}
\tightlist
\item
  \textbf{Overcoming a Learning Curve}: Because you have to \emph{learn}
  a name in order to use it (whether a function, a dog, or the name of
  someone at a party).
\item
  \textbf{Accepting Boundary Risks.} Just using \emph{a single word}
  means accepting the whole \emph{ecosystem} of the language the word is
  in. Using \emph{French words} means the Boundary Risk of the French
  Language.
\item
  \textbf{Accepting Map And Territory Risk.} Because the word refers to
  the \emph{concept} of the thing, and \emph{not the thing itself}.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/choosing-abstraction-400dpi.png}
\caption{Choosing an Abstraction\label{choosing-abstraction.png}}
\end{figure}

Abstraction (like any other action) is everywhere and seems to be at the
heart of what our brains do. But clearly, there is a trade-off with
abstraction: as you can see above, there are risks on both sides of the
action.

\emph{Naming} something seems innocuous, a small thing. Consider all the
classes, variables, products and systems in software development that
have names. Do all of these names ``factor'' correctly to things in the
real world? Or do they introduce arbitrary classification? (For example,
you might classify water as ``hot'' or ``cold'' while really there is
just temperature.)

Abstraction \emph{is} a small thing, but it's effects compound
massively.

\hypertarget{your-feature-risk-is-someone-elses-dependency-risk}{%
\section{Your Feature Risk is Someone Else's Dependency
Risk}\label{your-feature-risk-is-someone-elses-dependency-risk}}

In the Feature Risk chapter, we looked at the problems of
\emph{supplying something for a client to use as a dependency}: you've
got to satisfy a demand (Market Risk), and service a segment of the user
community (Feature Access Risk).

However, over the rest of the Dependency Risk chapters, we looked at
this from the point of view of \emph{being a client to someone else}:
you want to find trustworthy, reliable dependencies that don't give up
when you least want them to.

So Feature Risk and Dependency Risk are \emph{two sides of the same
coin}. You face Dependency Risk when you're a client, Feature Risk when
you're the supplier.

To \emph{use} a dependency requires the client and the supplier to
communicate, and this entails Communication Risk. You have to learn to
use a dependency. Maybe it's supplier learns something from you. This
changes internal models.

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/features-and-dependencies-400dpi.png}
\caption{Features And Dependencies\label{features-and-dependencies.png}}
\end{figure}

These relationships of features/dependencies are the basis of Supply
Chains and the world-wide network of goods and services that forms the
modern economy. The incredible complexity of this network mean
incredible Complexity Risk, too. Humans are masters at coordinating and
managing our dependencies.

\hypertarget{original-risk}{%
\section{Original Risk}\label{original-risk}}

As we discussed in Dependency Risk, \emph{depending on things} is
necessary for life, whether it is oxygen, food or sunlight. Minimising
Dependency-Risk is therefore the goal of all life.

Our problems compound when we try to Coordinate with the dependencies
themselves or each other.

\begin{itemize}
\tightlist
\item
  Coordination is the root of Communication Risk, as without
  coordination, we don't have to care about what the world is trying to
  tell us, or what we are trying to tell the world.
\item
  Communication Risk then begets Map and Territory Risk, because
\item
  Communication Risk also means Complexity Risk, because now we have
  built a communication graph (and we saw how to calculate how complex
  that is).
\item
  Boundary Risk, this is at a confluence of Dependency Risk,
  Communication Risk and Complexity Risk.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/origin-of-risk-400dpi.png}
\caption{Causes Of Risk\label{origin-of-risk.png}}
\end{figure}

The way this plays out is depicted in Figure \ref{origin-of-risk.png}.

\hypertarget{towards-a-periodic-table-of-risks}{%
\section{Towards A ``Periodic Table'' Of
Risks}\label{towards-a-periodic-table-of-risks}}

As we said at the start, Risk-First is all about developing \emph{A
Pattern Language}. We can use the terms like ``Feature Risk''\_ or
``Learning Curve Risk'' to \emph{explain} phenomena we see on software
projects. If we want to De-Risk our work, we need to be able to explain
what the risks are, and what we expect to do about them.

\begin{figure}
\centering
\includegraphics{images/generated/staging-and-classifying/periodic-table-large-400dpi.png}
\caption{Periodic Table of Risks\label{periodic-table-large.png}}
\end{figure}

Figure \ref{periodic-table-large.png} compiles all of the risks we've
seen so far on the journey across the risk landscape. Just like a
periodic table, there are perhaps others left to discover. \emph{Unlike}
a periodic table, these risks are not completely distinct: they mix like
paint and blend into one another.

Please help by reporting back what you find.

\part{Tools \& Practices}

\hypertarget{coming-next}{%
\chapter{Coming Next}\label{coming-next}}

This is nearly the end of \emph{Risk-First: The Menagerie}. But, it's
not the full picture. We've had Part 1 (The Introduction) and Part 2
(The Risk Landscape), but you're yet to read parts 3 \& 4. These are to
be published together in the next book, \emph{Risk-First: Tools and
Techniques}, but are also available at \texttt{https://riskfirst.org}.

But it feels a shame to end with Part 2, which is just a long list of
all the troubles you'll face on a software project. So in order to
improve the tone somewhat, here we have a single chapter from Part 3 .

As an encore, if you will.

\hypertarget{estimates}{%
\chapter{Estimates}\label{estimates}}

In this chapter, we're going to put a Risk-First spin on the process of
Estimating. But, in order to get there, we first need to start with
understanding \emph{why} we estimate. We're going to look at some ``Old
Saws'' of software estimation and what we can learn from them. Finally,
we'll bring our Risk-First menagerie to bear on de-risking the
estimation process.

\hypertarget{the-purpose-of-estimating}{%
\section{The Purpose Of Estimating}\label{the-purpose-of-estimating}}

Why bother estimating at all? There are two reasons why estimates are
useful:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{To allow for the creation of \emph{events}.} As we saw in
  Deadline Risk, if we can put a date on something, we can mitigate lots
  of Coordination Risk. Having a \emph{release date} for a product
  allows whole teams of people to coordinate their activities in ways
  that hugely reduce the need for Communication. ``Attack at dawn''
  allows disparate army units to avoid the Coordination Risk inherent in
  ``attack on my signal''. This is a \emph{good reason for estimating},
  because by using events you are mitigating Coordination Risk. This is
  often called a \emph{hard deadline}.
\item
  \textbf{To allow for the estimation of the Pay-Off of an action.} This
  is a \emph{bad reason for estimating}, as we will discuss in detail
  below. But briefly, the main issue is that Pay-Off isn't just about
  figuring out Schedule Risk - you should be looking at all the other
  Attendant Risks of the action too.
\end{enumerate}

\hypertarget{how-estimates-fail}{%
\section{How Estimates Fail}\label{how-estimates-fail}}

Estimates are a huge source of contention in the software world:

\begin{quotation}

``Typically, effort estimates are over-optimistic and there is a strong
over-confidence in their accuracy. The mean effort overrun seems to be
about 30\% and not decreasing over time.''

\sourceatright{\href{https://en.m.wikipedia.org/wiki/Software_development_effort_estimation}{\textemdash  Software Development Effort Estimation, \emph{Wikipedia}}.}
\end{quotation}

In their research ``Anchoring and Adjustment in Software Estimation'',
\href{http://www.cs.toronto.edu/\%7Esme/papers/2005/ESEC-FSE-05-Aranda.pdf}{Aranda
and Easterbrook} asked developers split into three groups (A, B and
Control) to give individual estimates on how long a piece of software
would take to build. They were each given the same specification.
However:

\begin{itemize}
\tightlist
\item
  Group A was given the hint: ``I admit I have no experience with
  software, but I guess it will take about two months to finish''.
\item
  Group B were given the same hint, except with \emph{20} months.
\end{itemize}

How long would members of each group estimate the work to take? The
results were startling. On average:

\begin{itemize}
\tightlist
\item
  Group A estimated 5.1 months.
\item
  The Control Group estimated 7.8 months.
\item
  Group B estimated 15.4 months.
\end{itemize}

The anchor mattered more than experience, how formal the estimation
method, or \emph{anything else}. \emph{We can't estimate time at all}.

\hypertarget{is-risk-to-blame}{%
\section{Is Risk To Blame?}\label{is-risk-to-blame}}

Why is it so bad? The problem with a developer answering a question such
as:

\begin{quotation}

``How long will it take to deliver X?''

\end{quotation}

Seems to be the following:

\begin{itemize}
\tightlist
\item
  The developer and the client likely don't agree on exactly what X is,
  and any description of it is inadequate anyway (Invisibility Risk).
\item
  The developer has a less-than-complete understanding of the
  environment he will be delivering X in (Complexity Risk and Map And
  Territory Risk).
\item
  The developer has some vague ideas about how to do X, but he'll need
  to try out various approaches until he finds something that works
  (Boundary Risk and Learning-Curve Risk).
\item
  The developer has no idea what Hidden Risk will surface when he starts
  work on it.
\item
  The developer has no idea what will happen if he takes too long and
  misses the date by a day/week/month/year (Schedule Risk).
\end{itemize}

\ldots{} and so on.

The reason the estimate of \emph{time} is wrong is because every action
attempts to mitigate risk and the estimate of \emph{risk} is wrong.

So what are we to do? It's a problem as old as software itself, and in
deference to that, let's examine the estimating problem via some ``Old
Saws''.

\hypertarget{old-saw-no.1-the-10x-developer}{%
\section{Old Saw No.~1: The ``10X
Developer''}\label{old-saw-no.1-the-10x-developer}}

\begin{quotation}

``A 10X developer is an individual who is thought to be as productive as
10 others in his or her field. The 10X developer would produce 10 times
the outcomes of other colleagues, in a production, engineering or
software design environment.''

\sourceatright{\href{https://www.techopedia.com/definition/31673/10X-developer}{\textemdash  10X Developer, \emph{Techopedia}}}
\end{quotation}

Let's try and pull this apart:

\begin{itemize}
\tightlist
\item
  How do we measure this ``productivity''? In Risk-First terms, this is
  about taking action to \emph{transform} our current position on the
  Risk Landscape to a position of more favourable risk. A ``10X
  Developer'' then must be able to take actions that have much higher
  Pay-Off than a ``1X Developer''. That is, mitigating more existing
  risk, and generating less Attendant Risk.
\item
  It stands to reason then, that someone taking action \emph{faster}
  will leaving us with less Schedule Risk.
\item
  However, if they are \emph{more expensive}, they may leave us with
  greater Funding Risk afterwards.
\item
  But, Schedule Risk isn't the only risk being transformed: The result
  might be bugs, expensive new dependencies or spaghetti-code
  complexity.
\item
  The ``10X'' developer \emph{must} also leave behind less of these kind
  of risks too.
\item
  That means that the ``10X Developer'' isn't merely faster, but
  \emph{taking different actions}. They are able to use their talent and
  experience to see actions with greater pay-off than the 1X Developer.
\end{itemize}

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/1x-10x-400dpi.png}
\caption{1X Task vs 10X Task\label{1x-10x.png}}
\end{figure}

Does the ``10X Developer'' even exist? Crucially, it would seem that
such a thing would be predicated on the existence of the ``1X
Developer'', who gets ``1X'' worth of work done each day. It's not clear
that there is any such thing as an average developer who is mitigating
risk at an average rate.

Even good developers have bad days, weeks or projects. Taking Action is
like placing a bet. Sometimes you lose and the Pay-Off doesn't appear:

\begin{itemize}
\tightlist
\item
  The Open-Source software you're trying to apply to a problem doesn't
  solve it in the way you need.
\item
  A crucial use-case of the problem turns out to change the shape of the
  solution entirely, leading to lots of rework.
\item
  An assumption about how network security is configured turns out to be
  wrong, leading to a lengthy engagement with the infrastructure team.
\end{itemize}

The easiest way to be the ``10X developer'' is to have \emph{done the
job before}. If you're coding in a familiar language, with familiar
libraries and tools, delivering a cookie-cutter solution to a problem in
the same manner you've done several times before, then you will be a
``10X Developer'' compared to \emph{you doing it the first time}
because:

\begin{itemize}
\tightlist
\item
  There's no Learning Curve Risk, because you already learnt everything.
\item
  There's no Dead End Risk because you already know all the right
  choices to make.
\end{itemize}

\hypertarget{old-saw-no.2-quality-speed-cost-pick-any-two}{%
\section{Old Saw No.~2: Quality, Speed, Cost: Pick Any
Two}\label{old-saw-no.2-quality-speed-cost-pick-any-two}}

\begin{quotation}

``The Project Management Triangle (called also the Triple Constraint,
Iron Triangle and Project Triangle) is a model of the constraints of
project management. While its origins are unclear, it has been used
since at least the 1950s. It contends that:

\end{quotation}

\begin{quotation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The quality of work is constrained by the project's budget, deadlines
  and scope (features).
\end{enumerate}

\end{quotation}

\begin{quotation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The project manager can trade between constraints.
\end{enumerate}

\end{quotation}

\begin{quotation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Changes in one constraint necessitate changes in others to compensate
  or quality will suffer."
\end{enumerate}

\end{quotation}

\begin{quotation}

\sourceatright{\href{https://en.wikipedia.org/wiki/Project_management_triangle}{\textemdash  Project Management Triangle, \emph{Wikipedia}}}
\end{quotation}

From a Risk-First perspective, we can now see that this is an
over-simplification. If \emph{quality} is a Feature Fit metric,
\emph{deadlines} is Schedule Risk and \emph{budget} refers to Funding
Risk then that leaves us with a lot of risks unaccounted for:

\begin{itemize}
\tightlist
\item
  I can deliver a project in very short order by building a bunch of
  screens that \emph{do nothing} (accruing \emph{stunning} levels of
  Implementation Risk as I go).
\item
  Or, by assuming a lottery win, the project's budget is fine. (Although
  I would have \emph{huge} Funding Risk because \emph{what are the
  chances of winning the lottery?}.)
\item
  Brooks' Law contradicts this by saying you can't trade budget for
  deadlines:
\end{itemize}

\begin{quotation}

``Brooks' law is an observation about software project management
according to which''adding human resources to a late software project
makes it later``.

\sourceatright{\href{https://en.wikipedia.org/wiki/Brooks_law}{\textemdash  Brooks Law, \emph{Wikipedia}}}
\end{quotation}

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/brooks-400dpi.png}
\caption{Brooks' Law, Risk-First Style\label{brooks.png}}
\end{figure}

Focusing on the three variables of the iron triangle isn't enough. You
can game these variables by sacrificing others: we need to be looking at
the project's risk \emph{holistically}.

\begin{itemize}
\tightlist
\item
  There's no point in calling a project complete if the dependencies you
  are using are unreliable or undergoing rapid change
\item
  There's no point in delivering the project on time if it's an
  Operational Risk nightmare, and requires constant round-the-clock
  support and will cost a fortune to \emph{run}. (Working on a project
  that ``hits it's delivery date'' but is nonetheless a broken mess once
  in production is too common a sight.)
\item
  There's no point in delivering a project on-budget if the market has
  moved on and needs different features.
\end{itemize}

\hypertarget{old-saw-no.3-parkinsons-law}{%
\subsection{Old Saw No.~3: Parkinson's
Law}\label{old-saw-no.3-parkinsons-law}}

We've already looked at Parkinson's Law in the chapter on Agency Risk,
but lets recap:

\begin{quotation}

``Parkinson's law is the adage that `work expands so as to fill the time
available for its completion'.''

\sourceatright{\href{https://en.wikipedia.org/wiki/Parkinsons_law}{\textemdash  Parkinson's Law, \emph{Wikipedia}}  }
\end{quotation}

Let's leave aside the Agency Risk concerns this time. Instead, let's
consider this from a Risk-First perspective. \emph{Of course} work would
expand to fill the time available: \emph{Time available} is an
\emph{absence of Schedule Risk}, it's always going to be sensible to
exchange free time to reduce more serious risks.

This is why projects will \emph{always} take at least as long as is
budgeted for them.

\hypertarget{a-case-study}{%
\subsection{A Case Study}\label{a-case-study}}

Let's look at a quick example of this in action, taken from
\href{http://amzn.eu/d/eTWKOsK}{Rapid Development by Steve McConnell}.
At the point of this excerpt, Carl (the Project Manager) is discussing
the schedule with Bill, the project sponsor:

\begin{quotation}

``I think it will take about 9 months, but that's just a rough estimate
at this point,'' Carl said. ``That's not going to work,'' Bill said. ``I
was hoping you'd say 3 or 4 months. We absolutely need to bring that
system in within 6 months. Can you do it in 6?'' \texttt{(1)}

\end{quotation}

Later in the story, the schedule has slipped twice and is about to slip
again:

\begin{quotation}

\ldots{} At the 9-month mark, the team had completed detailed design,
but coding still hadn't begun on some modules. It was clear that Carl
couldn't make the 10-month schedule either. He announced the third
schedule slip number--- to 12 months. Bill's face turned red when Carl
announced the slip, and the pressure from him became more intense.
\texttt{(2)}

\end{quotation}

At point \texttt{(2)}, Carl's tries to mitigate Feature Risk by
increasing Schedule Risk, although he knows that Bill will trust him
less for doing this, as shown below:

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/carl1-400dpi.png}
\caption{Carl's Schedule Slip increases Trust and Belief
Risks\label{carl1.png}}
\end{figure}

\begin{quotation}

Carl began to feel that his job was on the line. Coding proceeded fairly
well, but a few areas needed redesign and reimplementation. The team
hadn't coordinated design details in those areas well, and some of their
implementations conflicted. At the 11-month oversight-committee meeting,
Carl announced the fourth schedule slip--- to 13 months. Bill became
livid. ``Do you have any idea what you're doing?'' he yelled. ``You
obviously don't have any idea! You obviously don't have any idea when
the project is going to be done! I'll tell you when it's going to be
done! It's going to be done by the 13-month mark, or you're going to be
out of a job! I'm tired of being jerked around by you software guys! You
and your team are going to work 60 hours a week until you deliver!''
\texttt{(3)}

\end{quotation}

At point \texttt{(3)}, the schedule has slipped again, and Bill has
threatened Carl's job. Why did he do this? Because \emph{he doesn't
trust Carl's evaluation of the Schedule Risk}. By telling Carl that it's
his job on the line, he makes sure Carl appreciates the Schedule Risk.
However, forcing staff to do overtime is a dangerous ploy: it could
disenfranchise the staff, or cause corners to be cut:

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/bill1-400dpi.png}
\caption{Bill's Ultimatum\label{bill1.png}}
\end{figure}

\begin{quotation}

Carl felt his blood pressure rise, especially since Bill had backed him
into an unrealistic schedule in the first place. But he knew that with
four schedule slips under his belt, he had no credibility left. He felt
that he had to knuckle under to the mandatory overtime or he would lose
his job. Carl told his team about the meeting. They worked hard and
managed to deliver the software in just over 13 months. Additional
implementation uncovered additional design flaws, but with everyone
working 60 hours a week, they delivered the product through sweat and
sheer willpower. " \texttt{(4)}

\sourceatright{\href{http://amzn.eu/d/eTWKOsK}{\textemdash  McConnell, Steve, \emph{Rapid Development}}}
\end{quotation}

At point \texttt{(4)}, we see that Bill's gamble worked (for him at
least): the project was delivered on time by the team working overtime
for two months. This was lucky - it seems unlikely that no-one quit and
that the code didn't descend into a mess in that time.

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/team1-400dpi.png}
\caption{Team Response\label{team1.png}}
\end{figure}

Despite this being a fictional (or fictionalised) example, it rings true
for many projects. What \emph{should} have happened at point
\texttt{(1)}? Both Carl and Bill estimated incorrectly\ldots{} Or did
they?

\hypertarget{agile-estimation}{%
\section{Agile Estimation}\label{agile-estimation}}

One alternative approach, must espoused in DevOps/Agile is to pick a
short-enough period of time (say, two days or two weeks), and figure out
what the most meaningful step towards achieving an objective would be in
that time. By fixing the time period, we remove Schedule Risk from the
equation, don't we?

Well, no. First, how to choose the time period? Schedule Risk tends to
creep back in, in the form of something like
\href{https://en.wikipedia.org/wiki/Man-hour}{Man-Hours} or
\href{https://www.atlassian.com/agile/project-management/estimation}{Story
Points}:

\begin{quotation}

``Story points rate the relative effort of work in a Fibonacci-like
format: 0, 0.5, 1, 2, 3, 5, 8, 13, 20, 40, 100. It may sound
counter-intuitive, but that abstraction is actually helpful because it
pushes the team to make tougher decisions around the difficulty of
work.''

\sourceatright{\href{https://www.atlassian.com/agile/project-management/estimation}{\textemdash  Story Points, \emph{Atlassian}}}
\end{quotation}

Second, the strategy of picking the two-day action with the greatest
Pay-Off is \emph{often good}. (After all, this is just Gradient Descent,
and that's a perfectly good way for training
\href{https://en.wikipedia.org/wiki/Machine_learning}{Machine Learning}
systems.) However, just like following a river downhill from the top of
a mountain will \emph{often} get you to the sea, it probably won't take
the shortest path, and sometimes you'll get stuck at a lake.

The choice of using gradient descent means that you have given up on
Goals: Essentially, we have here the difference between ``Walking
towards a destination'' and ``Walking downhill''. Or, if you like, a
planned economy and a market economy. But, we don't live in
\emph{either}: everyone lives in some mixture of the two: our
governments \emph{have plans} for big things like roads and hospitals,
and taxes. Other stuff, they leave to the whims of supply and demand. A
project ends up being the same.

\hypertarget{risk-first-estimating}{%
\section{Risk-First Estimating}\label{risk-first-estimating}}

Let's figure out what we can take away from the above experiences:

\begin{itemize}
\tightlist
\item
  \textbf{From the ``10X Developer'' Saw:} the difference made by
  experience implies that a lot of the effort on a project comes from
  Learning Curve Risk and Dead End Risk.
\item
  \textbf{From ``Quality, Speed, Cost'':} we need to be considering
  \emph{all} risks, not just some arbitrary milestones on a project
  plan. Project plans can always be gamed, and you can always leave
  risks unaccounted for in order to hit the goals.
\item
  \textbf{From the Parkinson's Law:} giving people a \emph{time budget},
  you absolve them from Schedule Risk\ldots{} at least until they
  realise they're going to overrun. This gives them one less dimension
  of risk to worry about, but means they end up taking all the time you
  give them, because they are optimising over the remaining risks.
\item
  Finally, the lesson from Agile Estimation is that \emph{just
  iterating} is sometimes not as efficient as \emph{using your intuition
  and experience} to find a more optimal path.
\end{itemize}

How can we synthesise this knowledge, along with what we've learned into
something that makes more sense?

\hypertarget{tip-1-estimating-should-be-about-estimating-pay-off}{%
\subsubsection{\texorpdfstring{Tip \#1: Estimating Should be About
\emph{Estimating Pay
Off}}{Tip \#1: Estimating Should be About Estimating Pay Off}}\label{tip-1-estimating-should-be-about-estimating-pay-off}}

For a given action / road-map / business strategy, what Attendant Risks
are we going to have:

\begin{itemize}
\tightlist
\item
  What bets are we making about where the market will be?
\item
  What Communication Risk will we face explaining our product to people?
\item
  What Feature Fit risks are we likely to have when we get there?
\item
  What Complexity Risks will we face building our software? How can we
  avoid it ending up as a Big Ball Of Mud?
\item
  Where are we likely to face Boundary Risks and Dead End Risks
\end{itemize}

Instead of the Agile Estimation being about picking out a story-point
number based on some idealised amount of typing that needs to be done,
it should be about surfacing and weighing up risks. e.g:

\begin{itemize}
\tightlist
\item
  ``Adding this new database is problematic because it's going to
  massively increase our Dependency Risk.''
\item
  ``I don't think we should have component A interacting with component
  B because it'll introduce extra Communication Risk which we will
  always be tripping over.''
\item
  ``I worry we might not understand what the sales team want and are
  facing Feature Implementation Risk. How about we try and get agreement
  on a specification?''
\end{itemize}

\hypertarget{tip-2-the-risk-landscape-is-increasingly-complex-utilise-this}{%
\subsubsection{Tip \#2: The Risk Landscape is Increasingly Complex:
Utilise
This}\label{tip-2-the-risk-landscape-is-increasingly-complex-utilise-this}}

\begin{figure}
\centering
\includegraphics{images/estimates/central-line.png}
\caption{Journey via the Central Line\label{central-line.png}}
\end{figure}

If you were travelling across London from Ealing (in the West) to
Stratford (in the East) the \emph{fastest} route might be to take the
Central Line. You could do it via the A406 road, which would take a
\emph{bit} longer. It would \emph{feel} like you're mainly going in
completely the wrong direction doing that, but it's much faster than
cutting straight through London and you don't pay the congestion charge.

\begin{figure}
\centering
\includegraphics{images/estimates/car.png}
\caption{Journey by Car\label{car.png}}
\end{figure}

In terms of risk, they all have different profiles. You're often delayed
in the car, by some amount. The tube is \emph{generally} reliable, but
when it breaks down or is being repaired it might end up quicker to
walk.

If you were doing this same journey on foot, it's a very direct route,
but would take five times longer. However, if you were making this
journey a hundred years ago, that might be the way you chose (horseback
might be a bit faster).

\begin{figure}
\centering
\includegraphics{images/estimates/foot.png}
\caption{Journey on Foot\label{foot.png}}
\end{figure}

In the software development past, \emph{building it yourself} was the
only way to get anything done. It was like London \emph{before road and
rail}. Nowadays, you are bombarded with choices. It's actually
\emph{worse than London} because it's not even a two-dimensional
geographic space and there are multitudes of different routes and
acceptable destinations. Journey planning on the software Risk Landscape
is an optimisation problem \emph{par excellence}.

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/risk-landscape-400dpi.png}
\caption{Possible Moves On The Risk Landscape\label{risk-landscape.png}}
\end{figure}

Because the modern Risk Landscape is so complex:

\begin{itemize}
\tightlist
\item
  There can be orders of magnitude difference in \emph{time}, with very
  little difference in destination.
\item
  If it's Schedule Risk you're worried about, \emph{Code Yourself} isn't
  a great solution (for the whole thing, anyway). ``Take the tube'' and
  at least partly use something someone built already. There are
  probably multiple alternatives you can consider.
\item
  If no one has built something similar already, then why is that? Have
  you formulated the problem properly?
\item
  Going the wrong way is \emph{so much easier}.
\item
  Dead-Ends (like a broken Central Line) are much more likely to trip
  you up.
\item
  You need to keep up with developments in your field. Read widely.
\end{itemize}

\hypertarget{tip-3-meet-reality-early-on-the-biggest-risks}{%
\subsubsection{Tip \#3: Meet Reality Early on the Biggest
Risks}\label{tip-3-meet-reality-early-on-the-biggest-risks}}

In getting from A to B on the Risk Landscape, imagine that all the
Attendant Risks are the stages of a journey. Some might be on foot,
train, car and so on. In order for your course of action to work, all
the stages in the journey have to succeed.

Although you might have to make the steps of a journey in some order,
you can still mitigate risk in a different order. For example, checking
the trains are running, making sure your bike is working, booking
tickets and taxis, and so on.

The \emph{sensible} approach would be to test the steps \emph{in order
from weakest to strongest}. This means working out how to meet reality
for each risk in turn, in order from biggest risk to smallest.

Often, a \emph{strategy} will be broken up into multiple actions.
\emph{Which are the riskiest actions?} Figure this out, using the
Risk-First vocabulary and the best experience you can bring to bear,
then, perform the actions which Pay Off the biggest risks first.

As we saw from the ``10X Developer'' Saw, Learning Curve Risk and Dead
End Risk, are likely to be the biggest risks. How can we front-load this
and tackle these earlier?

\begin{itemize}
\tightlist
\item
  \emph{Having a vocabulary} (like the one Risk-First provides) allows
  us to \emph{at least talk about these}. e.g. ``I believe there is a
  Dead End Risk that we might not be able to get this software to run on
  Linux.''
\item
  Build mock-ups:

  \begin{itemize}
  \tightlist
  \item
    UI wireframes allow us to bottom out the Communication Risk of the
    interfaces we build.
  \item
    Spike Solutions allow us to de-risk algorithms and approaches before
    making them part of the main development.
  \item
    Test the market with these and meet reality early.
  \end{itemize}
\item
  Don't pick delivery dates far in the future. Collectively work out the
  biggest risks with your clients, and then arrange the next possible
  date to demonstrate the mitigation.
\item
  Do actions \emph{early} that are \emph{simple} but are nevertheless
  show-stoppers. They are as much a source of Hidden Risk as more
  obviously tricky actions.
\end{itemize}

\hypertarget{tip-4-talk-frankly-about-all-the-risks}{%
\subsubsection{Tip \#4: Talk Frankly About All The
Risks}\label{tip-4-talk-frankly-about-all-the-risks}}

Let's get back to Bill and Carl. What went wrong between points
\texttt{(1)} and \texttt{(2)}? Let's break it down:

\begin{itemize}
\tightlist
\item
  \textbf{Bill \emph{wants} the system in 3-4 months.} It doesn't
  happen.
\item
  \textbf{He says it ``must be delivered in 6 months'', but this doesn't
  happen either.} However, the world (and the project) doesn't end:
  \emph{it carries on}. What does this mean about the truth of his
  statement? Was he deliberately lying about the end date, or just
  espousing his view on the Schedule Risk?
\item
  \textbf{Carl's original estimate was 9 months.} Was he working to this
  all along? Did the initial brow-beating over deadlines at point
  \texttt{(1)} contribute to Agency Risk in a way that \emph{didn't}
  happen at point \texttt{(2)}?
\item
  \textbf{Why \emph{did} Bill get so angry?} His understanding of the
  Schedule Risk was, if anything, \emph{worse} than Carl's. It's not
  stated in the account, but it's likely the Trust Risk moved upwards:
  Did his superiors stop trusting him? Was his job at stake?
\item
  \textbf{How could including this risk in the discussion have improved
  the planning process?} Could the conversation have started like this
  instead?
\end{itemize}

\begin{quotation}

``I think it will take about 9 months, but that's just a rough estimate
at this point,'' Carl said. ``That's not going to work,'' Bill said. ``I
was hoping you'd say 3 or 4 months. I need to show the board something
by then or I'm worried they will lose confidence in me and this
project''.

\end{quotation}

\begin{quotation}

``OK,'' said Carl. ``But I'm really concerned we have huge Feature Fit
Risk. The task of understanding the requirements and doing the design is
massive.''

\end{quotation}

\begin{quotation}

``Well, in my head it's actually pretty simple,'' said Bill. ``Maybe I
don't have the full picture, or maybe your idea of what to build is more
complex than I think it needs to be. That's a massive risk right there
and I think we should try and mitigate it right now before things
progress. Maybe I'll need to go back to the board if it's worse than I
think.''

\end{quotation}

\begin{figure}
\centering
\includegraphics{images/generated/practices/estimates/bill2-400dpi.png}
\caption{Identifying The Action\label{bill2.png}}
\end{figure}

\hypertarget{tip-5-picture-worrying-futures}{%
\subsubsection{Tip \#5: Picture Worrying
Futures}\label{tip-5-picture-worrying-futures}}

The Bill/Carl problem is somewhat trivial (not to mention likely
fictional). How about one from real life? On a project I was working on
in November some years ago, we had two pieces of functionality we
needed: Bulk Uploads and Spock Integration. (It doesn't really matter
what these are). The bulk uploads would be useful \emph{now}. But, the
Spock Integration wasn't due until January. In the Spock estimation
meeting I wrote the following note:

\begin{quotation}

``Spock estimates were 4, 11 and 22 until we broke it down into tasks.
Now, estimates are above 55 for the whole piece. And worryingly, we
probably don't have all the tasks. We know we need bulk uploads in
November. Spock is January. So, do bulk uploads?''

\end{quotation}

The team \emph{wanted} to start Bulk Uploads work. After all, from these
estimates it looked like Spock could easily be completed in January.
However, the question should have been:

\begin{quotation}

``If it was February now, and we'd \emph{got nothing done}, what would
our biggest risk be?''

\end{quotation}

Missing Bulk Uploads wouldn't be a show-stopper, but missing Spock would
be a huge regulatory problem. \emph{Start work on the things you can't
miss.}

This is the essence of De-Risking.

\backmatter

\hypertarget{glossary}{%
\chapter{Glossary}\label{glossary}}

\hypertarget{abstraction-1}{%
\subsection{Abstraction}\label{abstraction-1}}

The process of removing physical, spatial, or temporal details or
attributes in the study of objects or systems in order to more closely
attend to other details of interest.

\hypertarget{agent}{%
\subsection{Agent}\label{agent}}

Agency is the capacity of an actor to act in a given environment. We use
the term \emph{agent} to refer to any process, person, system or
organisation with agency.

\hypertarget{feedback-loop}{%
\subsection{Feedback Loop}\label{feedback-loop}}

The process of testing an Internal Model by testing it, through taking
action to Meet Reality. Typically, we talk about short or long feedback
loops, depending on the intervals between Meeting Reality.

\hypertarget{goal-in-mind-1}{%
\subsection{Goal In Mind}\label{goal-in-mind-1}}

A picture of the future that an individual or team carries within their
Internal Model; An imagined destination on the Risk Landscape.

\hypertarget{internal-model}{%
\subsection{Internal Model}\label{internal-model}}

The model of reality held by an individual, team, software system or
other Agent. You can regard the concept of Internal Model as being what
you \emph{know} and what you \emph{think} about a certain situation. An
internal model \emph{represents} reality: reality is made of matter,
whereas the internal model is information.

Obviously, because we've all had different experiences, and our brains
are wired up differently, everyone will have a different Internal Model
of reality.

\begin{itemize}
\tightlist
\item
  Within an organisation, we might consider the Internal Model of a
  \emph{team of people} to be the shared knowledge, values and working
  practices of that team.
\item
  Within a software system, we might consider the Internal Model of a
  single server, and what knowledge it has of the world.
\item
  A codebase is a team's Internal Model written down and encoded as
  software.
\end{itemize}

\hypertarget{meet-reality}{%
\subsection{Meet Reality}\label{meet-reality}}

Any moment where we test an Internal Model by exposing it's predictive
power against reality. Note that ``Reality'' might be limited in some
way, for example, a trial period or test users.

\hypertarget{pay-off-1}{%
\subsection{Pay-Off}\label{pay-off-1}}

Pay-Off refers to the \emph{value} of the actions we take. When we
decide on a course of action, we have in mind a risk we wish to manage.
If the action is likely to have a big positive effect on the risk of a
project, we say it has a promising pay off, whereas if the action fails
to manage the risk, then it hasn't \emph{paid off}.

\hypertarget{risk}{%
\subsection{Risk}\label{risk}}

A possibility of loss or cost. Anything that \emph{can} go wrong on a
project, or is \emph{going} wrong, but so far hasn't been quantified. We
talk about risk because we wish to recognise both the range of
possibilities and the range of cost.

Usually broken down into:

\hypertarget{attendant-risk-1}{%
\subsubsection{Attendant Risk}\label{attendant-risk-1}}

A Risk you expect to face as the result of Taking Action.

\hypertarget{hidden-risk}{%
\subsubsection{Hidden Risk}\label{hidden-risk}}

Risks you aren't aware of when you consider Taking Action. i.e.~an
\emph{unknown unknown}.

\hypertarget{mitigated-risk}{%
\subsubsection{Mitigated Risk}\label{mitigated-risk}}

Risks that, as a result of Taking Action have been minimized.

\hypertarget{upside-risk-1}{%
\subsubsection{Upside Risk}\label{upside-risk-1}}

The possibility of things going well, and leaving us with a benefit. We
may take action to maximize the likelihood and return of upside risks.

\hypertarget{risk-landscape-1}{%
\subsection{Risk Landscape}\label{risk-landscape-1}}

A hypothetical landscape on which risks can be placed. Taking Action
means making a move on the Risk Landscape to reposition a project so
that it has a different profile of Attendant Risks.

\hypertarget{taking-action}{%
\subsection{Taking Action}\label{taking-action}}

Refers to any activity in the project. Actions are usually in order to
manage some kind of risk. At the same time, Taking Action usually means
interacting with reality and updating the Internal Model.

\end{document}  